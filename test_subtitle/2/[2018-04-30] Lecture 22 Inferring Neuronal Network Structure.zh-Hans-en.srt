1
00:02:01,530 --> 00:02:06,260
好的，大家好，我叫Cody Baker，是大学三年级的学生
okay hello everyone my name is Cody Baker and a third year student in the

2
00:02:06,260 --> 00:02:06,270
好的，大家好，我叫Cody Baker，是大学三年级的学生
Baker and a third year student in the Department of a fighting computational

3
00:02:06,270 --> 00:02:07,850
我系一所战斗计算数学与统计系学习
Baker and a third year student in the Department of a fighting computational

4
00:02:07,850 --> 00:02:10,460
我系一所战斗计算数学与统计系学习
Department of a fighting computational mathematics and statistics and I study

5
00:02:10,460 --> 00:02:10,470
我系一所战斗计算数学与统计系学习
mathematics and statistics and I study in computational neuroscience and

6
00:02:10,470 --> 00:02:12,470
在计算神经科学中，特别是在推理问题上
mathematics and statistics and I study in computational neuroscience and

7
00:02:12,470 --> 00:02:14,180
在计算神经科学中，特别是在推理问题上
in computational neuroscience and particular the problem of inferring

8
00:02:14,180 --> 00:02:14,190
在计算神经科学中，特别是在推理问题上
particular the problem of inferring neuronal network structure specifically

9
00:02:14,190 --> 00:02:17,180
神经元网络结构，特别是来自细胞外的数据
particular the problem of inferring neuronal network structure specifically

10
00:02:17,180 --> 00:02:19,130
神经元网络结构，特别是来自细胞外的数据
neuronal network structure specifically with data coming from extracellular

11
00:02:19,130 --> 00:02:19,140
神经元网络结构，特别是来自细胞外的数据
with data coming from extracellular recording techniques so before we start

12
00:02:19,140 --> 00:02:21,770
记录技术，所以在我们开始谈论结果之前，我们还要做一个
with data coming from extracellular recording techniques so before we start

13
00:02:21,770 --> 00:02:23,060
记录技术，所以在我们开始谈论结果之前，我们还要做一个
recording techniques so before we start to talk about results we also do a

14
00:02:23,060 --> 00:02:23,070
记录技术，所以在我们开始谈论结果之前，我们还要做一个
to talk about results we also do a little bit of background in neuroscience

15
00:02:23,070 --> 00:02:25,310
神经科学和我们现在使用的模型的背景知识很少
to talk about results we also do a little bit of background in neuroscience

16
00:02:25,310 --> 00:02:28,400
神经科学和我们现在使用的模型的背景知识很少
little bit of background in neuroscience and the models that we use now you don't

17
00:02:28,400 --> 00:02:28,410
神经科学和我们现在使用的模型的背景知识很少
and the models that we use now you don't have to know too much but you do have to

18
00:02:28,410 --> 00:02:29,990
必须了解太多，但是您必须知道大脑是一个器官
and the models that we use now you don't have to know too much but you do have to

19
00:02:29,990 --> 00:02:31,070
必须了解太多，但是您必须知道大脑是一个器官
have to know too much but you do have to know that the brain is an organ

20
00:02:31,070 --> 00:02:31,080
必须了解太多，但是您必须知道大脑是一个器官
know that the brain is an organ comprised of very large numbers of

21
00:02:31,080 --> 00:02:34,520
由非常多的单个计算单元组成，这些单元称为
know that the brain is an organ comprised of very large numbers of

22
00:02:34,520 --> 00:02:36,890
由非常多的单个计算单元组成，这些单元称为
comprised of very large numbers of individual computing unit cells known as

23
00:02:36,890 --> 00:02:36,900
由非常多的单个计算单元组成，这些单元称为
individual computing unit cells known as neurons and neurons are able to connect

24
00:02:36,900 --> 00:02:41,420
神经元和神经元能够通过突触相互连接
individual computing unit cells known as neurons and neurons are able to connect

25
00:02:41,420 --> 00:02:44,900
神经元和神经元能够通过突触相互连接
neurons and neurons are able to connect to one another by way of a synapse which

26
00:02:44,900 --> 00:02:44,910
神经元和神经元能够通过突触相互连接
to one another by way of a synapse which is when the axon extension of one neuron

27
00:02:44,910 --> 00:02:47,680
当一个神经元的轴突延伸附着到另一个神经元的树突上时，
to one another by way of a synapse which is when the axon extension of one neuron

28
00:02:47,680 --> 00:02:51,190
当一个神经元的轴突延伸附着到另一个神经元的树突上时，
is when the axon extension of one neuron attaches to the dendrites of another and

29
00:02:51,190 --> 00:02:51,200
当一个神经元的轴突延伸附着到另一个神经元的树突上时，
attaches to the dendrites of another and they share information across the

30
00:02:51,200 --> 00:02:54,949
它们通过电化学方式在整个突触中共享信息
attaches to the dendrites of another and they share information across the

31
00:02:54,949 --> 00:02:56,780
它们通过电化学方式在整个突触中共享信息
they share information across the synapse by way of electrochemical

32
00:02:56,780 --> 00:02:56,790
它们通过电化学方式在整个突触中共享信息
synapse by way of electrochemical impulses known as spikes these are brief

33
00:02:56,790 --> 00:02:59,570
这些脉冲称为尖峰脉冲，是通过电压迹线可观察到的短暂瞬变
synapse by way of electrochemical impulses known as spikes these are brief

34
00:02:59,570 --> 00:03:02,600
这些脉冲称为尖峰脉冲，是通过电压迹线可观察到的短暂瞬变
impulses known as spikes these are brief transients observable via voltage traces

35
00:03:02,600 --> 00:03:02,610
这些脉冲称为尖峰脉冲，是通过电压迹线可观察到的短暂瞬变
transients observable via voltage traces from the inside of a neuron you see the

36
00:03:02,610 --> 00:03:05,750
在神经元内部，您会看到尖峰是那里的两个大事件，
transients observable via voltage traces from the inside of a neuron you see the

37
00:03:05,750 --> 00:03:09,440
在神经元内部，您会看到尖峰是那里的两个大事件，
from the inside of a neuron you see the spikes are the two big events there and

38
00:03:09,440 --> 00:03:09,450
在神经元内部，您会看到尖峰是那里的两个大事件，
spikes are the two big events there and they decay very quickly Dunn's back to

39
00:03:09,450 --> 00:03:11,150
它们很快衰减邓恩回到了静止的电位
spikes are the two big events there and they decay very quickly Dunn's back to

40
00:03:11,150 --> 00:03:13,330
它们很快衰减邓恩回到了静止的电位
they decay very quickly Dunn's back to the resting potential

41
00:03:13,330 --> 00:03:13,340
它们很快衰减邓恩回到了静止的电位
the resting potential now neurons come in two types excitatory

42
00:03:13,340 --> 00:03:16,280
现在神经元有兴奋性和抑制性两种重要的区别
the resting potential now neurons come in two types excitatory

43
00:03:16,280 --> 00:03:20,060
现在神经元有兴奋性和抑制性两种重要的区别
now neurons come in two types excitatory and inhibitory the important difference

44
00:03:20,060 --> 00:03:20,070
现在神经元有兴奋性和抑制性两种重要的区别
and inhibitory the important difference is that the effect of spiking and a

45
00:03:20,070 --> 00:03:22,789
是尖峰和突触前细胞的作用可能导致更多
and inhibitory the important difference is that the effect of spiking and a

46
00:03:22,789 --> 00:03:25,910
是尖峰和突触前细胞的作用可能导致更多
is that the effect of spiking and a presynaptic cell can either cause more

47
00:03:25,910 --> 00:03:25,920
是尖峰和突触前细胞的作用可能导致更多
presynaptic cell can either cause more or less light in the postsynaptic cell

48
00:03:25,920 --> 00:03:27,890
或更少的突触后细胞和像你这样的聪明人的行为
presynaptic cell can either cause more or less light in the postsynaptic cell

49
00:03:27,890 --> 00:03:31,970
或更少的突触后细胞和像你这样的聪明人的行为
or less light in the postsynaptic cell and intelligent behavior people like you

50
00:03:31,970 --> 00:03:31,980
或更少的突触后细胞和像你这样的聪明人的行为
and intelligent behavior people like you and me are thought to arise by complex

51
00:03:31,980 --> 00:03:35,780
我和我被认为是由于尖峰的复杂，非常复杂的相互作用而产生的
and intelligent behavior people like you and me are thought to arise by complex

52
00:03:35,780 --> 00:03:37,970
我和我被认为是由于尖峰的复杂，非常复杂的相互作用而产生的
and me are thought to arise by complex very complex interactions of spiking

53
00:03:37,970 --> 00:03:37,980
我和我被认为是由于尖峰的复杂，非常复杂的相互作用而产生的
very complex interactions of spiking events in very large networks now there

54
00:03:37,980 --> 00:03:40,640
大型网络中的事件现在有很多不同的计算
very complex interactions of spiking events in very large networks now there

55
00:03:40,640 --> 00:03:42,410
大型网络中的事件现在有很多不同的计算
events in very large networks now there are a lot of different computational

56
00:03:42,410 --> 00:03:42,420
大型网络中的事件现在有很多不同的计算
are a lot of different computational theories that can explain very specific

57
00:03:42,420 --> 00:03:45,860
可以解释非常具体的任务（例如记忆视觉）的理论
are a lot of different computational theories that can explain very specific

58
00:03:45,860 --> 00:03:47,810
可以解释非常具体的任务（例如记忆视觉）的理论
theories that can explain very specific tasks such as memory visual

59
00:03:47,810 --> 00:03:47,820
可以解释非常具体的任务（例如记忆视觉）的理论
tasks such as memory visual classification District in making go on

60
00:03:47,820 --> 00:03:50,690
分类区仍在继续，但我们没有足够的实际数据来
tasks such as memory visual classification District in making go on

61
00:03:50,690 --> 00:03:54,800
分类区仍在继续，但我们没有足够的实际数据来
classification District in making go on but we don't have enough real data to

62
00:03:54,800 --> 00:03:54,810
分类区仍在继续，但我们没有足够的实际数据来
but we don't have enough real data to confirm that of actual brains follow any

63
00:03:54,810 --> 00:03:57,650
确认实际的大脑遵循任何特定的理论，其中很大一部分
but we don't have enough real data to confirm that of actual brains follow any

64
00:03:57,650 --> 00:04:01,310
确认实际的大脑遵循任何特定的理论，其中很大一部分
confirm that of actual brains follow any specific theory and a big part of this

65
00:04:01,310 --> 00:04:01,320
确认实际的大脑遵循任何特定的理论，其中很大一部分
specific theory and a big part of this is because in the past people had been

66
00:04:01,320 --> 00:04:03,050
是因为过去人们能够从我手中进行举报
specific theory and a big part of this is because in the past people had been

67
00:04:03,050 --> 00:04:04,740
是因为过去人们能够从我手中进行举报
is because in the past people had been able to report from my hands

68
00:04:04,740 --> 00:04:04,750
是因为过去人们能够从我手中进行举报
able to report from my hands neurons simultaneously at a time there

69
00:04:04,750 --> 00:04:08,340
最近一次同时出现神经元，并且这种情况一直在发展
able to report from my hands neurons simultaneously at a time there

70
00:04:08,340 --> 00:04:10,590
最近一次同时出现神经元，并且这种情况一直在发展
neurons simultaneously at a time there recently and this has been developing

71
00:04:10,590 --> 00:04:10,600
最近一次同时出现神经元，并且这种情况一直在发展
recently and this has been developing almost analogous to Moore's law every

72
00:04:10,600 --> 00:04:12,480
每隔几年几乎类似于摩尔定律，我们找到一种方法来记录
recently and this has been developing almost analogous to Moore's law every

73
00:04:12,480 --> 00:04:15,000
每隔几年几乎类似于摩尔定律，我们找到一种方法来记录
almost analogous to Moore's law every few years we find a way to record from

74
00:04:15,000 --> 00:04:15,010
每隔几年几乎类似于摩尔定律，我们找到一种方法来记录
few years we find a way to record from twice as many neurons as before in

75
00:04:15,010 --> 00:04:18,569
近年来，我们开发的神经元数量是以前的两倍
few years we find a way to record from twice as many neurons as before in

76
00:04:18,569 --> 00:04:20,009
近年来，我们开发的神经元数量是以前的两倍
twice as many neurons as before in recent years we have developed

77
00:04:20,009 --> 00:04:20,019
近年来，我们开发的神经元数量是以前的两倍
recent years we have developed techniques that can record from hundreds

78
00:04:20,019 --> 00:04:22,500
可以记录成千上万的技术我想现在他们正在开始
recent years we have developed techniques that can record from hundreds

79
00:04:22,500 --> 00:04:24,240
可以记录成千上万的技术我想现在他们正在开始
techniques that can record from hundreds thousands I think now they're starting

80
00:04:24,240 --> 00:04:24,250
可以记录成千上万的技术我想现在他们正在开始
thousands I think now they're starting to push tens of thousands and we're

81
00:04:24,250 --> 00:04:26,790
推动成千上万，我们将专注于一个
thousands I think now they're starting to push tens of thousands and we're

82
00:04:26,790 --> 00:04:28,740
推动成千上万，我们将专注于一个
to push tens of thousands and we're going to focus on one in particular on

83
00:04:28,740 --> 00:04:28,750
推动成千上万，我们将专注于一个
going to focus on one in particular on that that called calcium imaging now

84
00:04:28,750 --> 00:04:31,170
所谓的钙成像现在可以主动成像了，您拥有中央激光
going to focus on one in particular on that that called calcium imaging now

85
00:04:31,170 --> 00:04:33,180
所谓的钙成像现在可以主动成像了，您拥有中央激光
that that called calcium imaging now active imaging you have a central laser

86
00:04:33,180 --> 00:04:33,190
所谓的钙成像现在可以主动成像了，您拥有中央激光
active imaging you have a central laser hub is gaining gaining some cubic volume

87
00:04:33,190 --> 00:04:36,030
集线器正在获得一些立方体积的神经空间和一大堆
active imaging you have a central laser hub is gaining gaining some cubic volume

88
00:04:36,030 --> 00:04:40,250
集线器正在获得一些立方体积的神经空间和一大堆
hub is gaining gaining some cubic volume of neural space and a whole bunch of

89
00:04:40,250 --> 00:04:40,260
集线器正在获得一些立方体积的神经空间和一大堆
of neural space and a whole bunch of post processing machine learning based

90
00:04:40,260 --> 00:04:43,860
基于机器学习的后处理技术，您可以识别位置
of neural space and a whole bunch of post processing machine learning based

91
00:04:43,860 --> 00:04:45,300
基于机器学习的后处理技术，您可以识别位置
post processing machine learning based techniques you can identify the location

92
00:04:45,300 --> 00:04:45,310
基于机器学习的后处理技术，您可以识别位置
techniques you can identify the location in space of every individual neuron and

93
00:04:45,310 --> 00:04:48,800
在每个神经元的空间中，然后您就可以提取出
techniques you can identify the location in space of every individual neuron and

94
00:04:48,800 --> 00:04:53,040
在每个神经元的空间中，然后您就可以提取出
in space of every individual neuron and then you can extract a measure of

95
00:04:53,040 --> 00:04:53,050
在每个神经元的空间中，然后您就可以提取出
then you can extract a measure of fluorescence that indicates how active

96
00:04:53,050 --> 00:04:55,740
荧光指示神经元的活跃度和个体性，这是
then you can extract a measure of fluorescence that indicates how active

97
00:04:55,740 --> 00:04:58,050
荧光指示神经元的活跃度和个体性，这是
fluorescence that indicates how active and individual neuron is and this is

98
00:04:58,050 --> 00:04:58,060
荧光指示神经元的活跃度和个体性，这是
and individual neuron is and this is actual real data you're looking at here

99
00:04:58,060 --> 00:05:00,060
您在这里查看的是实际的真实数据，您可以看到一些神经元在刺刺
and individual neuron is and this is actual real data you're looking at here

100
00:05:00,060 --> 00:05:03,120
您在这里查看的是实际的真实数据，您可以看到一些神经元在刺刺
actual real data you're looking at here and you can see some neurons are spiking

101
00:05:03,120 --> 00:05:03,130
您在这里查看的是实际的真实数据，您可以看到一些神经元在刺刺
and you can see some neurons are spiking very frequently that's like that one

102
00:05:03,130 --> 00:05:05,190
很多时候，就像那个总是彩色的Thurmont穗状花序
and you can see some neurons are spiking very frequently that's like that one

103
00:05:05,190 --> 00:05:08,550
很多时候，就像那个总是彩色的Thurmont穗状花序
very frequently that's like that one that's always colored Thurmont spiking

104
00:05:08,550 --> 00:05:08,560
很多时候，就像那个总是彩色的Thurmont穗状花序
that's always colored Thurmont spiking at all and others are going very

105
00:05:08,560 --> 00:05:10,260
根本没有其他人根据最重要的内容进行
that's always colored Thurmont spiking at all and others are going very

106
00:05:10,260 --> 00:05:13,020
根本没有其他人根据最重要的内容进行
at all and others are going very sporadically according to what's on top

107
00:05:13,020 --> 00:05:13,030
根本没有其他人根据最重要的内容进行
sporadically according to what's on top of these and so in the context of the

108
00:05:13,030 --> 00:05:20,100
这些，因此在数据的上下文中，它看起来像什么
sporadically according to what's on top of these and so in the context of the

109
00:05:20,100 --> 00:05:21,719
这些，因此在数据的上下文中，它看起来像什么
of these and so in the context of the data what does it look like it looks

110
00:05:21,719 --> 00:05:21,729
这些，因此在数据的上下文中，它看起来像什么
data what does it look like it looks like a bunch of calcium sorry it looks

111
00:05:21,729 --> 00:05:24,840
像一堆钙，对不起，它看起来像一堆高斯预言
data what does it look like it looks like a bunch of calcium sorry it looks

112
00:05:24,840 --> 00:05:27,750
像一堆钙，对不起，它看起来像一堆高斯预言
like a bunch of calcium sorry it looks like a bunch of Gaussian Prophecy you

113
00:05:27,750 --> 00:05:27,760
像一堆钙，对不起，它看起来像一堆高斯预言
like a bunch of Gaussian Prophecy you get traces of relative fluorescence for

114
00:05:27,760 --> 00:05:29,700
获得脸部每个像素的相对荧光的痕迹，这些是
like a bunch of Gaussian Prophecy you get traces of relative fluorescence for

115
00:05:29,700 --> 00:05:34,310
获得脸部每个像素的相对荧光的痕迹，这些是
get traces of relative fluorescence for every pixel in the face these are the

116
00:05:34,310 --> 00:05:34,320
获得脸部每个像素的相对荧光的痕迹，这些是
every pixel in the face these are the cameras

117
00:05:34,320 --> 00:05:36,370
相机恒光束分束器
every pixel in the face these are the cameras

118
00:05:36,370 --> 00:05:40,540
相机恒光束分束器
cameras constant optical beam splitter you

119
00:05:40,540 --> 00:05:45,690
应该会自动学习下一个视频以跟随该视频，因此我是我的目标
cameras constant optical beam splitter you

120
00:05:45,690 --> 00:05:45,700
应该会自动学习下一个视频以跟随该视频，因此我是我的目标


121
00:05:45,700 --> 00:05:52,330
应该会自动学习下一个视频以跟随该视频，因此我是我的目标
should automatically learn to the next thing to follow that video so I my goal

122
00:05:52,330 --> 00:05:52,340
应该会自动学习下一个视频以跟随该视频，因此我是我的目标
thing to follow that video so I my goal here is to look at these traces as

123
00:05:52,340 --> 00:05:56,200
这里是将这些痕迹视为高斯过程，并试图猜测
thing to follow that video so I my goal here is to look at these traces as

124
00:05:56,200 --> 00:05:58,660
这里是将这些痕迹视为高斯过程，并试图猜测
here is to look at these traces as Gaussian processes and to try to guess

125
00:05:58,660 --> 00:05:58,670
这里是将这些痕迹视为高斯过程，并试图猜测
Gaussian processes and to try to guess which neurons are connected to one

126
00:05:58,670 --> 00:06:00,790
哪些神经元相互连接，我们可以从统计学上对马尔维斯
Gaussian processes and to try to guess which neurons are connected to one

127
00:06:00,790 --> 00:06:04,060
哪些神经元相互连接，我们可以从统计学上对马尔维斯
which neurons are connected to one another and we can statistically maulvis

128
00:06:04,060 --> 00:06:04,070
哪些神经元相互连接，我们可以从统计学上对马尔维斯
another and we can statistically maulvis data in a number of different ways we

129
00:06:04,070 --> 00:06:05,710
我们可以使用多种不同的方式使用随机微分方程
another and we can statistically maulvis data in a number of different ways we

130
00:06:05,710 --> 00:06:07,510
我们可以使用多种不同的方式使用随机微分方程
data in a number of different ways we can use stochastic differential equation

131
00:06:07,510 --> 00:06:07,520
我们可以使用多种不同的方式使用随机微分方程
can use stochastic differential equation for linear dynamical systems we talked

132
00:06:07,520 --> 00:06:09,430
对于线性动力系统，我们在课堂上讨论了通用自回归
can use stochastic differential equation for linear dynamical systems we talked

133
00:06:09,430 --> 00:06:12,370
对于线性动力系统，我们在课堂上讨论了通用自回归
for linear dynamical systems we talked about in class general auto regressive

134
00:06:12,370 --> 00:06:12,380
对于线性动力系统，我们在课堂上讨论了通用自回归
about in class general auto regressive processes or any sort of time series

135
00:06:12,380 --> 00:06:14,560
流程或任何时间序列模型，并且由于我们正在尝试
about in class general auto regressive processes or any sort of time series

136
00:06:14,560 --> 00:06:18,550
流程或任何时间序列模型，并且由于我们正在尝试
processes or any sort of time series model and since we're trying to go a

137
00:06:18,550 --> 00:06:18,560
流程或任何时间序列模型，并且由于我们正在尝试
model and since we're trying to go a little faster today I probably won't

138
00:06:18,560 --> 00:06:19,780
今天快一点，我可能不会在模型上谈论太多凝胶
model and since we're trying to go a little faster today I probably won't

139
00:06:19,780 --> 00:06:22,230
今天快一点，我可能不会在模型上谈论太多凝胶
little faster today I probably won't talk too much about the gel on models

140
00:06:22,230 --> 00:06:22,240
今天快一点，我可能不会在模型上谈论太多凝胶
talk too much about the gel on models okay so in the context of everything

141
00:06:22,240 --> 00:06:25,000
好的，所以在今天我们要谈论的所有事情的背景下，
talk too much about the gel on models okay so in the context of everything

142
00:06:25,000 --> 00:06:26,320
好的，所以在今天我们要谈论的所有事情的背景下，
okay so in the context of everything we're going to talk about today we're

143
00:06:26,320 --> 00:06:26,330
好的，所以在今天我们要谈论的所有事情的背景下，
we're going to talk about today we're always going to be referencing an

144
00:06:26,330 --> 00:06:28,030
总是要引用一个邻接矩阵或我们的概率
we're going to talk about today we're always going to be referencing an

145
00:06:28,030 --> 00:06:31,000
总是要引用一个邻接矩阵或我们的概率
always going to be referencing an adjacency matrix or our probabilistic

146
00:06:31,000 --> 00:06:31,010
总是要引用一个邻接矩阵或我们的概率
adjacency matrix or our probabilistic graphical models shown by this network

147
00:06:31,010 --> 00:06:33,840
该网络显示的图形模型现在可分解为两个不同的
adjacency matrix or our probabilistic graphical models shown by this network

148
00:06:33,840 --> 00:06:36,850
该网络显示的图形模型现在可分解为两个不同的
graphical models shown by this network now it is decomposable into two distinct

149
00:06:36,850 --> 00:06:36,860
该网络显示的图形模型现在可分解为两个不同的
now it is decomposable into two distinct parts it has a weighted part that is

150
00:06:36,860 --> 00:06:40,540
它有一个加权的部分，它是随机的并且是正态分布的，并且
now it is decomposable into two distinct parts it has a weighted part that is

151
00:06:40,540 --> 00:06:43,540
它有一个加权的部分，它是随机的并且是正态分布的，并且
parts it has a weighted part that is random and normally distributed and it

152
00:06:43,540 --> 00:06:43,550
它有一个加权的部分，它是随机的并且是正态分布的，并且
random and normally distributed and it has a structure driven by what's called

153
00:06:43,550 --> 00:06:45,910
具有所谓的进一步旅程驱动的结构，这意味着
random and normally distributed and it has a structure driven by what's called

154
00:06:45,910 --> 00:06:47,680
具有所谓的进一步旅程驱动的结构，这意味着
has a structure driven by what's called further journey which has means it's

155
00:06:47,680 --> 00:06:47,690
具有所谓的进一步旅程驱动的结构，这意味着
further journey which has means it's random binary at some level it's party

156
00:06:47,690 --> 00:06:50,410
在某种程度上它是聚会的随机二进制，所以这是一个示例邻接矩阵
further journey which has means it's random binary at some level it's party

157
00:06:50,410 --> 00:06:53,950
在某种程度上它是聚会的随机二进制，所以这是一个示例邻接矩阵
random binary at some level it's party so this is an example adjacency matrix

158
00:06:53,950 --> 00:06:53,960
在某种程度上它是聚会的随机二进制，所以这是一个示例邻接矩阵
so this is an example adjacency matrix remember it's back wise because we have

159
00:06:53,960 --> 00:06:56,680
记住这是明智的，因为我们的大脑中有兴奋性和抑制性神经元
so this is an example adjacency matrix remember it's back wise because we have

160
00:06:56,680 --> 00:07:00,550
记住这是明智的，因为我们的大脑中有兴奋性和抑制性神经元
remember it's back wise because we have excitatory and inhibitory neurons in our

161
00:07:00,550 --> 00:07:00,560
记住这是明智的，因为我们的大脑中有兴奋性和抑制性神经元
excitatory and inhibitory neurons in our model and here you continue inhibitory

162
00:07:00,560 --> 00:07:02,320
模型，在这里您继续抑制性的总是有负权重，所以您
excitatory and inhibitory neurons in our model and here you continue inhibitory

163
00:07:02,320 --> 00:07:06,220
模型，在这里您继续抑制性的总是有负权重，所以您
model and here you continue inhibitory ones always have negative weights so you

164
00:07:06,220 --> 00:07:06,230
模型，在这里您继续抑制性的总是有负权重，所以您
ones always have negative weights so you have random winding and spar structure

165
00:07:06,230 --> 00:07:08,410
最重要的是具有随机的绕组和翼梁结构，并明确说明
ones always have negative weights so you have random winding and spar structure

166
00:07:08,410 --> 00:07:10,840
最重要的是具有随机的绕组和翼梁结构，并明确说明
have random winding and spar structure on top of that and explicitly stating

167
00:07:10,840 --> 00:07:10,850
最重要的是具有随机的绕组和翼梁结构，并明确说明
on top of that and explicitly stating the problem we're interested in

168
00:07:10,850 --> 00:07:12,550
我们感兴趣的问题是，我们将稀疏结构Omega或
on top of that and explicitly stating the problem we're interested in

169
00:07:12,550 --> 00:07:15,610
我们感兴趣的问题是，我们将稀疏结构Omega或
the problem we're interested in differing the sparse structure Omega or

170
00:07:15,610 --> 00:07:15,620
我们感兴趣的问题是，我们将稀疏结构Omega或
differing the sparse structure Omega or the undirected case of Omega plus Omega

171
00:07:15,620 --> 00:07:18,070
欧米茄加欧米茄转置的无方向案例
differing the sparse structure Omega or the undirected case of Omega plus Omega

172
00:07:18,070 --> 00:07:19,950
欧米茄加欧米茄转置的无方向案例
the undirected case of Omega plus Omega transpose

173
00:07:19,950 --> 00:07:19,960
欧米茄加欧米茄转置的无方向案例
transpose and the quick note on this topic before

174
00:07:19,960 --> 00:07:23,590
在我们进行稳定性之前就此主题进行快速注释是非常重要的
transpose and the quick note on this topic before

175
00:07:23,590 --> 00:07:26,830
在我们进行稳定性之前就此主题进行快速注释是非常重要的
and the quick note on this topic before we go on stability is a very important

176
00:07:26,830 --> 00:07:26,840
在我们进行稳定性之前就此主题进行快速注释是非常重要的
we go on stability is a very important issue with these networks and you need

177
00:07:26,840 --> 00:07:28,630
这些网络的问题，您需要一组非常具体的约束来
we go on stability is a very important issue with these networks and you need

178
00:07:28,630 --> 00:07:31,030
这些网络的问题，您需要一组非常具体的约束来
issue with these networks and you need very specific set of constraints to

179
00:07:31,030 --> 00:07:31,040
这些网络的问题，您需要一组非常具体的约束来
very specific set of constraints to guarantee that your system is always

180
00:07:31,040 --> 00:07:33,040
确保您的系统始终稳定，并通过应用1
very specific set of constraints to guarantee that your system is always

181
00:07:33,040 --> 00:07:35,950
确保您的系统始终稳定，并通过应用1
guarantee that your system is always stable and you do that by applying a 1

182
00:07:35,950 --> 00:07:35,960
确保您的系统始终稳定，并通过应用1
stable and you do that by applying a 1 over square root and scaling on the

183
00:07:35,960 --> 00:07:39,030
超过平方根并按正态分布的捕捉缩放表示
stable and you do that by applying a 1 over square root and scaling on the

184
00:07:39,030 --> 00:07:42,160
超过平方根并按正态分布的捕捉缩放表示
over square root and scaling on the normally distributed snap express that

185
00:07:42,160 --> 00:07:42,170
超过平方根并按正态分布的捕捉缩放表示
normally distributed snap express that constrains a vast majority of the

186
00:07:42,170 --> 00:07:44,110
将绝大多数特征值限制在单位圆内，但是
normally distributed snap express that constrains a vast majority of the

187
00:07:44,110 --> 00:07:47,590
将绝大多数特征值限制在单位圆内，但是
constrains a vast majority of the eigenvalues to the unit circle and but

188
00:07:47,590 --> 00:07:47,600
将绝大多数特征值限制在单位圆内，但是
eigenvalues to the unit circle and but then you'll notice you have these two

189
00:07:47,600 --> 00:07:48,910
然后您会注意到您拥有这两个共轭的大特征值
eigenvalues to the unit circle and but then you'll notice you have these two

190
00:07:48,910 --> 00:07:50,800
然后您会注意到您拥有这两个共轭的大特征值
then you'll notice you have these two big eigen values that are conjugate

191
00:07:50,800 --> 00:07:50,810
然后您会注意到您拥有这两个共轭的大特征值
big eigen values that are conjugate pairs those are related to the Kurdish

192
00:07:50,810 --> 00:07:53,260
对那些与库尔德人有关的结构的稀疏性和
big eigen values that are conjugate pairs those are related to the Kurdish

193
00:07:53,260 --> 00:07:55,750
对那些与库尔德人有关的结构的稀疏性和
pairs those are related to the Kurdish for any structure the sparsity and those

194
00:07:55,750 --> 00:07:55,760
对那些与库尔德人有关的结构的稀疏性和
for any structure the sparsity and those you can keep to the right simply by

195
00:07:55,760 --> 00:07:59,740
您可以通过这两个陪审团的条件简单地保持在右边
for any structure the sparsity and those you can keep to the right simply by

196
00:07:59,740 --> 00:08:01,840
您可以通过这两个陪审团的条件简单地保持在右边
you can keep to the right simply by these two jury conditions the

197
00:08:01,840 --> 00:08:01,850
您可以通过这两个陪审团的条件简单地保持在右边
these two jury conditions the determinant of the trace on the block

198
00:08:01,850 --> 00:08:03,730
块上轨迹的决定因素在于网络的平均值，
these two jury conditions the determinant of the trace on the block

199
00:08:03,730 --> 00:08:06,780
块上轨迹的决定因素在于网络的平均值，
determinant of the trace on the block lies average for the network and

200
00:08:06,780 --> 00:08:06,790
块上轨迹的决定因素在于网络的平均值，
lies average for the network and throughout this we're going to be

201
00:08:06,790 --> 00:08:08,800
在这整个过程中，我们将量化各种性能
lies average for the network and throughout this we're going to be

202
00:08:08,800 --> 00:08:10,570
在这整个过程中，我们将量化各种性能
throughout this we're going to be quantifying the performance of various

203
00:08:10,570 --> 00:08:10,580
在这整个过程中，我们将量化各种性能
quantifying the performance of various algorithms using policy analysis and

204
00:08:10,580 --> 00:08:13,120
使用策略分析的算法以及是否比第一次看到它或
quantifying the performance of various algorithms using policy analysis and

205
00:08:13,120 --> 00:08:14,650
使用策略分析的算法以及是否比第一次看到它或
algorithms using policy analysis and whether than first time seeing it or

206
00:08:14,650 --> 00:08:14,660
使用策略分析的算法以及是否比第一次看到它或
whether than first time seeing it or just need a little refresher the ROC

207
00:08:14,660 --> 00:08:17,470
只需稍微刷新一下，ROC曲线就为false的参数函数
whether than first time seeing it or just need a little refresher the ROC

208
00:08:17,470 --> 00:08:20,320
只需稍微刷新一下，ROC曲线就为false的参数函数
just need a little refresher the ROC curve is a parametric function of false

209
00:08:20,320 --> 00:08:20,330
只需稍微刷新一下，ROC曲线就为false的参数函数
curve is a parametric function of false positive rate versus true positive rate

210
00:08:20,330 --> 00:08:22,210
正比率与真正比率作为线性分类器的阈值
curve is a parametric function of false positive rate versus true positive rate

211
00:08:22,210 --> 00:08:24,660
正比率与真正比率作为线性分类器的阈值
positive rate versus true positive rate as the threshold of a linear classifier

212
00:08:24,660 --> 00:08:24,670
正比率与真正比率作为线性分类器的阈值
as the threshold of a linear classifier is buried and so this is an example

213
00:08:24,670 --> 00:08:28,110
被埋了，所以这是我们要去做的一些东西的盗版曲线的例子
as the threshold of a linear classifier is buried and so this is an example

214
00:08:28,110 --> 00:08:30,190
被埋了，所以这是我们要去做的一些东西的盗版曲线的例子
is buried and so this is an example Piracy curve for some stuff we're going

215
00:08:30,190 --> 00:08:30,200
被埋了，所以这是我们要去做的一些东西的盗版曲线的例子
Piracy curve for some stuff we're going to talk about in just a bit

216
00:08:30,200 --> 00:08:32,290
谈论一下，你会看到你得到很高的真实
Piracy curve for some stuff we're going to talk about in just a bit

217
00:08:32,290 --> 00:08:34,060
谈论一下，你会看到你得到很高的真实
to talk about in just a bit and you can see you get very high true

218
00:08:34,060 --> 00:08:34,070
谈论一下，你会看到你得到很高的真实
and you can see you get very high true positives for very low false positives

219
00:08:34,070 --> 00:08:36,630
积极性极低的误报率，但总的来说，我们经常会感兴趣
and you can see you get very high true positives for very low false positives

220
00:08:36,630 --> 00:08:39,790
积极性极低的误报率，但总的来说，我们经常会感兴趣
positives for very low false positives but overall we will often be interested

221
00:08:39,790 --> 00:08:39,800
积极性极低的误报率，但总的来说，我们经常会感兴趣
but overall we will often be interested only in the area under this curve which

222
00:08:39,800 --> 00:08:41,950
仅在此曲线下方的区域内，才是1/2之间的好才华
but overall we will often be interested only in the area under this curve which

223
00:08:41,950 --> 00:08:44,890
仅在此曲线下方的区域内，才是1/2之间的好才华
only in the area under this curve which is a nice talented measure between 1/2

224
00:08:44,890 --> 00:08:44,900
仅在此曲线下方的区域内，才是1/2之间的好才华
is a nice talented measure between 1/2 and 1 corresponding to just random

225
00:08:44,900 --> 00:08:47,470
和1对应于随机猜测和完美分类
is a nice talented measure between 1/2 and 1 corresponding to just random

226
00:08:47,470 --> 00:08:49,600
和1对应于随机猜测和完美分类
and 1 corresponding to just random guessing and perfect classification

227
00:08:49,600 --> 00:08:49,610
和1对应于随机猜测和完美分类
guessing and perfect classification respectively okay so the case model

228
00:08:49,610 --> 00:08:52,960
分别好吧，所以我们将简要讨论的案例模型是
guessing and perfect classification respectively okay so the case model

229
00:08:52,960 --> 00:08:54,670
分别好吧，所以我们将简要讨论的案例模型是
respectively okay so the case model we'll talk briefly about is the

230
00:08:54,670 --> 00:08:54,680
分别好吧，所以我们将简要讨论的案例模型是
we'll talk briefly about is the stochastic differential equation which

231
00:08:54,680 --> 00:08:56,320
随机微分方程是一种威尔逊考文率模型，可以
we'll talk briefly about is the stochastic differential equation which

232
00:08:56,320 --> 00:09:00,790
随机微分方程是一种威尔逊考文率模型，可以
stochastic differential equation which is a Wilson cowan rate model which can

233
00:09:00,790 --> 00:09:00,800
随机微分方程是一种威尔逊考文率模型，可以
is a Wilson cowan rate model which can be expressed as this equation in terms

234
00:09:00,800 --> 00:09:04,690
用该方程的随机微分表示为
is a Wilson cowan rate model which can be expressed as this equation in terms

235
00:09:04,690 --> 00:09:07,450
用该方程的随机微分表示为
be expressed as this equation in terms of the stochastic differential of the

236
00:09:07,450 --> 00:09:07,460
用该方程的随机微分表示为
of the stochastic differential of the white noise which is just the

237
00:09:07,460 --> 00:09:09,520
白噪声，这只是耳朵获利过程的差异，但
of the stochastic differential of the white noise which is just the

238
00:09:09,520 --> 00:09:12,880
白噪声，这只是耳朵获利过程的差异，但
white noise which is just the differential of ear profit process but

239
00:09:12,880 --> 00:09:12,890
白噪声，这只是耳朵获利过程的差异，但
differential of ear profit process but if you just back up and look at it it's

240
00:09:12,890 --> 00:09:14,620
如果您只是备份并查看它，实际上只是一个箭头，
differential of ear profit process but if you just back up and look at it it's

241
00:09:14,620 --> 00:09:16,740
如果您只是备份并查看它，实际上只是一个箭头，
if you just back up and look at it it's really just an arrow one process in

242
00:09:16,740 --> 00:09:16,750
如果您只是备份并查看它，实际上只是一个箭头，
really just an arrow one process in continuous time so we know how to deal

243
00:09:16,750 --> 00:09:19,630
连续的时间，所以我们知道如何处理
really just an arrow one process in continuous time so we know how to deal

244
00:09:19,630 --> 00:09:20,770
连续的时间，所以我们知道如何处理
continuous time so we know how to deal with this

245
00:09:20,770 --> 00:09:20,780
连续的时间，所以我们知道如何处理
with this and you know the most useful thing that

246
00:09:20,780 --> 00:09:23,410
您知道我们将使用此方程式最有用的是
with this and you know the most useful thing that

247
00:09:23,410 --> 00:09:25,690
您知道我们将使用此方程式最有用的是
and you know the most useful thing that we will use this equation for is the

248
00:09:25,690 --> 00:09:25,700
您知道我们将使用此方程式最有用的是
we will use this equation for is the fact that has analytical solutions to

249
00:09:25,700 --> 00:09:28,270
对诸如交叉协方差之类的东西具有解析解的事实
we will use this equation for is the fact that has analytical solutions to

250
00:09:28,270 --> 00:09:29,890
对诸如交叉协方差之类的东西具有解析解的事实
fact that has analytical solutions to stuff like the cross cross covariance

251
00:09:29,890 --> 00:09:29,900
对诸如交叉协方差之类的东西具有解析解的事实
stuff like the cross cross covariance and in particular the cross spectrum

252
00:09:29,900 --> 00:09:33,700
特别是交叉谱，它是傅立叶变换的傅立叶变换
stuff like the cross cross covariance and in particular the cross spectrum

253
00:09:33,700 --> 00:09:36,750
特别是交叉谱，它是傅立叶变换的傅立叶变换
and in particular the cross spectrum which is the Fourier transform of that

254
00:09:36,750 --> 00:09:36,760
特别是交叉谱，它是傅立叶变换的傅立叶变换
which is the Fourier transform of that the specific algebraic form of the zero

255
00:09:36,760 --> 00:09:40,660
零频率互谱的特定代数形式可以是
which is the Fourier transform of that the specific algebraic form of the zero

256
00:09:40,660 --> 00:09:42,970
零频率互谱的特定代数形式可以是
the specific algebraic form of the zero frequency cross spectrum can be

257
00:09:42,970 --> 00:09:42,980
零频率互谱的特定代数形式可以是
frequency cross spectrum can be explicitly expanded to give a one-to-one

258
00:09:42,980 --> 00:09:45,790
明确扩展以提供双向之间的一对一关系
frequency cross spectrum can be explicitly expanded to give a one-to-one

259
00:09:45,790 --> 00:09:47,920
明确扩展以提供双向之间的一对一关系
explicitly expanded to give a one-to-one relationship between bi-directional

260
00:09:47,920 --> 00:09:47,930
明确扩展以提供双向之间的一对一关系
relationship between bi-directional connectivity and precision so this is

261
00:09:47,930 --> 00:09:50,230
连通性和精确度，所以这有点像所有
relationship between bi-directional connectivity and precision so this is

262
00:09:50,230 --> 00:09:53,800
连通性和精确度，所以这有点像所有
connectivity and precision so this is kind of like an analogous to all the

263
00:09:53,800 --> 00:09:53,810
连通性和精确度，所以这有点像所有
kind of like an analogous to all the stuff we talked about with Gaussian

264
00:09:53,810 --> 00:09:54,820
我们讨论过的与高斯图形模型有关的东西，除了这是一个
kind of like an analogous to all the stuff we talked about with Gaussian

265
00:09:54,820 --> 00:09:57,220
我们讨论过的与高斯图形模型有关的东西，除了这是一个
stuff we talked about with Gaussian graphical models except this is a

266
00:09:57,220 --> 00:09:57,230
我们讨论过的与高斯图形模型有关的东西，除了这是一个
graphical models except this is a process that's varying in time and so

267
00:09:57,230 --> 00:10:01,930
过程是随时间变化的，因此您可以等效地表示为贷款
graphical models except this is a process that's varying in time and so

268
00:10:01,930 --> 00:10:03,820
过程是随时间变化的，因此您可以等效地表示为贷款
process that's varying in time and so you can equivalently express as a loan

269
00:10:03,820 --> 00:10:03,830
过程是随时间变化的，因此您可以等效地表示为贷款
you can equivalently express as a loan process and disclose form as an LDS that

270
00:10:03,830 --> 00:10:07,180
处理和披露作为LDS的表格，在此过程中我们已经看到了很多
you can equivalently express as a loan process and disclose form as an LDS that

271
00:10:07,180 --> 00:10:09,430
处理和披露作为LDS的表格，在此过程中我们已经看到了很多
process and disclose form as an LDS that we've seen a lot of throughout this

272
00:10:09,430 --> 00:10:09,440
处理和披露作为LDS的表格，在此过程中我们已经看到了很多
we've seen a lot of throughout this class and there are a lot of different

273
00:10:09,440 --> 00:10:13,450
班级，并且有很多与次理想相关的次要问题
we've seen a lot of throughout this class and there are a lot of different

274
00:10:13,450 --> 00:10:15,490
班级，并且有很多与次理想相关的次要问题
class and there are a lot of different sub problems related to sub ideal

275
00:10:15,490 --> 00:10:15,500
班级，并且有很多与次理想相关的次要问题
sub problems related to sub ideal observations you can have more

276
00:10:15,500 --> 00:10:18,130
在模型中，您可以拥有比神经元更多的观察结果
sub problems related to sub ideal observations you can have more

277
00:10:18,130 --> 00:10:19,810
在模型中，您可以拥有比神经元更多的观察结果
observations you can have more observations than neurons in the model

278
00:10:19,810 --> 00:10:19,820
在模型中，您可以拥有比神经元更多的观察结果
observations than neurons in the model that's a great problem to have because

279
00:10:19,820 --> 00:10:21,430
这是一个很大的问题，因为那时您有多个样本
observations than neurons in the model that's a great problem to have because

280
00:10:21,430 --> 00:10:22,930
这是一个很大的问题，因为那时您有多个样本
that's a great problem to have because then you have multiple samples from

281
00:10:22,930 --> 00:10:22,940
这是一个很大的问题，因为那时您有多个样本
then you have multiple samples from every neuron but it's often not the case

282
00:10:22,940 --> 00:10:25,360
每个神经元，但通常情况并非如此，通常是因为您的观察次数较少
then you have multiple samples from every neuron but it's often not the case

283
00:10:25,360 --> 00:10:28,150
每个神经元，但通常情况并非如此，通常是因为您的观察次数较少
every neuron but it's often not the case often times you have fewer observations

284
00:10:28,150 --> 00:10:28,160
每个神经元，但通常情况并非如此，通常是因为您的观察次数较少
often times you have fewer observations than you do neurons in which case you

285
00:10:28,160 --> 00:10:30,610
而不是神经元，在这种情况下，您几乎必须转移整个神经元
often times you have fewer observations than you do neurons in which case you

286
00:10:30,610 --> 00:10:31,690
而不是神经元，在这种情况下，您几乎必须转移整个神经元
than you do neurons in which case you pretty much have to shift the entire

287
00:10:31,690 --> 00:10:31,700
而不是神经元，在这种情况下，您几乎必须转移整个神经元
pretty much have to shift the entire argument around not talking about

288
00:10:31,700 --> 00:10:34,990
关于不讨论推断单个神经元连通性的争论，但
pretty much have to shift the entire argument around not talking about

289
00:10:34,990 --> 00:10:37,090
关于不讨论推断单个神经元连通性的争论，但
argument around not talking about inferring single neuron connectivity but

290
00:10:37,090 --> 00:10:37,100
关于不讨论推断单个神经元连通性的争论，但
inferring single neuron connectivity but other connectivity between multiple

291
00:10:37,100 --> 00:10:39,550
我知道多个神经元局部和空间之间的其他连通性
inferring single neuron connectivity but other connectivity between multiple

292
00:10:39,550 --> 00:10:43,870
我知道多个神经元局部和空间之间的其他连通性
other connectivity between multiple neurons local and space I know the

293
00:10:43,870 --> 00:10:43,880
我知道多个神经元局部和空间之间的其他连通性
neurons local and space I know the really hard problem is you can have

294
00:10:43,880 --> 00:10:45,490
真正困难的问题是您可以有不同数量的观测值
neurons local and space I know the really hard problem is you can have

295
00:10:45,490 --> 00:10:47,550
真正困难的问题是您可以有不同数量的观测值
really hard problem is you can have different numbers of observations

296
00:10:47,550 --> 00:10:47,560
真正困难的问题是您可以有不同数量的观测值
different numbers of observations throughout time whenever you apply

297
00:10:47,560 --> 00:10:50,560
在任何时候，只要您应用钙成像，就将其应用到
different numbers of observations throughout time whenever you apply

298
00:10:50,560 --> 00:10:52,690
在任何时候，只要您应用钙成像，就将其应用到
throughout time whenever you apply calcium imaging you're applying it to a

299
00:10:52,690 --> 00:10:52,700
在任何时候，只要您应用钙成像，就将其应用到
calcium imaging you're applying it to a live subject and so they are sometimes

300
00:10:52,700 --> 00:10:56,200
生活对象，因此有时会麻醉以尽量减少了解
calcium imaging you're applying it to a live subject and so they are sometimes

301
00:10:56,200 --> 00:10:58,390
生活对象，因此有时会麻醉以尽量减少了解
live subject and so they are sometimes anesthetized to try to minimize knowing

302
00:10:58,390 --> 00:10:58,400
生活对象，因此有时会麻醉以尽量减少了解
anesthetized to try to minimize knowing but there's always a little bit of

303
00:10:58,400 --> 00:10:59,860
但是总会有一点抖动和一点动静，所以
anesthetized to try to minimize knowing but there's always a little bit of

304
00:10:59,860 --> 00:11:02,950
但是总会有一点抖动和一点动静，所以
but there's always a little bit of jitter a little bit of movement and so

305
00:11:02,950 --> 00:11:02,960
但是总会有一点抖动和一点动静，所以
jitter a little bit of movement and so you always have to be able to try to

306
00:11:02,960 --> 00:11:05,890
您必须始终能够尝试识别出您所处的神经元集合
jitter a little bit of movement and so you always have to be able to try to

307
00:11:05,890 --> 00:11:08,110
您必须始终能够尝试识别出您所处的神经元集合
you always have to be able to try to identify the set of neurons that you are

308
00:11:08,110 --> 00:11:08,120
您必须始终能够尝试识别出您所处的神经元集合
identify the set of neurons that you are somehow reporting from constantly

309
00:11:08,120 --> 00:11:10,180
始终不断地进行报告，并一起编写所有内容
identify the set of neurons that you are somehow reporting from constantly

310
00:11:10,180 --> 00:11:11,800
始终不断地进行报告，并一起编写所有内容
somehow reporting from constantly throughout time and write together all

311
00:11:11,800 --> 00:11:11,810
始终不断地进行报告，并一起编写所有内容
throughout time and write together all the data samples from that but my focus

312
00:11:11,810 --> 00:11:15,310
数据样本，但是我今天的重点是更基本的
throughout time and write together all the data samples from that but my focus

313
00:11:15,310 --> 00:11:16,770
数据样本，但是我今天的重点是更基本的
the data samples from that but my focus today is on a more fundamental

314
00:11:16,770 --> 00:11:16,780
数据样本，但是我今天的重点是更基本的
today is on a more fundamental difficulty so justr simplicity let's

315
00:11:16,780 --> 00:11:19,630
困难，所以简单一点，让我们假设我们有近乎完美的观察结果
today is on a more fundamental difficulty so justr simplicity let's

316
00:11:19,630 --> 00:11:22,030
困难，所以简单一点，让我们假设我们有近乎完美的观察结果
difficulty so justr simplicity let's assume we have near-perfect observations

317
00:11:22,030 --> 00:11:22,040
困难，所以简单一点，让我们假设我们有近乎完美的观察结果
assume we have near-perfect observations for the LDL

318
00:11:22,040 --> 00:11:23,660
对于LDL，所以当我们有一个线性
assume we have near-perfect observations for the LDL

319
00:11:23,660 --> 00:11:25,740
对于LDL，所以当我们有一个线性
for the LDL so we're gonna do when we have a linear

320
00:11:25,740 --> 00:11:25,750
对于LDL，所以当我们有一个线性
so we're gonna do when we have a linear dynamical system well the best way to

321
00:11:25,750 --> 00:11:27,540
动态系统最好的推断参数的方法是
so we're gonna do when we have a linear dynamical system well the best way to

322
00:11:27,540 --> 00:11:29,630
动态系统最好的推断参数的方法是
dynamical system well the best way to get inference of parameters is

323
00:11:29,630 --> 00:11:29,640
动态系统最好的推断参数的方法是
get inference of parameters is expectation-maximization right you've

324
00:11:29,640 --> 00:11:31,920
期望最大化，您已经运行了卡尔曼滤波和平滑处理
get inference of parameters is expectation-maximization right you've

325
00:11:31,920 --> 00:11:33,600
期望最大化，您已经运行了卡尔曼滤波和平滑处理
expectation-maximization right you've run the Kalman filtering and smoothing

326
00:11:33,600 --> 00:11:33,610
期望最大化，您已经运行了卡尔曼滤波和平滑处理
run the Kalman filtering and smoothing by Muslims passing and then you get a

327
00:11:33,610 --> 00:11:35,910
由穆斯林经过，然后您会在某些初始值上获得速率DM算法
run the Kalman filtering and smoothing by Muslims passing and then you get a

328
00:11:35,910 --> 00:11:38,580
由穆斯林经过，然后您会在某些初始值上获得速率DM算法
by Muslims passing and then you get a rate DM algorithm on some initial

329
00:11:38,580 --> 00:11:38,590
由穆斯林经过，然后您会在某些初始值上获得速率DM算法
rate DM algorithm on some initial guesses and after the few iterations

330
00:11:38,590 --> 00:11:40,470
猜测，经过几次迭代，它将收敛，这是一个示例
rate DM algorithm on some initial guesses and after the few iterations

331
00:11:40,470 --> 00:11:43,170
猜测，经过几次迭代，它将收敛，这是一个示例
guesses and after the few iterations it'll converge and this is an example

332
00:11:43,170 --> 00:11:43,180
猜测，经过几次迭代，它将收敛，这是一个示例
it'll converge and this is an example application of it you see a true network

333
00:11:43,180 --> 00:11:46,250
应用它，您会在左侧看到一个真正的网络，然后您就拥有了
it'll converge and this is an example application of it you see a true network

334
00:11:46,250 --> 00:11:48,870
应用它，您会在左侧看到一个真正的网络，然后您就拥有了
application of it you see a true network there up on the left and then you have

335
00:11:48,870 --> 00:11:48,880
应用它，您会在左侧看到一个真正的网络，然后您就拥有了
there up on the left and then you have an estimate given out a fixed false

336
00:11:48,880 --> 00:11:51,390
给出固定的误报率的估算值，因此该估算值
there up on the left and then you have an estimate given out a fixed false

337
00:11:51,390 --> 00:11:54,000
给出固定的误报率的估算值，因此该估算值
an estimate given out a fixed false positive ratio so this estimate of the

338
00:11:54,000 --> 00:11:54,010
给出固定的误报率的估算值，因此该估算值
positive ratio so this estimate of the network was chosen to be right about

339
00:11:54,010 --> 00:11:56,490
在ROC曲线上选择的网络就在那附近，
positive ratio so this estimate of the network was chosen to be right about

340
00:11:56,490 --> 00:11:59,760
在ROC曲线上选择的网络就在那附近，
network was chosen to be right about there on the ROC curve to live there to

341
00:11:59,760 --> 00:11:59,770
在ROC曲线上选择的网络就在那附近，
there on the ROC curve to live there to have a similar level of sparsity and a

342
00:11:59,770 --> 00:12:03,330
具有相似的稀疏度和相当高的信心
there on the ROC curve to live there to have a similar level of sparsity and a

343
00:12:03,330 --> 00:12:04,890
具有相似的稀疏度和相当高的信心
have a similar level of sparsity and a fairly high degree of confidence that

344
00:12:04,890 --> 00:12:04,900
具有相似的稀疏度和相当高的信心
fairly high degree of confidence that the selected edges are in fact true

345
00:12:04,900 --> 00:12:07,440
选定的边缘实际上是真实的边缘，但最重要的是
fairly high degree of confidence that the selected edges are in fact true

346
00:12:07,440 --> 00:12:11,010
选定的边缘实际上是真实的边缘，但最重要的是
the selected edges are in fact true edges but the most important thing here

347
00:12:11,010 --> 00:12:11,020
选定的边缘实际上是真实的边缘，但最重要的是
edges but the most important thing here is the fact that the area under the ROC

348
00:12:11,020 --> 00:12:13,410
是ROC曲线下的面积单调增加的事实
edges but the most important thing here is the fact that the area under the ROC

349
00:12:13,410 --> 00:12:16,260
是ROC曲线下的面积单调增加的事实
is the fact that the area under the ROC curve monotonically increases that you

350
00:12:16,260 --> 00:12:16,270
是ROC曲线下的面积单调增加的事实
curve monotonically increases that you feed it more and more data in near will

351
00:12:16,270 --> 00:12:18,510
几乎以数十到数百的规模向其提供越来越多的数据
curve monotonically increases that you feed it more and more data in near will

352
00:12:18,510 --> 00:12:21,000
几乎以数十到数百的规模向其提供越来越多的数据
feed it more and more data in near will on the scale of tens to hundreds of

353
00:12:21,000 --> 00:12:21,010
几乎以数十到数百的规模向其提供越来越多的数据
on the scale of tens to hundreds of thousands of data samples that will

354
00:12:21,010 --> 00:12:22,590
数以千计的数据样本将很快变得非常重要，
on the scale of tens to hundreds of thousands of data samples that will

355
00:12:22,590 --> 00:12:25,590
数以千计的数据样本将很快变得非常重要，
thousands of data samples that will become very important just a second and

356
00:12:25,590 --> 00:12:25,600
数以千计的数据样本将很快变得非常重要，
become very important just a second and you can also see that it converging to a

357
00:12:25,600 --> 00:12:27,810
您还可以看到，对于这些简单的方法，它已经收敛到一个完美的分类器
become very important just a second and you can also see that it converging to a

358
00:12:27,810 --> 00:12:31,920
您还可以看到，对于这些简单的方法，它已经收敛到一个完美的分类器
you can also see that it converging to a perfect classifier for it these simple

359
00:12:31,920 --> 00:12:31,930
您还可以看到，对于这些简单的方法，它已经收敛到一个完美的分类器
perfect classifier for it these simple networks now why is it we know that if

360
00:12:31,930 --> 00:12:36,690
网络现在为什么会这样？我们知道，如果您只有ggm，那就有一个标准
perfect classifier for it these simple networks now why is it we know that if

361
00:12:36,690 --> 00:12:39,330
网络现在为什么会这样？我们知道，如果您只有ggm，那就有一个标准
networks now why is it we know that if you just have a ggm there's a standard

362
00:12:39,330 --> 00:12:39,340
网络现在为什么会这样？我们知道，如果您只有ggm，那就有一个标准
you just have a ggm there's a standard time invariant graph we can explicitly

363
00:12:39,340 --> 00:12:42,990
时不变图，我们可以显式地得到一组条件
you just have a ggm there's a standard time invariant graph we can explicitly

364
00:12:42,990 --> 00:12:46,320
时不变图，我们可以显式地得到一组条件
time invariant graph we can explicitly get to a set of conditional

365
00:12:46,320 --> 00:12:46,330
时不变图，我们可以显式地得到一组条件
get to a set of conditional independencies from the precision maker

366
00:12:46,330 --> 00:12:47,910
来自精密制造商的独立性，我们知道，但是精密矩阵是
get to a set of conditional independencies from the precision maker

367
00:12:47,910 --> 00:12:50,970
来自精密制造商的独立性，我们知道，但是精密矩阵是
independencies from the precision maker we know that but the precision matrix is

368
00:12:50,970 --> 00:12:50,980
来自精密制造商的独立性，我们知道，但是精密矩阵是
we know that but the precision matrix is just one type of a general idea that's

369
00:12:50,980 --> 00:12:54,150
只是一般概念的一种，称为偏相关和粒子
we know that but the precision matrix is just one type of a general idea that's

370
00:12:54,150 --> 00:12:56,730
只是一般概念的一种，称为偏相关和粒子
just one type of a general idea that's called partial correlation and particle

371
00:12:56,730 --> 00:12:56,740
只是一般概念的一种，称为偏相关和粒子
called partial correlation and particle relations are really just pairwise

372
00:12:56,740 --> 00:12:58,530
关系实际上只是基于一组的成对相关
called partial correlation and particle relations are really just pairwise

373
00:12:58,530 --> 00:13:02,100
关系实际上只是基于一组的成对相关
relations are really just pairwise correlations conditioned on from set of

374
00:13:02,100 --> 00:13:02,110
关系实际上只是基于一组的成对相关
correlations conditioned on from set of the network and precision is in fact the

375
00:13:02,110 --> 00:13:05,810
网络和精度实际上是
correlations conditioned on from set of the network and precision is in fact the

376
00:13:05,810 --> 00:13:08,400
网络和精度实际上是
the network and precision is in fact the largest type of partial correlation in

377
00:13:08,400 --> 00:13:08,410
网络和精度实际上是
largest type of partial correlation in the sense of you condition on everything

378
00:13:08,410 --> 00:13:10,860
除了平价以外，您的感觉还取决于网络上的其他所有内容
largest type of partial correlation in the sense of you condition on everything

379
00:13:10,860 --> 00:13:13,080
除了平价以外，您的感觉还取决于网络上的其他所有内容
the sense of you condition on everything else on the network besides the parity

380
00:13:13,080 --> 00:13:13,090
除了平价以外，您的感觉还取决于网络上的其他所有内容
else on the network besides the parity that you're looking at but expectation

381
00:13:13,090 --> 00:13:15,360
您正在查看的商品，但期望最大化也可以看作是
else on the network besides the parity that you're looking at but expectation

382
00:13:15,360 --> 00:13:18,060
您正在查看的商品，但期望最大化也可以看作是
that you're looking at but expectation maximization can also be viewed as a

383
00:13:18,060 --> 00:13:18,070
您正在查看的商品，但期望最大化也可以看作是
maximization can also be viewed as a type of partial correlation if you look

384
00:13:18,070 --> 00:13:20,250
如果查看我们在作业5中得出的值，则是部分相关的类型
maximization can also be viewed as a type of partial correlation if you look

385
00:13:20,250 --> 00:13:22,080
如果查看我们在作业5中得出的值，则是部分相关的类型
type of partial correlation if you look at the values we derived in homework 5

386
00:13:22,080 --> 00:13:22,090
如果查看我们在作业5中得出的值，则是部分相关的类型
at the values we derived in homework 5 or in the equivalent common estimate

387
00:13:22,090 --> 00:13:26,150
或在等价的共同估算中，您可以看到您的数量是
at the values we derived in homework 5 or in the equivalent common estimate

388
00:13:26,150 --> 00:13:29,110
或在等价的共同估算中，您可以看到您的数量是
or in the equivalent common estimate you can see you have quantities that are

389
00:13:29,110 --> 00:13:29,120
或在等价的共同估算中，您可以看到您的数量是
you can see you have quantities that are essentially proportional to the 0 large

390
00:13:29,120 --> 00:13:32,720
基本上与每个学生的0个大样本成正比
you can see you have quantities that are essentially proportional to the 0 large

391
00:13:32,720 --> 00:13:35,540
基本上与每个学生的0个大样本成正比
essentially proportional to the 0 large sample per student being projected in

392
00:13:35,540 --> 00:13:35,550
基本上与每个学生的0个大样本成正比
sample per student being projected in the direction of the live 1 cross

393
00:13:35,550 --> 00:13:37,100
实时1交叉协方差的方向，因为记住eeehm给
sample per student being projected in the direction of the live 1 cross

394
00:13:37,100 --> 00:13:39,949
实时1交叉协方差的方向，因为记住eeehm给
the direction of the live 1 cross covariance because remember eeehm gives

395
00:13:39,949 --> 00:13:39,959
实时1交叉协方差的方向，因为记住eeehm给
covariance because remember eeehm gives us a directed measure whereas precision

396
00:13:39,959 --> 00:13:43,160
我们采用有针对性的措施，而精度是您必须施加的对称值
covariance because remember eeehm gives us a directed measure whereas precision

397
00:13:43,160 --> 00:13:45,889
我们采用有针对性的措施，而精度是您必须施加的对称值
us a directed measure whereas precision is a symmetric value you have to impose

398
00:13:45,889 --> 00:13:45,899
我们采用有针对性的措施，而精度是您必须施加的对称值
is a symmetric value you have to impose some sort of directionality in some way

399
00:13:45,899 --> 00:13:48,079
某种程度上的方向性，还有很多其他不同
is a symmetric value you have to impose some sort of directionality in some way

400
00:13:48,079 --> 00:13:49,369
某种程度上的方向性，还有很多其他不同
some sort of directionality in some way and there are a lot of other different

401
00:13:49,369 --> 00:13:49,379
某种程度上的方向性，还有很多其他不同
and there are a lot of other different methods but I thought that was kind of

402
00:13:49,379 --> 00:13:51,619
方法，但我认为pm确实只是一个
and there are a lot of other different methods but I thought that was kind of

403
00:13:51,619 --> 00:13:53,869
方法，但我认为pm确实只是一个
methods but I thought that was kind of interesting that p.m. is really just a

404
00:13:53,869 --> 00:13:53,879
方法，但我认为pm确实只是一个
interesting that p.m. is really just a special case of correlation okay we

405
00:13:53,879 --> 00:13:59,360
相关的特殊情况好吗，我们讨论过直接估算
interesting that p.m. is really just a special case of correlation okay we

406
00:13:59,360 --> 00:14:01,819
相关的特殊情况好吗，我们讨论过直接估算
special case of correlation okay we talked about directly estimating the

407
00:14:01,819 --> 00:14:01,829
相关的特殊情况好吗，我们讨论过直接估算
talked about directly estimating the precision instead of doing the common

408
00:14:01,829 --> 00:14:03,619
精度，而不是做普通的事情，经验数据的一个大问题是
talked about directly estimating the precision instead of doing the common

409
00:14:03,619 --> 00:14:07,579
精度，而不是做普通的事情，经验数据的一个大问题是
precision instead of doing the common stuff a big issue with empirical data is

410
00:14:07,579 --> 00:14:07,589
精度，而不是做普通的事情，经验数据的一个大问题是
stuff a big issue with empirical data is you have very short duration of trials

411
00:14:07,589 --> 00:14:10,480
您的试用期非常短，通常在几秒钟到
stuff a big issue with empirical data is you have very short duration of trials

412
00:14:10,480 --> 00:14:12,889
您的试用期非常短，通常在几秒钟到
you have very short duration of trials typically in the order of seconds to

413
00:14:12,889 --> 00:14:12,899
您的试用期非常短，通常在几秒钟到
typically in the order of seconds to minutes if that aware is the plot that I

414
00:14:12,899 --> 00:14:16,429
分钟，如果那是我刚刚向您展示的情节
typically in the order of seconds to minutes if that aware is the plot that I

415
00:14:16,429 --> 00:14:17,679
分钟，如果那是我刚刚向您展示的情节
minutes if that aware is the plot that I was just showing you where

416
00:14:17,679 --> 00:14:17,689
分钟，如果那是我刚刚向您展示的情节
was just showing you where expectation-maximization converged to a

417
00:14:17,689 --> 00:14:19,910
在ROC曲线下，期望最大化收敛到一个非常好的区域
was just showing you where expectation-maximization converged to a

418
00:14:19,910 --> 00:14:22,550
在ROC曲线下，期望最大化收敛到一个非常好的区域
expectation-maximization converged to a really good area under the ROC curve you

419
00:14:22,550 --> 00:14:22,560
在ROC曲线下，期望最大化收敛到一个非常好的区域
really good area under the ROC curve you needed hundreds of thousands of data

420
00:14:22,560 --> 00:14:24,319
需要成千上万的数据样本，这等于让您
really good area under the ROC curve you needed hundreds of thousands of data

421
00:14:24,319 --> 00:14:27,199
需要成千上万的数据样本，这等于让您
needed hundreds of thousands of data samples that would equate to having you

422
00:14:27,199 --> 00:14:27,209
需要成千上万的数据样本，这等于让您
samples that would equate to having you know trials that lasted for several

423
00:14:27,209 --> 00:14:28,910
知道审判已经持续了几个小时现在不切实际没有生命
samples that would equate to having you know trials that lasted for several

424
00:14:28,910 --> 00:14:32,509
知道审判已经持续了几个小时现在不切实际没有生命
know trials that lasted for several hours now not just impractical no living

425
00:14:32,509 --> 00:14:32,519
知道审判已经持续了几个小时现在不切实际没有生命
hours now not just impractical no living subject wants to sit there and watching

426
00:14:32,519 --> 00:14:33,980
对象想要坐在那里看电影，通常要花三个小时
hours now not just impractical no living subject wants to sit there and watching

427
00:14:33,980 --> 00:14:35,870
对象想要坐在那里看电影，通常要花三个小时
subject wants to sit there and watching movies with three hours these typically

428
00:14:35,870 --> 00:14:35,880
对象想要坐在那里看电影，通常要花三个小时
movies with three hours these typically might have to deal with so we have very

429
00:14:35,880 --> 00:14:40,550
可能需要处理，所以我们只有很少的数据，因此可以更好地利用
movies with three hours these typically might have to deal with so we have very

430
00:14:40,550 --> 00:14:42,650
可能需要处理，所以我们只有很少的数据，因此可以更好地利用
might have to deal with so we have very little data and so to make better use of

431
00:14:42,650 --> 00:14:42,660
可能需要处理，所以我们只有很少的数据，因此可以更好地利用
little data and so to make better use of what little data we have we will use the

432
00:14:42,660 --> 00:14:44,900
我们拥有多少数据，我们将使用正则化这个流行词，因此
little data and so to make better use of what little data we have we will use the

433
00:14:44,900 --> 00:14:49,699
我们拥有多少数据，我们将使用正则化这个流行词，因此
what little data we have we will use the buzzword of regularization and so the

434
00:14:49,699 --> 00:14:49,709
我们拥有多少数据，我们将使用正则化这个流行词，因此
buzzword of regularization and so the beijing of perspective regularization is

435
00:14:49,709 --> 00:14:51,740
透视正则化的北京实际上就像应用先验
buzzword of regularization and so the beijing of perspective regularization is

436
00:14:51,740 --> 00:14:53,960
透视正则化的北京实际上就像应用先验
beijing of perspective regularization is really just like applying a prior

437
00:14:53,960 --> 00:14:53,970
透视正则化的北京实际上就像应用先验
really just like applying a prior distribution to the coefficients for

438
00:14:53,970 --> 00:14:55,939
某些回归模型的系数分布以及与
really just like applying a prior distribution to the coefficients for

439
00:14:55,939 --> 00:14:58,610
某些回归模型的系数分布以及与
distribution to the coefficients for some regression model and concerning the

440
00:14:58,610 --> 00:14:58,620
某些回归模型的系数分布以及与
some regression model and concerning the model in that way really makes better

441
00:14:58,620 --> 00:15:01,160
这样的模型实际上可以更好地利用您所提供的数据
some regression model and concerning the model in that way really makes better

442
00:15:01,160 --> 00:15:04,040
这样的模型实际上可以更好地利用您所提供的数据
model in that way really makes better use of what data you have they it gives

443
00:15:04,040 --> 00:15:04,050
这样的模型实际上可以更好地利用您所提供的数据
use of what data you have they it gives you a higher-quality estimate for

444
00:15:04,050 --> 00:15:06,910
您将获得较高质量的估算值，以获取舒适的数据量，因此
use of what data you have they it gives you a higher-quality estimate for

445
00:15:06,910 --> 00:15:10,429
您将获得较高质量的估算值，以获取舒适的数据量，因此
you a higher-quality estimate for comfortable amounts of data and so the

446
00:15:10,429 --> 00:15:10,439
您将获得较高质量的估算值，以获取舒适的数据量，因此
comfortable amounts of data and so the specific estimation approach for

447
00:15:10,439 --> 00:15:12,079
我将使用的具体估计方法是图形化的
comfortable amounts of data and so the specific estimation approach for

448
00:15:12,079 --> 00:15:14,600
我将使用的具体估计方法是图形化的
specific estimation approach for proceeding that I will use is graphical

449
00:15:14,600 --> 00:15:14,610
我将使用的具体估计方法是图形化的
proceeding that I will use is graphical lasso a very popular approach very

450
00:15:14,610 --> 00:15:17,120
套索一种非常流行的方法，非常流行的算法，如果解决方案
proceeding that I will use is graphical lasso a very popular approach very

451
00:15:17,120 --> 00:15:20,389
套索一种非常流行的方法，非常流行的算法，如果解决方案
lasso a very popular approach very popular algorithm and if the solution of

452
00:15:20,389 --> 00:15:20,399
套索一种非常流行的方法，非常流行的算法，如果解决方案
popular algorithm and if the solution of this optimization equation where you'll

453
00:15:20,399 --> 00:15:23,299
这个优化方程式，您会在这里注意到，我们对它使用l1范数
popular algorithm and if the solution of this optimization equation where you'll

454
00:15:23,299 --> 00:15:27,230
这个优化方程式，您会在这里注意到，我们对它使用l1范数
this optimization equation where you'll notice here we're using an l1 norm on

455
00:15:27,230 --> 00:15:27,240
这个优化方程式，您会在这里注意到，我们对它使用l1范数
notice here we're using an l1 norm on our regularization that is

456
00:15:27,240 --> 00:15:29,500
我们的正规化就像在我们的身上加了一个稀疏的传单
notice here we're using an l1 norm on our regularization that is

457
00:15:29,500 --> 00:15:32,650
我们的正规化就像在我们的身上加了一个稀疏的传单
our regularization that is like imposing a sparse flyer on our

458
00:15:32,650 --> 00:15:32,660
我们的正规化就像在我们的身上加了一个稀疏的传单
like imposing a sparse flyer on our precision matrix and the regularization

459
00:15:32,660 --> 00:15:36,880
精度矩阵和可选择数量的正则强度Ram
like imposing a sparse flyer on our precision matrix and the regularization

460
00:15:36,880 --> 00:15:39,040
精度矩阵和可选择数量的正则强度Ram
precision matrix and the regularization strength Ram that can be chosen a number

461
00:15:39,040 --> 00:15:39,050
精度矩阵和可选择数量的正则强度Ram
strength Ram that can be chosen a number of different ways the simplest way is to

462
00:15:39,050 --> 00:15:42,670
最简单的方法是针对目标bono进行交叉验证
strength Ram that can be chosen a number of different ways the simplest way is to

463
00:15:42,670 --> 00:15:44,410
最简单的方法是针对目标bono进行交叉验证
of different ways the simplest way is to cross validated against target bono

464
00:15:44,410 --> 00:15:44,420
最简单的方法是针对目标bono进行交叉验证
cross validated against target bono sparsity the far more interesting

465
00:15:44,420 --> 00:15:46,720
稀疏性更有趣的方法是使用一种称为
cross validated against target bono sparsity the far more interesting

466
00:15:46,720 --> 00:15:48,040
稀疏性更有趣的方法是使用一种称为
sparsity the far more interesting approach is to use something called the

467
00:15:48,040 --> 00:15:48,050
稀疏性更有趣的方法是使用一种称为
approach is to use something called the Stars algorithm which uses all sorts of

468
00:15:48,050 --> 00:15:50,650
采用各种措施（例如基于体育的基特维奇运动）的明星算法
approach is to use something called the Stars algorithm which uses all sorts of

469
00:15:50,650 --> 00:15:54,220
采用各种措施（例如基于体育的基特维奇运动）的明星算法
Stars algorithm which uses all sorts of measures like kitv icy sports-based

470
00:15:54,220 --> 00:15:54,230
采用各种措施（例如基于体育的基特维奇运动）的明星算法
measures like kitv icy sports-based criterion and it runs all these to

471
00:15:54,230 --> 00:15:57,010
准则，并且将所有这些运行到各种迭代中，以产生一种
measures like kitv icy sports-based criterion and it runs all these to

472
00:15:57,010 --> 00:16:00,100
准则，并且将所有这些运行到各种迭代中，以产生一种
criterion and it runs all these to various iterations to kind of produce a

473
00:16:00,100 --> 00:16:00,110
准则，并且将所有这些运行到各种迭代中，以产生一种
various iterations to kind of produce a target level of expected sparsity and so

474
00:16:00,110 --> 00:16:05,620
目标稀疏度的水平，因此如果您使用饼图Galasso
various iterations to kind of produce a target level of expected sparsity and so

475
00:16:05,620 --> 00:16:08,200
目标稀疏度的水平，因此如果您使用饼图Galasso
target level of expected sparsity and so if you a pie graph Galasso and in

476
00:16:08,200 --> 00:16:08,210
目标稀疏度的水平，因此如果您使用饼图Galasso
if you a pie graph Galasso and in combination with a number of other

477
00:16:08,210 --> 00:16:09,670
结合许多其他措施，您会发现到目前为止
if you a pie graph Galasso and in combination with a number of other

478
00:16:09,670 --> 00:16:12,430
结合许多其他措施，您会发现到目前为止
combination with a number of other measures you'll notice that by far it

479
00:16:12,430 --> 00:16:12,440
结合许多其他措施，您会发现到目前为止
measures you'll notice that by far it always surpasses every other measure for

480
00:16:12,440 --> 00:16:15,340
在这些类型的
measures you'll notice that by far it always surpasses every other measure for

481
00:16:15,340 --> 00:16:17,230
在这些类型的
always surpasses every other measure for in terms of structure in these types of

482
00:16:17,230 --> 00:16:17,240
在这些类型的
in terms of structure in these types of networks and here are notice the

483
00:16:17,240 --> 00:16:19,750
网络，这是以前注意到的T规模的差异
in terms of structure in these types of networks and here are notice the

484
00:16:19,750 --> 00:16:21,610
网络，这是以前注意到的T规模的差异
networks and here are notice the difference in the scale of T previously

485
00:16:21,610 --> 00:16:21,620
网络，这是以前注意到的T规模的差异
difference in the scale of T previously we were talking about tens hundreds of

486
00:16:21,620 --> 00:16:24,040
我们现在谈论的是成千上万的数据点
difference in the scale of T previously we were talking about tens hundreds of

487
00:16:24,040 --> 00:16:25,300
我们现在谈论的是成千上万的数据点
we were talking about tens hundreds of thousands of data points now we're

488
00:16:25,300 --> 00:16:25,310
我们现在谈论的是成千上万的数据点
thousands of data points now we're talking about hundreds which is why our

489
00:16:25,310 --> 00:16:27,550
谈论数百个，这就是为什么我们知道恢复不是那么好
thousands of data points now we're talking about hundreds which is why our

490
00:16:27,550 --> 00:16:30,190
谈论数百个，这就是为什么我们知道恢复不是那么好
talking about hundreds which is why our you know it recovery isn't that great

491
00:16:30,190 --> 00:16:30,200
谈论数百个，这就是为什么我们知道恢复不是那么好
you know it recovery isn't that great but the point is still that crossover

492
00:16:30,200 --> 00:16:32,560
但重点仍然是，交叉功能比其他任何功能都好得多
you know it recovery isn't that great but the point is still that crossover

493
00:16:32,560 --> 00:16:35,200
但重点仍然是，交叉功能比其他任何功能都好得多
but the point is still that crossover does a far better job than any other

494
00:16:35,200 --> 00:16:35,210
但重点仍然是，交叉功能比其他任何功能都好得多
does a far better job than any other algorithm including the naive estimate

495
00:16:35,210 --> 00:16:38,710
包括天真的精度估计（仅是反函数）的算法
does a far better job than any other algorithm including the naive estimate

496
00:16:38,710 --> 00:16:40,150
包括天真的精度估计（仅是反函数）的算法
algorithm including the naive estimate of precision which is just the inverse

497
00:16:40,150 --> 00:16:40,160
包括天真的精度估计（仅是反函数）的算法
of precision which is just the inverse of sample covariance okay but there's a

498
00:16:40,160 --> 00:16:44,020
样本协方差还可以，但是我们有一个很大的不现实的假设
of precision which is just the inverse of sample covariance okay but there's a

499
00:16:44,020 --> 00:16:46,120
样本协方差还可以，但是我们有一个很大的不现实的假设
of sample covariance okay but there's a big unrealistic assumption that we've

500
00:16:46,120 --> 00:16:46,130
样本协方差还可以，但是我们有一个很大的不现实的假设
big unrealistic assumption that we've made throughout all the models so far

501
00:16:46,130 --> 00:16:48,580
到目前为止，在所有模型中都进行了建模，现在缺少外部输入
big unrealistic assumption that we've made throughout all the models so far

502
00:16:48,580 --> 00:16:52,000
到目前为止，在所有模型中都进行了建模，现在缺少外部输入
made throughout all the models so far and that's a lack of external input now

503
00:16:52,000 --> 00:16:52,010
到目前为止，在所有模型中都进行了建模，现在缺少外部输入
and that's a lack of external input now in in empirical studies you never have

504
00:16:52,010 --> 00:16:56,230
在实证研究中，您永远不会观察到这些东西，因此它们
and that's a lack of external input now in in empirical studies you never have

505
00:16:56,230 --> 00:16:58,480
在实证研究中，您永远不会观察到这些东西，因此它们
in in empirical studies you never have observations of these things and so they

506
00:16:58,480 --> 00:16:58,490
在实证研究中，您永远不会观察到这些东西，因此它们
observations of these things and so they take on the role of latent variables

507
00:16:58,490 --> 00:17:00,850
承担潜在变量的角色，这使它们很难处理
observations of these things and so they take on the role of latent variables

508
00:17:00,850 --> 00:17:03,160
承担潜在变量的角色，这使它们很难处理
take on the role of latent variables which makes them very difficult to deal

509
00:17:03,160 --> 00:17:03,170
承担潜在变量的角色，这使它们很难处理
which makes them very difficult to deal with and the way to interpret the

510
00:17:03,170 --> 00:17:05,710
解释外部输入的方法通常在皮质中
which makes them very difficult to deal with and the way to interpret the

511
00:17:05,710 --> 00:17:08,050
解释外部输入的方法通常在皮质中
with and the way to interpret the external inputs is typically in cortex

512
00:17:08,050 --> 00:17:08,060
解释外部输入的方法通常在皮质中
external inputs is typically in cortex you have multiple recurrent layers where

513
00:17:08,060 --> 00:17:11,829
您有多个循环层，其中一个主题的前馈可提供
external inputs is typically in cortex you have multiple recurrent layers where

514
00:17:11,829 --> 00:17:15,160
您有多个循环层，其中一个主题的前馈可提供
you have multiple recurrent layers where one subject's feed-forward offers

515
00:17:15,160 --> 00:17:15,170
您有多个循环层，其中一个主题的前馈可提供
one subject's feed-forward offers heapsort projections onto the other

516
00:17:15,170 --> 00:17:19,370
堆排序投射到另一个上，通常只是兴奋性的
one subject's feed-forward offers heapsort projections onto the other

517
00:17:19,370 --> 00:17:21,769
堆排序投射到另一个上，通常只是兴奋性的
heapsort projections onto the other and typically it's only excitatory

518
00:17:21,769 --> 00:17:21,779
堆排序投射到另一个上，通常只是兴奋性的
and typically it's only excitatory neurons that do that as well so they

519
00:17:21,779 --> 00:17:25,730
神经元也这样做，因此它们承担了潜在变量的作用，
and typically it's only excitatory neurons that do that as well so they

520
00:17:25,730 --> 00:17:27,529
神经元也这样做，因此它们承担了潜在变量的作用，
neurons that do that as well so they take on the role of latent variables and

521
00:17:27,529 --> 00:17:27,539
神经元也这样做，因此它们承担了潜在变量的作用，
take on the role of latent variables and so you can update the FTEs and

522
00:17:27,539 --> 00:17:29,450
因此，您可以按照以下方式更新FTE和过渡模型：添加一个
take on the role of latent variables and so you can update the FTEs and

523
00:17:29,450 --> 00:17:31,700
因此，您可以按照以下方式更新FTE和过渡模型：添加一个
so you can update the FTEs and transition models as follows you add a

524
00:17:31,700 --> 00:17:31,710
因此，您可以按照以下方式更新FTE和过渡模型：添加一个
transition models as follows you add a mean drive from some external adjacent

525
00:17:31,710 --> 00:17:34,970
是指我们从某些外部邻近地点驱车而来，因此教堂非常相似
transition models as follows you add a mean drive from some external adjacent

526
00:17:34,970 --> 00:17:36,860
是指我们从某些外部邻近地点驱车而来，因此教堂非常相似
mean drive from some external adjacent we made church so it's very similar in

527
00:17:36,860 --> 00:17:36,870
是指我们从某些外部邻近地点驱车而来，因此教堂非常相似
we made church so it's very similar in structure to the recurrent but typically

528
00:17:36,870 --> 00:17:40,070
经常性的结构，但通常是矩形，您通常可以
we made church so it's very similar in structure to the recurrent but typically

529
00:17:40,070 --> 00:17:41,840
经常性的结构，但通常是矩形，您通常可以
structure to the recurrent but typically rectangular could you typically have

530
00:17:41,840 --> 00:17:41,850
经常性的结构，但通常是矩形，您通常可以
rectangular could you typically have more or less number of neurons and then

531
00:17:41,850 --> 00:17:45,590
或多或少的神经元数量，然后您现在还具有相关的噪声项
rectangular could you typically have more or less number of neurons and then

532
00:17:45,590 --> 00:17:49,539
或多或少的神经元数量，然后您现在还具有相关的噪声项
more or less number of neurons and then you also now have correlated noise terms

533
00:17:49,539 --> 00:17:49,549
或多或少的神经元数量，然后您现在还具有相关的噪声项
you also now have correlated noise terms where B is the trusty decomposition of

534
00:17:49,549 --> 00:17:52,700
其中B是外部协方差矩阵gamma的可信赖分解
you also now have correlated noise terms where B is the trusty decomposition of

535
00:17:52,700 --> 00:17:56,840
其中B是外部协方差矩阵gamma的可信赖分解
where B is the trusty decomposition of the external covariance matrix gamma and

536
00:17:56,840 --> 00:17:56,850
其中B是外部协方差矩阵gamma的可信赖分解
the external covariance matrix gamma and so there's been some proposals on the

537
00:17:56,850 --> 00:17:59,990
所以关于文学的一些建议至少可以在
the external covariance matrix gamma and so there's been some proposals on the

538
00:17:59,990 --> 00:18:02,299
所以关于文学的一些建议至少可以在
so there's been some proposals on the literature that you can at least in the

539
00:18:02,299 --> 00:18:02,309
所以关于文学的一些建议至少可以在
literature that you can at least in the case of low rank external input where

540
00:18:02,309 --> 00:18:04,850
低级外部输入的情况下，您只有少量神经元
literature that you can at least in the case of low rank external input where

541
00:18:04,850 --> 00:18:07,039
低级外部输入的情况下，您只有少量神经元
case of low rank external input where you just have a handful of neurons in

542
00:18:07,039 --> 00:18:07,049
低级外部输入的情况下，您只有少量神经元
you just have a handful of neurons in the external population there there's

543
00:18:07,049 --> 00:18:09,350
有人建议您可以使用高斯
you just have a handful of neurons in the external population there there's

544
00:18:09,350 --> 00:18:10,999
有人建议您可以使用高斯
the external population there there's been proposed that you can use Gaussian

545
00:18:10,999 --> 00:18:11,009
有人建议您可以使用高斯
been proposed that you can use Gaussian process factor analysis to fit those

546
00:18:11,009 --> 00:18:14,419
过程因子分析以适合那些照明尺寸，并且应该
been proposed that you can use Gaussian process factor analysis to fit those

547
00:18:14,419 --> 00:18:17,269
过程因子分析以适合那些照明尺寸，并且应该
process factor analysis to fit those lighting dimensions and that should

548
00:18:17,269 --> 00:18:17,279
过程因子分析以适合那些照明尺寸，并且应该
lighting dimensions and that should improve your estimate unfortunately I

549
00:18:17,279 --> 00:18:18,919
不幸的是我提高了您的估计
lighting dimensions and that should improve your estimate unfortunately I

550
00:18:18,919 --> 00:18:21,049
不幸的是我提高了您的估计
improve your estimate unfortunately I tried and tried and tried to get this to

551
00:18:21,049 --> 00:18:21,059
不幸的是我提高了您的估计
tried and tried and tried to get this to work unfortunately it appears is it

552
00:18:21,059 --> 00:18:23,749
不幸的是，如果使用GP FA的话，它是否适合该过程？
tried and tried and tried to get this to work unfortunately it appears is it

553
00:18:23,749 --> 00:18:27,289
不幸的是，如果使用GP FA的话，它是否适合该过程？
work unfortunately it appears is it using GP FA over fits the process if

554
00:18:27,289 --> 00:18:27,299
不幸的是，如果使用GP FA的话，它是否适合该过程？
using GP FA over fits the process if it's not only the latent variables but

555
00:18:27,299 --> 00:18:29,690
不仅是潜在变量，还有一些有价值的信息
using GP FA over fits the process if it's not only the latent variables but

556
00:18:29,690 --> 00:18:31,759
不仅是潜在变量，还有一些有价值的信息
it's not only the latent variables but some of the valuable information from

557
00:18:31,759 --> 00:18:31,769
不仅是潜在变量，还有一些有价值的信息
some of the valuable information from the stochastic process itself and so he

558
00:18:31,769 --> 00:18:35,180
随机过程本身，所以他写了C Grasso用于残差
some of the valuable information from the stochastic process itself and so he

559
00:18:35,180 --> 00:18:38,860
随机过程本身，所以他写了C Grasso用于残差
the stochastic process itself and so he written C Grasso used on the residuals

560
00:18:38,860 --> 00:18:38,870
随机过程本身，所以他写了C Grasso用于残差
written C Grasso used on the residuals before and after an application of GP FA

561
00:18:38,870 --> 00:18:42,169
在应用GP FA之前和之后以及GP FA的过度装配导致
written C Grasso used on the residuals before and after an application of GP FA

562
00:18:42,169 --> 00:18:45,169
在应用GP FA之前和之后以及GP FA的过度装配导致
before and after an application of GP FA and the overfitting from GP FA causes it

563
00:18:45,169 --> 00:18:45,179
在应用GP FA之前和之后以及GP FA的过度装配导致
and the overfitting from GP FA causes it to decay a little lower it's also very

564
00:18:45,179 --> 00:18:50,690
衰减得更低一点对于大型网络来说，算法也非常慢
and the overfitting from GP FA causes it to decay a little lower it's also very

565
00:18:50,690 --> 00:18:53,379
衰减得更低一点对于大型网络来说，算法也非常慢
to decay a little lower it's also very very slow algorithms for larger networks

566
00:18:53,379 --> 00:18:53,389
衰减得更低一点对于大型网络来说，算法也非常慢
very slow algorithms for larger networks so it's not considered practical

567
00:18:53,389 --> 00:18:56,389
因此目前尚不实用
very slow algorithms for larger networks so it's not considered practical

568
00:18:56,389 --> 00:18:58,820
因此目前尚不实用
so it's not considered practical currently

569
00:18:58,820 --> 00:18:58,830
因此目前尚不实用
currently okay and a quick note the problem at

570
00:18:58,830 --> 00:19:02,450
好的，快速注意一下，至少持续平均上升的问题可以
currently okay and a quick note the problem at

571
00:19:02,450 --> 00:19:05,060
好的，快速注意一下，至少持续平均上升的问题可以
okay and a quick note the problem at least of having a mean constant rise can

572
00:19:05,060 --> 00:19:05,070
好的，快速注意一下，至少持续平均上升的问题可以
least of having a mean constant rise can be solved in the context of a linear

573
00:19:05,070 --> 00:19:06,560
在线性动力系统中解决，这是一个荷马问题
least of having a mean constant rise can be solved in the context of a linear

574
00:19:06,560 --> 00:19:09,860
在线性动力系统中解决，这是一个荷马问题
be solved in the context of a linear dynamical system this is a Homer problem

575
00:19:09,860 --> 00:19:09,870
在线性动力系统中解决，这是一个荷马问题
dynamical system this is a Homer problem and vicious machine learning books

576
00:19:09,870 --> 00:19:12,010
和恶意机器学习书籍第13部分，基本上，您只需添加一些
dynamical system this is a Homer problem and vicious machine learning books

577
00:19:12,010 --> 00:19:15,590
和恶意机器学习书籍第13部分，基本上，您只需添加一些
and vicious machine learning books section 13 basically you just add some

578
00:19:15,590 --> 00:19:15,600
和恶意机器学习书籍第13部分，基本上，您只需添加一些
section 13 basically you just add some additional rows to your hidden States

579
00:19:15,600 --> 00:19:18,770
隐藏状态的其他行现在可以统一解决，可以吸收
section 13 basically you just add some additional rows to your hidden States

580
00:19:18,770 --> 00:19:21,440
隐藏状态的其他行现在可以统一解决，可以吸收
additional rows to your hidden States fix them at unity now you can absorb

581
00:19:21,440 --> 00:19:21,450
隐藏状态的其他行现在可以统一解决，可以吸收
fix them at unity now you can absorb additional columns as the main input

582
00:19:21,450 --> 00:19:25,270
额外的列作为新网络W的主要输入，
fix them at unity now you can absorb additional columns as the main input

583
00:19:25,270 --> 00:19:28,820
额外的列作为新网络W的主要输入，
additional columns as the main input onto your new network W and that

584
00:19:28,820 --> 00:19:28,830
额外的列作为新网络W的主要输入，
onto your new network W and that districts the whole problem but your ovm

585
00:19:28,830 --> 00:19:31,520
确定整个问题所在，但您的ovm估计仍然可以
onto your new network W and that districts the whole problem but your ovm

586
00:19:31,520 --> 00:19:34,570
确定整个问题所在，但您的ovm估计仍然可以
districts the whole problem but your ovm estimates would still be perfectly fine

587
00:19:34,570 --> 00:19:34,580
确定整个问题所在，但您的ovm估计仍然可以
estimates would still be perfectly fine unfortunately it doesn't appear to work

588
00:19:34,580 --> 00:19:37,940
不幸的是，它似乎也不起作用，我们将解释为什么
estimates would still be perfectly fine unfortunately it doesn't appear to work

589
00:19:37,940 --> 00:19:40,880
不幸的是，它似乎也不起作用，我们将解释为什么
unfortunately it doesn't appear to work either and we'll explain why in just a

590
00:19:40,880 --> 00:19:40,890
不幸的是，它似乎也不起作用，我们将解释为什么
either and we'll explain why in just a second okay we're back to the level

591
00:19:40,890 --> 00:19:42,650
其次，我们回到了拥有成千上万数据的水平
either and we'll explain why in just a second okay we're back to the level

592
00:19:42,650 --> 00:19:44,930
其次，我们回到了拥有成千上万数据的水平
second okay we're back to the level where we have tens of thousands of data

593
00:19:44,930 --> 00:19:44,940
其次，我们回到了拥有成千上万数据的水平
where we have tens of thousands of data samples so they should be doing better

594
00:19:44,940 --> 00:19:46,520
样本，所以他们应该做得更好，但是不是
where we have tens of thousands of data samples so they should be doing better

595
00:19:46,520 --> 00:19:49,040
样本，所以他们应该做得更好，但是不是
samples so they should be doing better right but they're not this is in the

596
00:19:49,040 --> 00:19:49,050
样本，所以他们应该做得更好，但是不是
right but they're not this is in the presence of external input Hackney has a

597
00:19:49,050 --> 00:19:51,350
外部输入的存在哈克尼有一个潜在变量，所以为什么不
right but they're not this is in the presence of external input Hackney has a

598
00:19:51,350 --> 00:19:55,250
外部输入的存在哈克尼有一个潜在变量，所以为什么不
presence of external input Hackney has a latent variables and so why is not a

599
00:19:55,250 --> 00:19:55,260
外部输入的存在哈克尼有一个潜在变量，所以为什么不
latent variables and so why is not a single measure giving us good influence

600
00:19:55,260 --> 00:19:57,950
单项措施能给我们带来良好的影响，这是因为我们现在受到偏见
latent variables and so why is not a single measure giving us good influence

601
00:19:57,950 --> 00:20:02,560
单项措施能给我们带来良好的影响，这是因为我们现在受到偏见
single measure giving us good influence it's because we are now receiving biased

602
00:20:02,560 --> 00:20:02,570
单项措施能给我们带来良好的影响，这是因为我们现在受到偏见
it's because we are now receiving biased external input covariance that in fact

603
00:20:02,570 --> 00:20:05,450
实际上与主输入驱动器共享项的外部输入协方差
it's because we are now receiving biased external input covariance that in fact

604
00:20:05,450 --> 00:20:08,210
实际上与主输入驱动器共享项的外部输入协方差
external input covariance that in fact shares terms with the main input drive

605
00:20:08,210 --> 00:20:08,220
实际上与主输入驱动器共享项的外部输入协方差
shares terms with the main input drive so at least expectation-maximization you

606
00:20:08,220 --> 00:20:11,180
所以至少要期望最大化，您现在必须完全重做最后一步
shares terms with the main input drive so at least expectation-maximization you

607
00:20:11,180 --> 00:20:14,030
所以至少要期望最大化，您现在必须完全重做最后一步
so at least expectation-maximization you have to completely redo the end step now

608
00:20:14,030 --> 00:20:14,040
所以至少要期望最大化，您现在必须完全重做最后一步
have to completely redo the end step now I've tried to do this analytically

609
00:20:14,040 --> 00:20:16,120
不幸的是，我尝试过分析这一点，其中有一个特定的部分
have to completely redo the end step now I've tried to do this analytically

610
00:20:16,120 --> 00:20:18,850
不幸的是，我尝试过分析这一点，其中有一个特定的部分
I've tried to do this analytically unfortunately there is one specific part

611
00:20:18,850 --> 00:20:18,860
不幸的是，我尝试过分析这一点，其中有一个特定的部分
unfortunately there is one specific part that is essentially intractable and so

612
00:20:18,860 --> 00:20:22,430
这本质上是棘手的，所以您需要实施概括
unfortunately there is one specific part that is essentially intractable and so

613
00:20:22,430 --> 00:20:23,840
这本质上是棘手的，所以您需要实施概括
that is essentially intractable and so you would need to implement generalize

614
00:20:23,840 --> 00:20:23,850
这本质上是棘手的，所以您需要实施概括
you would need to implement generalize DM to a box made a local pollution but

615
00:20:23,850 --> 00:20:29,720
DM到盒子里造成了局部污染，但现在通常没有其他措施
you would need to implement generalize DM to a box made a local pollution but

616
00:20:29,720 --> 00:20:31,400
DM到盒子里造成了局部污染，但现在通常没有其他措施
DM to a box made a local pollution but now generally none of the other measures

617
00:20:31,400 --> 00:20:31,410
DM到盒子里造成了局部污染，但现在通常没有其他措施
now generally none of the other measures work well either sample precision

618
00:20:31,410 --> 00:20:33,880
样本精度协方差都很好，即使它们都不适合
now generally none of the other measures work well either sample precision

619
00:20:33,880 --> 00:20:37,160
样本精度协方差都很好，即使它们都不适合
work well either sample precision covariance even they are fit none of

620
00:20:37,160 --> 00:20:37,170
样本精度协方差都很好，即使它们都不适合
covariance even they are fit none of them did a good job because they're all

621
00:20:37,170 --> 00:20:38,990
他们做得很好，因为它们在某种程度上都具有精度的功能
covariance even they are fit none of them did a good job because they're all

622
00:20:38,990 --> 00:20:42,140
他们做得很好，因为它们在某种程度上都具有精度的功能
them did a good job because they're all somehow functions of the precision for

623
00:20:42,140 --> 00:20:42,150
他们做得很好，因为它们在某种程度上都具有精度的功能
somehow functions of the precision for this process which in the presence of an

624
00:20:42,150 --> 00:20:44,570
在有外部输入的情况下进行以下过程的过程
somehow functions of the precision for this process which in the presence of an

625
00:20:44,570 --> 00:20:47,630
在有外部输入的情况下进行以下过程的过程
this process which in the presence of an external input takes on the following

626
00:20:47,630 --> 00:20:47,640
在有外部输入的情况下进行以下过程的过程
external input takes on the following form where you have additive terms going

627
00:20:47,640 --> 00:20:49,520
从外部输入协方差得到附加项的表格
external input takes on the following form where you have additive terms going

628
00:20:49,520 --> 00:20:51,500
从外部输入协方差得到附加项的表格
form where you have additive terms going from the external input covariance and

629
00:20:51,500 --> 00:20:51,510
从外部输入协方差得到附加项的表格
from the external input covariance and remember this is the part that gives us

630
00:20:51,510 --> 00:20:53,150
记住这是给我们两个一对一关系的部分
from the external input covariance and remember this is the part that gives us

631
00:20:53,150 --> 00:20:55,100
记住这是给我们两个一对一关系的部分
remember this is the part that gives us two one-to-one relationship with

632
00:20:55,100 --> 00:20:55,110
记住这是给我们两个一对一关系的部分
two one-to-one relationship with bi-directional network connectivity it's

633
00:20:55,110 --> 00:20:58,070
双向网络连接，现在所有设备都在争先恐后地进行投影。
two one-to-one relationship with bi-directional network connectivity it's

634
00:20:58,070 --> 00:21:00,410
双向网络连接，现在所有设备都在争先恐后地进行投影。
bi-directional network connectivity it's now being scrambled projected in all

635
00:21:00,410 --> 00:21:00,420
双向网络连接，现在所有设备都在争先恐后地进行投影。
now being scrambled projected in all sorts of different directions by the XR

636
00:21:00,420 --> 00:21:02,570
XR 1的各种不同方向的协方差，您也得到了
now being scrambled projected in all sorts of different directions by the XR

637
00:21:02,570 --> 00:21:04,220
XR 1的各种不同方向的协方差，您也得到了
sorts of different directions by the XR 1 for covariance and you're also getting

638
00:21:04,220 --> 00:21:04,230
XR 1的各种不同方向的协方差，您也得到了
1 for covariance and you're also getting more very

639
00:21:04,230 --> 00:21:05,030
从三重乘积项来看，更多的是
1 for covariance and you're also getting more very

640
00:21:05,030 --> 00:21:07,700
从三重乘积项来看，更多的是
more very from the triple product term so it's

641
00:21:07,700 --> 00:21:07,710
从三重乘积项来看，更多的是
from the triple product term so it's just not a good problem and then yeah I

642
00:21:07,710 --> 00:21:12,170
只是不是一个好问题，然后是的，我才刚刚开始获得系统
from the triple product term so it's just not a good problem and then yeah I

643
00:21:12,170 --> 00:21:14,360
只是不是一个好问题，然后是的，我才刚刚开始获得系统
just not a good problem and then yeah I just we just started to get systems

644
00:21:14,360 --> 00:21:14,370
只是不是一个好问题，然后是的，我才刚刚开始获得系统
just we just started to get systems we're going a little faster today quick

645
00:21:14,370 --> 00:21:17,840
今天我们要快一点，快速将我的合作伙伴插入其中
just we just started to get systems we're going a little faster today quick

646
00:21:17,840 --> 00:21:19,880
今天我们要快一点，快速将我的合作伙伴插入其中
we're going a little faster today quick plug my collaborators on a lot of this

647
00:21:19,880 --> 00:21:19,890
今天我们要快一点，快速将我的合作伙伴插入其中
plug my collaborators on a lot of this research at Rice University in Houston

648
00:21:19,890 --> 00:21:22,520
休斯敦莱斯大学的研究由Ginevra Allen实验室负责
plug my collaborators on a lot of this research at Rice University in Houston

649
00:21:22,520 --> 00:21:25,640
休斯敦莱斯大学的研究由Ginevra Allen实验室负责
research at Rice University in Houston is headed by the lab of Ginevra Allen

650
00:21:25,640 --> 00:21:25,650
休斯敦莱斯大学的研究由Ginevra Allen实验室负责
is headed by the lab of Ginevra Allen they were exploring a couple other cases

651
00:21:25,650 --> 00:21:27,920
他们正在探索其他一些时间依赖性的案例，这些案例确实
is headed by the lab of Ginevra Allen they were exploring a couple other cases

652
00:21:27,920 --> 00:21:29,540
他们正在探索其他一些时间依赖性的案例，这些案例确实
they were exploring a couple other cases of time dependence which are really

653
00:21:29,540 --> 00:21:29,550
他们正在探索其他一些时间依赖性的案例，这些案例确实
of time dependence which are really interesting that I don't have to talk

654
00:21:29,550 --> 00:21:32,270
有趣的是，我不必在接下来的演讲中谈论
of time dependence which are really interesting that I don't have to talk

655
00:21:32,270 --> 00:21:35,210
有趣的是，我不必在接下来的演讲中谈论
interesting that I don't have to talk about just as an upcoming talk next

656
00:21:35,210 --> 00:21:35,220
有趣的是，我不必在接下来的演讲中谈论
about just as an upcoming talk next Friday May 4th that's a part of a team

657
00:21:35,220 --> 00:21:38,210
5月4日，星期五，这是团队讨论会的一部分，但我认为这是
about just as an upcoming talk next Friday May 4th that's a part of a team

658
00:21:38,210 --> 00:21:39,590
5月4日，星期五，这是团队讨论会的一部分，但我认为这是
Friday May 4th that's a part of a team that's colloquium but I think it's

659
00:21:39,590 --> 00:21:39,600
5月4日，星期五，这是团队讨论会的一部分，但我认为这是
that's colloquium but I think it's sponsored by IBM he really goes there

660
00:21:39,600 --> 00:21:42,950
在IBM的赞助下，他真的很感兴趣与高水平的人打交道。
that's colloquium but I think it's sponsored by IBM he really goes there

661
00:21:42,950 --> 00:21:43,910
在IBM的赞助下，他真的很感兴趣与高水平的人打交道。
sponsored by IBM he really goes there interested in dealing with high

662
00:21:43,910 --> 00:21:43,920
在IBM的赞助下，他真的很感兴趣与高水平的人打交道。
interested in dealing with high dimensional data as she does a lot of

663
00:21:43,920 --> 00:21:45,410
维度数据，因为她做了很多其他项目和生物统计学而不是
interested in dealing with high dimensional data as she does a lot of

664
00:21:45,410 --> 00:21:48,950
维度数据，因为她做了很多其他项目和生物统计学而不是
dimensional data as she does a lot of other projects and biostatistics not

665
00:21:48,950 --> 00:21:48,960
维度数据，因为她做了很多其他项目和生物统计学而不是
other projects and biostatistics not just neuroscience and so here are many

666
00:21:48,960 --> 00:21:52,610
只是神经科学，所以这里有许多其他参考资料允许
other projects and biostatistics not just neuroscience and so here are many

667
00:21:52,610 --> 00:21:54,110
只是神经科学，所以这里有许多其他参考资料允许
just neuroscience and so here are many other references that allow this is

668
00:21:54,110 --> 00:21:54,120
只是神经科学，所以这里有许多其他参考资料允许
other references that allow this is based on the first two were kind of

669
00:21:54,120 --> 00:21:57,170
基于前两个是艾伦（Allen）的联合出版物，这是
other references that allow this is based on the first two were kind of

670
00:21:57,170 --> 00:22:00,230
基于前两个是艾伦（Allen）的联合出版物，这是
based on the first two were kind of joint publications by Allen and this is

671
00:22:00,230 --> 00:22:00,240
基于前两个是艾伦（Allen）的联合出版物，这是
joint publications by Allen and this is just a general background on the problem

672
00:22:00,240 --> 00:22:02,870
只是关于这个问题的一般背景，而只是要谈论
joint publications by Allen and this is just a general background on the problem

673
00:22:02,870 --> 00:22:04,880
只是关于这个问题的一般背景，而只是要谈论
just a general background on the problem in general and simply gonna talk about

674
00:22:04,880 --> 00:22:04,890
只是关于这个问题的一般背景，而只是要谈论
in general and simply gonna talk about GL and say if you want to learn more

675
00:22:04,890 --> 00:22:06,890
GL，如果您想了解更多有关什么基因组可以提供任何信息的信息，
in general and simply gonna talk about GL and say if you want to learn more

676
00:22:06,890 --> 00:22:09,200
GL，如果您想了解更多有关什么基因组可以提供任何信息的信息，
GL and say if you want to learn more about what genomes can offer any

677
00:22:09,200 --> 00:22:09,210
GL，如果您想了解更多有关什么基因组可以提供任何信息的信息，
about what genomes can offer any publication hospital lab is the way to

678
00:22:09,210 --> 00:22:11,060
出版物医院实验室是工作的一种方式，它的工作受到多个方面的支持
about what genomes can offer any publication hospital lab is the way to

679
00:22:11,060 --> 00:22:14,360
出版物医院实验室是工作的一种方式，它的工作受到多个方面的支持
publication hospital lab is the way to go it's work is supported under multiple

680
00:22:14,360 --> 00:22:14,370
出版物医院实验室是工作的一种方式，它的工作受到多个方面的支持
go it's work is supported under multiple NSF grants not like to thank everyone in

681
00:22:14,370 --> 00:22:16,880
NSF赠款不希望感谢Rosenbaum实验室中的每个人对
go it's work is supported under multiple NSF grants not like to thank everyone in

682
00:22:16,880 --> 00:22:18,530
NSF赠款不希望感谢Rosenbaum实验室中的每个人对
NSF grants not like to thank everyone in the Rosenbaum lab for their feedback on

683
00:22:18,530 --> 00:22:18,540
NSF赠款不希望感谢Rosenbaum实验室中的每个人对
the Rosenbaum lab for their feedback on the early versions of this presentation

684
00:22:18,540 --> 00:22:20,470
此演示文稿的早期版本，非常感谢您的收听，您呢？
the Rosenbaum lab for their feedback on the early versions of this presentation

685
00:22:20,470 --> 00:22:22,730
此演示文稿的早期版本，非常感谢您的收听，您呢？
the early versions of this presentation so thank you for listening and do you

686
00:22:22,730 --> 00:22:22,740
此演示文稿的早期版本，非常感谢您的收听，您呢？
so thank you for listening and do you have any questions

687
00:22:22,740 --> 00:22:25,430
有任何疑问
so thank you for listening and do you have any questions

688
00:22:25,430 --> 00:22:37,480
是的
so thank you for listening and do you have any questions

689
00:22:37,480 --> 00:22:37,490
是的


690
00:22:37,490 --> 00:22:40,090
是的
yes

691
00:22:40,090 --> 00:22:40,460
好吧，所以他都问我要看多少个神经元，所以我看了beta
yes

692
00:22:40,460 --> 00:22:40,470
好吧，所以他都问我要看多少个神经元，所以我看了beta


693
00:22:40,470 --> 00:22:47,090
好吧，所以他都问我要看多少个神经元，所以我看了beta
okay so everything he asked how many neurons do I look at so I looked at beta

694
00:22:47,090 --> 00:22:47,100
好吧，所以他都问我要看多少个神经元，所以我看了beta
neurons do I look at so I looked at beta test containing hundreds but everything

695
00:22:47,100 --> 00:22:51,140
测试包含数百个，但您在此演示文稿中看到的所有内容均为30
neurons do I look at so I looked at beta test containing hundreds but everything

696
00:22:51,140 --> 00:22:54,680
测试包含数百个，但您在此演示文稿中看到的所有内容均为30
test containing hundreds but everything you saw in this presentation had was 30

697
00:22:54,680 --> 00:22:54,690
测试包含数百个，但您在此演示文稿中看到的所有内容均为30
you saw in this presentation had was 30 so very small Network now I have with

698
00:22:54,690 --> 00:22:58,160
现在我的网络非常小，有成千上万个神经元插头
you saw in this presentation had was 30 so very small Network now I have with

699
00:22:58,160 --> 00:23:01,640
现在我的网络非常小，有成千上万个神经元插头
so very small Network now I have with that hundreds and thousands plug neuron

700
00:23:01,640 --> 00:23:01,650
现在我的网络非常小，有成千上万个神经元插头
that hundreds and thousands plug neuron of neurons in the context of in silico

701
00:23:01,650 --> 00:23:04,400
计算机模拟中神经元的数量，而您唯一的是
that hundreds and thousands plug neuron of neurons in the context of in silico

702
00:23:04,400 --> 00:23:09,050
计算机模拟中神经元的数量，而您唯一的是
of neurons in the context of in silico modeling and you the only thing is it's

703
00:23:09,050 --> 00:23:09,060
计算机模拟中神经元的数量，而您唯一的是
modeling and you the only thing is it's harder to get really clear results to

704
00:23:09,060 --> 00:23:12,380
很难获得真正清晰的结果，以表明您可以提高
modeling and you the only thing is it's harder to get really clear results to

705
00:23:12,380 --> 00:23:15,110
很难获得真正清晰的结果，以表明您可以提高
harder to get really clear results to show you you can crank up the data that

706
00:23:15,110 --> 00:23:15,120
很难获得真正清晰的结果，以表明您可以提高
show you you can crank up the data that you feed the model do really like

707
00:23:15,120 --> 00:23:17,510
您提供的模型确实确实像数百万个数据点，那就是
show you you can crank up the data that you feed the model do really like

708
00:23:17,510 --> 00:23:19,640
您提供的模型确实确实像数百万个数据点，那就是
you feed the model do really like millions of data points and that's

709
00:23:19,640 --> 00:23:19,650
您提供的模型确实确实像数百万个数据点，那就是
millions of data points and that's what's required to get really good

710
00:23:19,650 --> 00:23:20,930
要获得一生中真正好的推论，您需要什么？
millions of data points and that's what's required to get really good

711
00:23:20,930 --> 00:23:23,420
要获得一生中真正好的推论，您需要什么？
what's required to get really good inference for life you know a thousand

712
00:23:23,420 --> 00:23:23,430
要获得一生中真正好的推论，您需要什么？
inference for life you know a thousand neurons or something like that so yeah I

713
00:23:23,430 --> 00:23:27,110
神经元之类的东西，所以是的，我看着这个很小的网络
inference for life you know a thousand neurons or something like that so yeah I

714
00:23:27,110 --> 00:23:30,320
神经元之类的东西，所以是的，我看着这个很小的网络
neurons or something like that so yeah I looked at fairly small networks in this

715
00:23:30,320 --> 00:23:30,330
神经元之类的东西，所以是的，我看着这个很小的网络
looked at fairly small networks in this context but the goal is to develop

716
00:23:30,330 --> 00:23:35,060
上下文，但目标是开发方法，但有其原因
looked at fairly small networks in this context but the goal is to develop

717
00:23:35,060 --> 00:23:37,040
上下文，但目标是开发方法，但有其原因
context but the goal is to develop methods but there the reason there is

718
00:23:37,040 --> 00:23:37,050
上下文，但目标是开发方法，但有其原因
methods but there the reason there is computational time glosso doesn't even

719
00:23:37,050 --> 00:23:41,300
如果您有几个以上的时间，那么计算时间的词汇表甚至无法收敛
methods but there the reason there is computational time glosso doesn't even

720
00:23:41,300 --> 00:23:44,300
如果您有几个以上的时间，那么计算时间的词汇表甚至无法收敛
computational time glosso doesn't even converge if you have more than a few

721
00:23:44,300 --> 00:23:44,310
如果您有几个以上的时间，那么计算时间的词汇表甚至无法收敛
converge if you have more than a few hundred neurons there's a certain step

722
00:23:44,310 --> 00:23:46,400
一百个神经元套索算法中有一个特定步骤
converge if you have more than a few hundred neurons there's a certain step

723
00:23:46,400 --> 00:23:48,290
一百个神经元套索算法中有一个特定步骤
hundred neurons there's a certain step in the lasso algorithm where you have to

724
00:23:48,290 --> 00:23:48,300
一百个神经元套索算法中有一个特定步骤
in the lasso algorithm where you have to do a kind of shooting thing and it just

725
00:23:48,300 --> 00:23:52,280
做一种射击的事情，如果你不收敛就需要永远
in the lasso algorithm where you have to do a kind of shooting thing and it just

726
00:23:52,280 --> 00:23:55,400
做一种射击的事情，如果你不收敛就需要永远
do a kind of shooting thing and it just it takes forever to not converge if you

727
00:23:55,400 --> 00:23:55,410
做一种射击的事情，如果你不收敛就需要永远
it takes forever to not converge if you have a few hundred neurons and very

728
00:23:55,410 --> 00:23:57,500
有几百个神经元和非常少量的数据
it takes forever to not converge if you have a few hundred neurons and very

729
00:23:57,500 --> 00:24:00,350
有几百个神经元和非常少量的数据
have a few hundred neurons and very small amounts of data

730
00:24:00,350 --> 00:24:00,549
但希望是有一天，我们会花所有的方法来解决这种情况
have a few hundred neurons and very small amounts of data

731
00:24:00,549 --> 00:24:00,559
但希望是有一天，我们会花所有的方法来解决这种情况


732
00:24:00,559 --> 00:24:05,769
但希望是有一天，我们会花所有的方法来解决这种情况
but the hope is to one day spend all of our methods to the case where we can

733
00:24:05,769 --> 00:24:05,779
但希望是有一天，我们会花所有的方法来解决这种情况
our methods to the case where we can look at tens of thousands simultaneously

734
00:24:05,779 --> 00:24:07,899
同时看成千上万，仍然执行此级别的
our methods to the case where we can look at tens of thousands simultaneously

735
00:24:07,899 --> 00:24:09,970
同时看成千上万，仍然执行此级别的
look at tens of thousands simultaneously and still perform this level of

736
00:24:09,970 --> 00:24:09,980
同时看成千上万，仍然执行此级别的
and still perform this level of inference we're just not there yet good

737
00:24:09,980 --> 00:24:12,730
推断我们还不存在好问题，其他的都对，谢谢
and still perform this level of inference we're just not there yet good

738
00:24:12,730 --> 00:24:18,850
推断我们还不存在好问题，其他的都对，谢谢
inference we're just not there yet good question and the others right thank you

739
00:24:18,850 --> 00:25:14,380
大家下午好，我的演讲是关于基于Web的树状结构
inference we're just not there yet good question and the others right thank you

740
00:25:14,380 --> 00:25:14,390
大家下午好，我的演讲是关于基于Web的树状结构


741
00:25:14,390 --> 00:25:19,030
大家下午好，我的演讲是关于基于Web的树状结构
so good afternoon everybody my talk is about web-based tree-structured

742
00:25:19,030 --> 00:25:19,040
大家下午好，我的演讲是关于基于Web的树状结构
about web-based tree-structured compressive sensing with variation of

743
00:25:19,040 --> 00:25:21,190
贝叶斯分析和小波变换的压缩感知
about web-based tree-structured compressive sensing with variation of

744
00:25:21,190 --> 00:25:25,000
贝叶斯分析和小波变换的压缩感知
compressive sensing with variation of Bayesian analysis so and wavelet based

745
00:25:25,000 --> 00:25:25,010
贝叶斯分析和小波变换的压缩感知
Bayesian analysis so and wavelet based transform can be used to decompose a

746
00:25:25,010 --> 00:25:28,210
变换可用于分解我们具有的给定信号或函数
Bayesian analysis so and wavelet based transform can be used to decompose a

747
00:25:28,210 --> 00:25:30,700
变换可用于分解我们具有的给定信号或函数
transform can be used to decompose a given signal or function that we have in

748
00:25:30,700 --> 00:25:30,710
变换可用于分解我们具有的给定信号或函数
given signal or function that we have in terms of some basic functions called

749
00:25:30,710 --> 00:25:33,100
一些称为小波的基本函数的术语，然后我们可以研究这些
given signal or function that we have in terms of some basic functions called

750
00:25:33,100 --> 00:25:37,690
一些称为小波的基本函数的术语，然后我们可以研究这些
terms of some basic functions called wavelets and then we can study these the

751
00:25:37,690 --> 00:25:37,700
一些称为小波的基本函数的术语，然后我们可以研究这些
wavelets and then we can study these the structure of these wavelet coefficients

752
00:25:37,700 --> 00:25:39,520
这些小波系数的结构适合填充我们拥有的数据
wavelets and then we can study these the structure of these wavelet coefficients

753
00:25:39,520 --> 00:25:42,160
这些小波系数的结构适合填充我们拥有的数据
structure of these wavelet coefficients proper to fill data that we have so

754
00:25:42,160 --> 00:25:42,170
这些小波系数的结构适合填充我们拥有的数据
proper to fill data that we have so imagine that we have a signal and we

755
00:25:42,170 --> 00:25:44,530
想象一下，我们有一个信号，然后应用是否在此构成
proper to fill data that we have so imagine that we have a signal and we

756
00:25:44,530 --> 00:25:46,450
想象一下，我们有一个信号，然后应用是否在此构成
imagine that we have a signal and we apply whether the composition on this

757
00:25:46,450 --> 00:25:46,460
想象一下，我们有一个信号，然后应用是否在此构成
apply whether the composition on this the results are two types of data one is

758
00:25:46,460 --> 00:25:49,510
结果是两种类型的数据，一种是缩放系数，另一种是
apply whether the composition on this the results are two types of data one is

759
00:25:49,510 --> 00:25:51,910
结果是两种类型的数据，一种是缩放系数，另一种是
the results are two types of data one is the scaling coefficients the other ones

760
00:25:51,910 --> 00:25:51,920
结果是两种类型的数据，一种是缩放系数，另一种是
the scaling coefficients the other ones are the favorite coefficient scaling

761
00:25:51,920 --> 00:25:55,390
最喜欢的系数缩放系数给出的近似值是
the scaling coefficients the other ones are the favorite coefficient scaling

762
00:25:55,390 --> 00:25:58,360
最喜欢的系数缩放系数给出的近似值是
are the favorite coefficient scaling coefficients give an approximation of

763
00:25:58,360 --> 00:25:58,370
最喜欢的系数缩放系数给出的近似值是
coefficients give an approximation of the function that we have in some lower

764
00:25:58,370 --> 00:26:00,720
我们在较低分辨率的空间中具有的功能
coefficients give an approximation of the function that we have in some lower

765
00:26:00,720 --> 00:26:03,580
我们在较低分辨率的空间中具有的功能
the function that we have in some lower resolution space and the other

766
00:26:03,580 --> 00:26:03,590
我们在较低分辨率的空间中具有的功能
resolution space and the other coefficient provides us with the detail

767
00:26:03,590 --> 00:26:06,040
系数为我们提供了重建原始图像所需的细节
resolution space and the other coefficient provides us with the detail

768
00:26:06,040 --> 00:26:10,090
系数为我们提供了重建原始图像所需的细节
coefficient provides us with the detail that we need to reconstruct the original

769
00:26:10,090 --> 00:26:10,100
系数为我们提供了重建原始图像所需的细节
that we need to reconstruct the original data that we have from those that

770
00:26:10,100 --> 00:26:12,430
从这些近似数据中得到的数据现在我们可以应用
that we need to reconstruct the original data that we have from those that

771
00:26:12,430 --> 00:26:15,040
从这些近似数据中得到的数据现在我们可以应用
data that we have from those that approximation now we can apply the

772
00:26:15,040 --> 00:26:15,050
从这些近似数据中得到的数据现在我们可以应用
approximation now we can apply the wavelet decomposition as many at times

773
00:26:15,050 --> 00:26:17,080
小波分解的次数是我们想要的，每次都需要
approximation now we can apply the wavelet decomposition as many at times

774
00:26:17,080 --> 00:26:20,410
小波分解的次数是我们想要的，每次都需要
wavelet decomposition as many at times as we want and each time we need to take

775
00:26:20,410 --> 00:26:20,420
小波分解的次数是我们想要的，每次都需要
as we want and each time we need to take the product mission that we have why the

776
00:26:20,420 --> 00:26:22,360
我们有产品任务，为什么要对此进行合成，然后我们最终
as we want and each time we need to take the product mission that we have why the

777
00:26:22,360 --> 00:26:25,000
我们有产品任务，为什么要对此进行合成，然后我们最终
the product mission that we have why the composition on that and then we end up

778
00:26:25,000 --> 00:26:25,010
我们有产品任务，为什么要对此进行合成，然后我们最终
composition on that and then we end up with another set of reverberate

779
00:26:25,010 --> 00:26:26,770
另一组回响系数甚至更低的分辨率
composition on that and then we end up with another set of reverberate

780
00:26:26,770 --> 00:26:30,040
另一组回响系数甚至更低的分辨率
with another set of reverberate coefficient and even lower resolution of

781
00:26:30,040 --> 00:26:30,050
另一组回响系数甚至更低的分辨率
coefficient and even lower resolution of the approximation so to reconstruct the

782
00:26:30,050 --> 00:26:33,490
近似，以便重建数据，并且
coefficient and even lower resolution of the approximation so to reconstruct the

783
00:26:33,490 --> 00:26:36,760
近似，以便重建数据，并且
the approximation so to reconstruct the data which and

784
00:26:36,760 --> 00:26:38,470
我们可以采用这些开尔文系数并将其与天气情况相加
the approximation so to reconstruct the data which and

785
00:26:38,470 --> 00:26:38,480
我们可以采用这些开尔文系数并将其与天气情况相加


786
00:26:38,480 --> 00:26:45,430
我们可以采用这些开尔文系数并将其与天气情况相加
we can take these Kelvin coefficients and sum them with the weather conditions

787
00:26:45,430 --> 00:26:45,440
我们可以采用这些开尔文系数并将其与天气情况相加
and sum them with the weather conditions that we have for all the levels of

788
00:26:45,440 --> 00:26:48,150
我们具有所有分解水平，并且我们重建了
and sum them with the weather conditions that we have for all the levels of

789
00:26:48,150 --> 00:26:51,480
我们具有所有分解水平，并且我们重建了
that we have for all the levels of decomposition and we reconstruct our

790
00:26:51,480 --> 00:26:51,490
我们具有所有分解水平，并且我们重建了
decomposition and we reconstruct our original data so for most ignores the

791
00:26:51,490 --> 00:26:56,440
原始数据，因此对于大多数人而言，小波系数是不可或缺的
decomposition and we reconstruct our original data so for most ignores the

792
00:26:56,440 --> 00:26:58,480
原始数据，因此对于大多数人而言，小波系数是不可或缺的
original data so for most ignores the wavelet coefficients are part and

793
00:26:58,480 --> 00:26:58,490
原始数据，因此对于大多数人而言，小波系数是不可或缺的
wavelet coefficients are part and they're compressible and that means that

794
00:26:58,490 --> 00:27:01,300
它们是可压缩的，这意味着我们可以将许多豁免设置为零
wavelet coefficients are part and they're compressible and that means that

795
00:27:01,300 --> 00:27:03,250
它们是可压缩的，这意味着我们可以将许多豁免设置为零
they're compressible and that means that we can set to zero many of the waiver

796
00:27:03,250 --> 00:27:03,260
它们是可压缩的，这意味着我们可以将许多豁免设置为零
we can set to zero many of the waiver coefficients that we have many of them

797
00:27:03,260 --> 00:27:05,410
我们拥有许多系数，它们的价值微不足道，我们可以忽略不计
we can set to zero many of the waiver coefficients that we have many of them

798
00:27:05,410 --> 00:27:08,110
我们拥有许多系数，它们的价值微不足道，我们可以忽略不计
coefficients that we have many of them have negligible value and we can neglect

799
00:27:08,110 --> 00:27:08,120
我们拥有许多系数，它们的价值微不足道，我们可以忽略不计
have negligible value and we can neglect them and we can reconstruct the function

800
00:27:08,120 --> 00:27:12,760
他们，我们可以从修改后的小波系数重建函数
have negligible value and we can neglect them and we can reconstruct the function

801
00:27:12,760 --> 00:27:14,890
他们，我们可以从修改后的小波系数重建函数
them and we can reconstruct the function from the modified wavelet coefficients

802
00:27:14,890 --> 00:27:14,900
他们，我们可以从修改后的小波系数重建函数
from the modified wavelet coefficients and end up with a good very accurately

803
00:27:14,900 --> 00:27:21,990
并最终获得非常准确的结果，因为我们拥有的测量
from the modified wavelet coefficients and end up with a good very accurately

804
00:27:21,990 --> 00:27:25,630
并最终获得非常准确的结果，因为我们拥有的测量
and end up with a good very accurately because the measurements that we have

805
00:27:25,630 --> 00:27:25,640
并最终获得非常准确的结果，因为我们拥有的测量
because the measurements that we have might not might not always be easy and

806
00:27:25,640 --> 00:27:29,500
可能并不总是容易且便宜地获取，例如在MRI中
because the measurements that we have might not might not always be easy and

807
00:27:29,500 --> 00:27:32,470
可能并不总是容易且便宜地获取，例如在MRI中
might not might not always be easy and cheap to acquire for example in MRI

808
00:27:32,470 --> 00:27:32,480
可能并不总是容易且便宜地获取，例如在MRI中
cheap to acquire for example in MRI image imaging it's very tedious faster

809
00:27:32,480 --> 00:27:35,980
图像成像非常繁琐，需要耗时的成像
cheap to acquire for example in MRI image imaging it's very tedious faster

810
00:27:35,980 --> 00:27:42,220
图像成像非常繁琐，需要耗时的成像
image imaging it's very tedious faster it's time-consuming imaging we need to

811
00:27:42,220 --> 00:27:42,230
图像成像非常繁琐，需要耗时的成像
it's time-consuming imaging we need to take image in many spiritual bands so

812
00:27:42,230 --> 00:27:44,830
在许多精神团体中拍摄图像，所以人们可能会认为这是有用的方法
it's time-consuming imaging we need to take image in many spiritual bands so

813
00:27:44,830 --> 00:27:48,100
在许多精神团体中拍摄图像，所以人们可能会认为这是有用的方法
take image in many spiritual bands so one might think that it's the useful way

814
00:27:48,100 --> 00:27:48,110
在许多精神团体中拍摄图像，所以人们可能会认为这是有用的方法
one might think that it's the useful way to only measure the informative data

815
00:27:48,110 --> 00:27:55,180
仅测量信息量
one might think that it's the useful way to only measure the informative data

816
00:27:55,180 --> 00:27:57,420
我们需要进行的测量，因此我们假设不可压缩的测试是
one might think that it's the useful way to only measure the informative data

817
00:27:57,420 --> 00:27:57,430
我们需要进行的测量，因此我们假设不可压缩的测试是


818
00:27:57,430 --> 00:28:07,450
我们需要进行的测量，因此我们假设不可压缩的测试是
measurements that we need to have so the incompressible testing we assume that

819
00:28:07,450 --> 00:28:07,460
我们需要进行的测量，因此我们假设不可压缩的测试是
incompressible testing we assume that the signal we have is compressible

820
00:28:07,460 --> 00:28:09,490
我们拥有的信号是可压缩的即时基础，然后我们可以精确地
incompressible testing we assume that the signal we have is compressible

821
00:28:09,490 --> 00:28:15,400
我们拥有的信号是可压缩的即时基础，然后我们可以精确地
the signal we have is compressible instant basis and then we can exactly we

822
00:28:15,400 --> 00:28:15,410
我们拥有的信号是可压缩的即时基础，然后我们可以精确地
instant basis and then we can exactly we construct the originals are underlying

823
00:28:15,410 --> 00:28:18,040
构造原始信号是具有多个
instant basis and then we can exactly we construct the originals are underlying

824
00:28:18,040 --> 00:28:20,440
构造原始信号是具有多个
construct the originals are underlying original signal with a number of

825
00:28:20,440 --> 00:28:20,450
构造原始信号是具有多个
original signal with a number of appropriately designed projected

826
00:28:20,450 --> 00:28:22,630
经过适当设计的投影测量，我们可以成为
original signal with a number of appropriately designed projected

827
00:28:22,630 --> 00:28:33,880
经过适当设计的投影测量，我们可以成为
appropriately designed projected measurement and we can be theta where

828
00:28:33,880 --> 00:28:33,890
经过适当设计的投影测量，我们可以成为
measurement and we can be theta where theta is over bed with coefficient and T

829
00:28:33,890 --> 00:28:37,450
θ在床上，系数为T，T为矩阵行，它们是
measurement and we can be theta where theta is over bed with coefficient and T

830
00:28:37,450 --> 00:28:40,870
θ在床上，系数为T，T为矩阵行，它们是
theta is over bed with coefficient and T is the matrix rows of which are the

831
00:28:40,870 --> 00:28:40,880
θ在床上，系数为T，T为矩阵行，它们是
is the matrix rows of which are the random with the time projected

832
00:28:40,880 --> 00:28:43,410
与时间投影投影向量随机
is the matrix rows of which are the random with the time projected

833
00:28:43,410 --> 00:28:46,430
与时间投影投影向量随机
random with the time projected projection vector

834
00:28:46,430 --> 00:28:46,440
与时间投影投影向量随机
projection vector so we would like if we assume that this

835
00:28:46,440 --> 00:28:50,580
因此，如果我们假设该V是n维结束的，则以1为基础
projection vector so we would like if we assume that this

836
00:28:50,580 --> 00:28:53,700
因此，如果我们假设该V是n维结束的，则以1为基础
so we would like if we assume that this V is n dimensional ended based with one

837
00:28:53,700 --> 00:28:53,710
因此，如果我们假设该V是n维结束的，则以1为基础
V is n dimensional ended based with one x and and dimensional n elements and

838
00:28:53,710 --> 00:28:56,909
x和and维n个元素，theta是我们要拥有的n个元素
V is n dimensional ended based with one x and and dimensional n elements and

839
00:28:56,909 --> 00:28:59,850
x和and维n个元素，theta是我们要拥有的n个元素
x and and dimensional n elements and theta is the has n elements we would

840
00:28:59,850 --> 00:28:59,860
x和and维n个元素，theta是我们要拥有的n个元素
theta is the has n elements we would like the number of measurements to be as

841
00:28:59,860 --> 00:29:01,590
比如测量的数量要尽可能少
theta is the has n elements we would like the number of measurements to be as

842
00:29:01,590 --> 00:29:08,639
比如测量的数量要尽可能少
like the number of measurements to be as low as possible conditions that we have

843
00:29:08,639 --> 00:29:13,370
我们有这些θ系数，我们可以重建我们的图像或信号，
like the number of measurements to be as low as possible conditions that we have

844
00:29:13,370 --> 00:29:13,380
我们有这些θ系数，我们可以重建我们的图像或信号，


845
00:29:13,380 --> 00:29:20,129
我们有这些θ系数，我们可以重建我们的图像或信号，
we have these theta coefficients we can reconstruct our image or signal that we

846
00:29:20,129 --> 00:29:20,139
我们有这些θ系数，我们可以重建我们的图像或信号，
reconstruct our image or signal that we have using an image transport but we

847
00:29:20,139 --> 00:29:24,480
已经使用图像传输，但是我们测量它是一个投影，它是一个
reconstruct our image or signal that we have using an image transport but we

848
00:29:24,480 --> 00:29:30,629
已经使用图像传输，但是我们测量它是一个投影，它是一个
have using an image transport but we measure it is a projection it is a

849
00:29:30,629 --> 00:29:30,639
已经使用图像传输，但是我们测量它是一个投影，它是一个
measure it is a projection it is a projection this problem is undetermined

850
00:29:30,639 --> 00:29:52,110
投影这个问题尚未确定，仍然存在，并且是解决该问题的好方法
measure it is a projection it is a projection this problem is undetermined

851
00:29:52,110 --> 00:29:54,289
投影这个问题尚未确定，仍然存在，并且是解决该问题的好方法
projection this problem is undetermined and it still posed and a good way to

852
00:29:54,289 --> 00:29:54,299
投影这个问题尚未确定，仍然存在，并且是解决该问题的好方法
and it still posed and a good way to approach this problem is using Bayesian

853
00:29:54,299 --> 00:29:57,119
解决这个问题的方法是使用贝叶斯Setia转换，因此一些结构和
and it still posed and a good way to approach this problem is using Bayesian

854
00:29:57,119 --> 00:30:05,070
解决这个问题的方法是使用贝叶斯Setia转换，因此一些结构和
approach this problem is using Bayesian Setia conversion so some structures and

855
00:30:05,070 --> 00:30:05,080
解决这个问题的方法是使用贝叶斯Setia转换，因此一些结构和
Setia conversion so some structures and we can incorporate this structure of

856
00:30:05,080 --> 00:30:07,409
我们可以结合这个波的这种结构来获得我们的系数
Setia conversion so some structures and we can incorporate this structure of

857
00:30:07,409 --> 00:30:10,350
我们可以结合这个波的这种结构来获得我们的系数
we can incorporate this structure of this wave with to have our coefficients

858
00:30:10,350 --> 00:30:10,360
我们可以结合这个波的这种结构来获得我们的系数
this wave with to have our coefficients to in order to reduce the number of

859
00:30:10,360 --> 00:30:12,720
为了减少如果我们需要的测量数量
this wave with to have our coefficients to in order to reduce the number of

860
00:30:12,720 --> 00:30:15,690
为了减少如果我们需要的测量数量
to in order to reduce the number of required measurements that we have if we

861
00:30:15,690 --> 00:30:15,700
为了减少如果我们需要的测量数量
required measurements that we have if we want to apply the treatment web

862
00:30:15,700 --> 00:30:17,490
要在信号给晕机上应用治疗网络变换，我们可以
required measurements that we have if we want to apply the treatment web

863
00:30:17,490 --> 00:30:20,430
要在信号给晕机上应用治疗网络变换，我们可以
want to apply the treatment web transform on airsick given signal we can

864
00:30:20,430 --> 00:30:20,440
要在信号给晕机上应用治疗网络变换，我们可以
transform on airsick given signal we can define this as deploying the series the

865
00:30:20,440 --> 00:30:23,999
将其定义为部署高通和低通滤波器系列，并且
transform on airsick given signal we can define this as deploying the series the

866
00:30:23,999 --> 00:30:29,129
将其定义为部署高通和低通滤波器系列，并且
define this as deploying the series the high-pass and low-pass filters and that

867
00:30:29,129 --> 00:30:29,139
将其定义为部署高通和低通滤波器系列，并且
high-pass and low-pass filters and that would result in a quadtree here H stands

868
00:30:29,139 --> 00:30:32,850
将产生四叉树，其中H代表高通，L代表Lopes
high-pass and low-pass filters and that would result in a quadtree here H stands

869
00:30:32,850 --> 00:30:35,549
将产生四叉树，其中H代表高通，L代表Lopes
would result in a quadtree here H stands for the high-pass and L stands for Lopes

870
00:30:35,549 --> 00:30:35,559
将产生四叉树，其中H代表高通，L代表Lopes
for the high-pass and L stands for Lopes we have a signal with labels will end up

871
00:30:35,559 --> 00:30:38,940
我们有一个带有标签的信号将最终以两种类型的结果开始
for the high-pass and L stands for Lopes we have a signal with labels will end up

872
00:30:38,940 --> 00:30:41,789
我们有一个带有标签的信号将最终以两种类型的结果开始
we have a signal with labels will end up with two types of results began on each

873
00:30:41,789 --> 00:30:41,799
我们有一个带有标签的信号将最终以两种类型的结果开始
with two types of results began on each of these we apply these two

874
00:30:41,799 --> 00:30:43,980
在这些中，我们最后使用这两个levan过滤器
with two types of results began on each of these we apply these two

875
00:30:43,980 --> 00:30:47,490
在这些中，我们最后使用这两个levan过滤器
of these we apply these two levan filters at the end we end up with

876
00:30:47,490 --> 00:30:47,500
在这些中，我们最后使用这两个levan过滤器
levan filters at the end we end up with three stop bands of death coefficients

877
00:30:47,500 --> 00:30:50,310
如果这是细节中的细节，则三个死亡系数的阻带
levan filters at the end we end up with three stop bands of death coefficients

878
00:30:50,310 --> 00:30:54,030
如果这是细节中的细节，则三个死亡系数的阻带
three stop bands of death coefficients if this one is the details in the

879
00:30:54,030 --> 00:30:54,040
如果这是细节中的细节，则三个死亡系数的阻带
if this one is the details in the horizontal Direction vertical and

880
00:30:54,040 --> 00:30:56,700
水平方向垂直和对角线区域，这部分是
if this one is the details in the horizontal Direction vertical and

881
00:30:56,700 --> 00:30:59,970
水平方向垂直和对角线区域，这部分是
horizontal Direction vertical and diagonal region and this part is the

882
00:30:59,970 --> 00:30:59,980
水平方向垂直和对角线区域，这部分是
diagonal region and this part is the scoring conditions that we have which

883
00:30:59,980 --> 00:31:02,490
给我们评分的条件使我们在宇宙中形成
diagonal region and this part is the scoring conditions that we have which

884
00:31:02,490 --> 00:31:04,830
给我们评分的条件使我们在宇宙中形成
scoring conditions that we have which gives us the formation in the universe

885
00:31:04,830 --> 00:31:04,840
给我们评分的条件使我们在宇宙中形成
gives us the formation in the universe space now

886
00:31:04,840 --> 00:31:06,750
现在可以再次构成的空间
gives us the formation in the universe space now

887
00:31:06,750 --> 00:31:09,419
现在可以再次构成的空间
space now this can again will be composed again

888
00:31:09,419 --> 00:31:09,429
现在可以再次构成的空间
this can again will be composed again from wavelet coefficients and from

889
00:31:09,429 --> 00:31:12,600
从小波系数到杀死系数，一次又一次
this can again will be composed again from wavelet coefficients and from

890
00:31:12,600 --> 00:31:16,920
从小波系数到杀死系数，一次又一次
from wavelet coefficients and from killing coefficient and again and again

891
00:31:16,920 --> 00:31:20,150
被称为最后一个是弱音，父母之间的亲子关系
from wavelet coefficients and from killing coefficient and again and again

892
00:31:20,150 --> 00:31:20,160
被称为最后一个是弱音，父母之间的亲子关系


893
00:31:20,160 --> 00:32:04,440
被称为最后一个是弱音，父母之间的亲子关系
is called the last one is the weak note the parent-child relationship between

894
00:32:04,440 --> 00:32:04,450
被称为最后一个是弱音，父母之间的亲子关系
the parent-child relationship between the coefficients across each each of

895
00:32:04,450 --> 00:32:27,060
每个系数都有另外四个孩子，直到我们
the parent-child relationship between the coefficients across each each of

896
00:32:27,060 --> 00:32:32,610
每个系数都有另外四个孩子，直到我们
the coefficients across each each of these have four other children until we

897
00:32:32,610 --> 00:32:36,680
想要使用我们先前在其中合并的结构
the coefficients across each each of these have four other children until we

898
00:32:36,680 --> 00:32:36,690
想要使用我们先前在其中合并的结构


899
00:32:36,690 --> 00:32:44,549
想要使用我们先前在其中合并的结构
would like to use this structure that we have an incorporated in the prior in

900
00:32:44,549 --> 00:32:44,559
想要使用我们先前在其中合并的结构
have an incorporated in the prior in order to reduce

901
00:32:44,559 --> 00:32:46,330
为了减少测量所需的
have an incorporated in the prior in order to reduce

902
00:32:46,330 --> 00:32:50,279
为了减少测量所需的
order to reduce of measurement that are required for a

903
00:32:50,279 --> 00:32:50,289
为了减少测量所需的
of measurement that are required for a basically a good accuracy reconstruction

904
00:32:50,289 --> 00:32:53,710
基本上以前已经对信号进行了良好的精度重建
of measurement that are required for a basically a good accuracy reconstruction

905
00:32:53,710 --> 00:32:56,019
基本上以前已经对信号进行了良好的精度重建
basically a good accuracy reconstruction of the signal this has been previously

906
00:32:56,019 --> 00:32:56,029
基本上以前已经对信号进行了良好的精度重建
of the signal this has been previously used in other jobs like compressing

907
00:32:56,029 --> 00:32:58,899
用于其他工作，例如压缩电子邮件，压缩数据或纹理
of the signal this has been previously used in other jobs like compressing

908
00:32:58,899 --> 00:33:02,950
用于其他工作，例如压缩电子邮件，压缩数据或纹理
used in other jobs like compressing email compressing data or texture

909
00:33:02,950 --> 00:33:02,960
用于其他工作，例如压缩电子邮件，压缩数据或纹理
email compressing data or texture synthesis or image denoising and we

910
00:33:02,960 --> 00:33:07,779
合成或图像去噪，我们想利用此产品
email compressing data or texture synthesis or image denoising and we

911
00:33:07,779 --> 00:33:10,870
合成或图像去噪，我们想利用此产品
synthesis or image denoising and we would like to take this product exploit

912
00:33:10,870 --> 00:33:10,880
合成或图像去噪，我们想利用此产品
would like to take this product exploit the structure of these wavelet countries

913
00:33:10,880 --> 00:33:12,850
这些小波国家的结构，并在我们的视力倒置中使用它们
would like to take this product exploit the structure of these wavelet countries

914
00:33:12,850 --> 00:33:16,269
这些小波国家的结构，并在我们的视力倒置中使用它们
the structure of these wavelet countries and use them in our vision inversion one

915
00:33:16,269 --> 00:33:16,279
这些小波国家的结构，并在我们的视力倒置中使用它们
and use them in our vision inversion one thing about the weblog coefficients is

916
00:33:16,279 --> 00:33:18,190
关于Weblog系数的事情是，Nuke Digital Web Web
and use them in our vision inversion one thing about the weblog coefficients is

917
00:33:18,190 --> 00:33:20,110
关于Weblog系数的事情是，Nuke Digital Web Web
thing about the weblog coefficients is that the nuke digital web web

918
00:33:20,110 --> 00:33:20,120
关于Weblog系数的事情是，Nuke Digital Web Web
that the nuke digital web web coefficient tend to cluster together and

919
00:33:20,120 --> 00:33:23,370
系数倾向于聚集在一起，并且它们显然可以忽略不计
that the nuke digital web web coefficient tend to cluster together and

920
00:33:23,370 --> 00:33:29,019
系数倾向于聚集在一起，并且它们显然可以忽略不计
coefficient tend to cluster together and they apparently a negligible coefficient

921
00:33:29,019 --> 00:33:29,029
系数倾向于聚集在一起，并且它们显然可以忽略不计
they apparently a negligible coefficient it children with high probability would

922
00:33:29,029 --> 00:33:31,990
它的孩子很有可能是0棵树，这意味着父对象是
they apparently a negligible coefficient it children with high probability would

923
00:33:31,990 --> 00:33:44,139
它的孩子很有可能是0棵树，这意味着父对象是
it children with high probability would be 0 trees it means that the parent is

924
00:33:44,139 --> 00:33:44,149
它的孩子很有可能是0棵树，这意味着父对象是
be 0 trees it means that the parent is doing children is do as 200 so forth and

925
00:33:44,149 --> 00:33:49,630
做孩子大约是200左右
be 0 trees it means that the parent is doing children is do as 200 so forth and

926
00:33:49,630 --> 00:33:49,889
我们可以在多个树中使用隐藏的马尔可夫树进行结构化，我们可以说
be 0 trees it means that the parent is doing children is do as 200 so forth and

927
00:33:49,889 --> 00:33:49,899
我们可以在多个树中使用隐藏的马尔可夫树进行结构化，我们可以说


928
00:33:49,899 --> 00:34:00,789
我们可以在多个树中使用隐藏的马尔可夫树进行结构化，我们可以说
we can structure using hidden markov trees in multiple trees we can say that

929
00:34:00,789 --> 00:34:00,799
我们可以在多个树中使用隐藏的马尔可夫树进行结构化，我们可以说
trees in multiple trees we can say that all right

930
00:34:00,799 --> 00:34:01,480
好的，所以我们有两种系数
trees in multiple trees we can say that all right

931
00:34:01,480 --> 00:34:04,090
好的，所以我们有两种系数
all right so we have two types of coefficients one

932
00:34:04,090 --> 00:34:04,100
好的，所以我们有两种系数
so we have two types of coefficients one unintelligible coefficient you ever try

933
00:34:04,100 --> 00:34:06,639
难以理解的系数，您曾经尝试过可以为我们提供的有效系数
so we have two types of coefficients one unintelligible coefficient you ever try

934
00:34:06,639 --> 00:34:08,710
难以理解的系数，您曾经尝试过可以为我们提供的有效系数
unintelligible coefficient you ever try for the significant coefficients we can

935
00:34:08,710 --> 00:34:08,720
难以理解的系数，您曾经尝试过可以为我们提供的有效系数
for the significant coefficients we can draw the color negligible coefficient

936
00:34:08,720 --> 00:34:11,800
用低方差从Adelphia绘制颜色可忽略的系数，我们
for the significant coefficients we can draw the color negligible coefficient

937
00:34:11,800 --> 00:34:14,470
用低方差从Adelphia绘制颜色可忽略的系数，我们
draw the color negligible coefficient from Adelphia with a low variance and we

938
00:34:14,470 --> 00:34:14,480
用低方差从Adelphia绘制颜色可忽略的系数，我们
from Adelphia with a low variance and we can draw the coefficient significant

939
00:34:14,480 --> 00:34:17,919
可以从高斯中得出系数的显着系数
from Adelphia with a low variance and we can draw the coefficient significant

940
00:34:17,919 --> 00:34:19,960
可以从高斯中得出系数的显着系数
can draw the coefficient significant coefficients we will from a Gaussian

941
00:34:19,960 --> 00:34:19,970
可以从高斯中得出系数的显着系数
coefficients we will from a Gaussian with a larger variance and to define

942
00:34:19,970 --> 00:34:27,280
具有更大的方差并定义此父子关系，我们可以
coefficients we will from a Gaussian with a larger variance and to define

943
00:34:27,280 --> 00:34:30,550
具有更大的方差并定义此父子关系，我们可以
with a larger variance and to define this parent-child relationship we can

944
00:34:30,550 --> 00:34:30,560
具有更大的方差并定义此父子关系，我们可以
this parent-child relationship we can use a markup representation across the

945
00:34:30,560 --> 00:34:34,659
在技​​能上使用标记表示法，因此此标记合适
this parent-child relationship we can use a markup representation across the

946
00:34:34,659 --> 00:34:37,899
在技​​能上使用标记表示法，因此此标记合适
use a markup representation across the skills so this mark appropriate

947
00:34:37,899 --> 00:34:37,909
在技​​能上使用标记表示法，因此此标记合适
skills so this mark appropriate transition can be defined using a two by

948
00:34:37,909 --> 00:34:41,050
可以使用二乘二矩阵P IJ定义跃迁，其中I代表
skills so this mark appropriate transition can be defined using a two by

949
00:34:41,050 --> 00:34:44,530
可以使用二乘二矩阵P IJ定义跃迁，其中I代表
transition can be defined using a two by two matrix P IJ where I stands for the

950
00:34:44,530 --> 00:34:44,540
可以使用二乘二矩阵P IJ定义跃迁，其中I代表
two matrix P IJ where I stands for the state of the

951
00:34:44,540 --> 00:34:46,150
接孩子的状态，例如孩子
two matrix P IJ where I stands for the state of the

952
00:34:46,150 --> 00:34:50,780
接孩子的状态，例如孩子
state of the pick up the child so tij for example kid

953
00:34:50,780 --> 00:34:50,790
接孩子的状态，例如孩子
pick up the child so tij for example kid Lolo is the probability of child and

954
00:34:50,790 --> 00:34:54,230
Lolo是孩子和父母都处于新状态的概率
pick up the child so tij for example kid Lolo is the probability of child and

955
00:34:54,230 --> 00:34:56,570
Lolo是孩子和父母都处于新状态的概率
Lolo is the probability of child and parents both being in the new state

956
00:34:56,570 --> 00:34:56,580
Lolo是孩子和父母都处于新状态的概率
parents both being in the new state which is a high probability so we show

957
00:34:56,580 --> 00:34:58,910
这是一个很高的概率，所以我们用一个来显示-所有人都是
parents both being in the new state which is a high probability so we show

958
00:34:58,910 --> 00:35:01,940
这是一个很高的概率，所以我们用一个来显示-所有人都是
which is a high probability so we show it with one - extra everyone being a

959
00:35:01,940 --> 00:35:01,950
这是一个很高的概率，所以我们用一个来显示-所有人都是
it with one - extra everyone being a small positive number if parent

960
00:35:01,950 --> 00:35:09,590
如果父系数可忽略，则其子项的正数较小
it with one - extra everyone being a small positive number if parent

961
00:35:09,590 --> 00:35:11,810
如果父系数可忽略，则其子项的正数较小
small positive number if parent coefficients is negligible its children

962
00:35:11,810 --> 00:35:11,820
如果父系数可忽略，则其子项的正数较小
coefficients is negligible its children would be negligible as well in the tree

963
00:35:11,820 --> 00:35:19,370
在树中我们也可以忽略不计
coefficients is negligible its children would be negligible as well in the tree

964
00:35:19,370 --> 00:35:21,500
在树中我们也可以忽略不计
would be negligible as well in the tree we are assuming that our observations

965
00:35:21,500 --> 00:35:21,510
在树中我们也可以忽略不计
we are assuming that our observations are our coefficients but in compressive

966
00:35:21,510 --> 00:35:27,710
是我们的系数，但在压缩感测中，我们的测量值是随机的
we are assuming that our observations are our coefficients but in compressive

967
00:35:27,710 --> 00:35:32,570
是我们的系数，但在压缩感测中，我们的测量值是随机的
are our coefficients but in compressive sensing our measurements are the random

968
00:35:32,570 --> 00:35:32,580
是我们的系数，但在压缩感测中，我们的测量值是随机的
sensing our measurements are the random projections of these weather

969
00:35:32,580 --> 00:35:34,190
这些天气系数的投影，我们没有观察到这些
sensing our measurements are the random projections of these weather

970
00:35:34,190 --> 00:35:37,610
这些天气系数的投影，我们没有观察到这些
projections of these weather coefficients and we don't observe these

971
00:35:37,610 --> 00:35:37,620
这些天气系数的投影，我们没有观察到这些
coefficients and we don't observe these coefficients directively directly

972
00:35:37,620 --> 00:35:41,770
假设我们的信号称为X，直接有针对性地确定系数
coefficients and we don't observe these coefficients directively directly

973
00:35:41,770 --> 00:35:45,800
假设我们的信号称为X，直接有针对性地确定系数
coefficients directively directly alright assuming our signal is called X

974
00:35:45,800 --> 00:35:45,810
假设我们的信号称为X，直接有针对性地确定系数
alright assuming our signal is called X we and we have a match basically bevit

975
00:35:45,810 --> 00:35:51,400
我们和我们有一个匹配，基本上是构图，确保它是矩阵Phi
alright assuming our signal is called X we and we have a match basically bevit

976
00:35:51,400 --> 00:35:55,040
我们和我们有一个匹配，基本上是构图，确保它是矩阵Phi
we and we have a match basically bevit the composition make sure it matrix Phi

977
00:35:55,040 --> 00:35:55,050
我们和我们有一个匹配，基本上是构图，确保它是矩阵Phi
the composition make sure it matrix Phi we apply this and we get overridden with

978
00:35:55,050 --> 00:35:57,890
我们应用它，我们被系数覆盖，我们的测量结果是
the composition make sure it matrix Phi we apply this and we get overridden with

979
00:35:57,890 --> 00:36:01,180
我们应用它，我们被系数覆盖，我们的测量结果是
we apply this and we get overridden with coefficients and our measurements are

980
00:36:01,180 --> 00:36:01,190
我们应用它，我们被系数覆盖，我们的测量结果是
coefficients and our measurements are random projections of theta M which

981
00:36:01,190 --> 00:36:12,980
θM的随机投影，其中包括有效系数
coefficients and our measurements are random projections of theta M which

982
00:36:12,980 --> 00:36:16,300
θM的随机投影，其中包括有效系数
random projections of theta M which includes the significant coefficients

983
00:36:16,300 --> 00:36:16,310
θM的随机投影，其中包括有效系数
includes the significant coefficients the negligible ones are set to zero and

984
00:36:16,310 --> 00:36:19,390
可以忽略不计的值设置为零，而另一个为theta e，其中
includes the significant coefficients the negligible ones are set to zero and

985
00:36:19,390 --> 00:36:23,240
可以忽略不计的值设置为零，而另一个为theta e，其中
the negligible ones are set to zero and the other one is theta e where the

986
00:36:23,240 --> 00:36:23,250
可以忽略不计的值设置为零，而另一个为theta e，其中
the other one is theta e where the natural significant ones are set to zero

987
00:36:23,250 --> 00:36:25,700
自然有效的那些设置为零，而只有可忽略的一个，并且
the other one is theta e where the natural significant ones are set to zero

988
00:36:25,700 --> 00:36:29,320
自然有效的那些设置为零，而只有可忽略的一个，并且
natural significant ones are set to zero and it only has the negligible one and

989
00:36:29,320 --> 00:36:29,330
自然有效的那些设置为零，而只有可忽略的一个，并且
and it only has the negligible one and we also assume that we have noise in our

990
00:36:29,330 --> 00:36:32,150
我们还假设我们的测量中有噪声，因此我们可以将其开始
and it only has the negligible one and we also assume that we have noise in our

991
00:36:32,150 --> 00:36:35,810
我们还假设我们的测量中有噪声，因此我们可以将其开始
we also assume that we have noise in our measurement so we can start this to our

992
00:36:35,810 --> 00:36:35,820
我们还假设我们的测量中有噪声，因此我们可以将其开始
measurement so we can start this to our and right there at n which is the noise

993
00:36:35,820 --> 00:36:40,610
在n处就是噪声，可以用a表示
measurement so we can start this to our and right there at n which is the noise

994
00:36:40,610 --> 00:36:42,500
在n处就是噪声，可以用a表示
and right there at n which is the noise it can be it is represented with a

995
00:36:42,500 --> 00:36:42,510
在n处就是噪声，可以用a表示
it can be it is represented with a Gaussian with some precision is the

996
00:36:42,510 --> 00:36:56,290
具有高精确度的高斯是有效的小波系数
it can be it is represented with a Gaussian with some precision is the

997
00:36:56,290 --> 00:36:59,120
具有高精确度的高斯是有效的小波系数
Gaussian with some precision is the significant wavelet coefficients first

998
00:36:59,120 --> 00:36:59,130
具有高精确度的高斯是有效的小波系数
significant wavelet coefficients first their locations second their values and

999
00:36:59,130 --> 00:37:04,640
他们的位置紧随其后的是价值
significant wavelet coefficients first their locations second their values and

1000
00:37:04,640 --> 00:37:04,770
[鼓掌]所以这个的后验分布
significant wavelet coefficients first their locations second their values and

1001
00:37:04,770 --> 00:37:04,780
[鼓掌]所以这个的后验分布


1002
00:37:04,780 --> 00:37:09,790
[鼓掌]所以这个的后验分布
[Applause] so the posterior distribution of this

1003
00:37:09,790 --> 00:37:09,800
[鼓掌]所以这个的后验分布
so the posterior distribution of this would be inferred using the updated

1004
00:37:09,800 --> 00:37:15,070
将使用更新的度量来推断，我们现在这个结构是
so the posterior distribution of this would be inferred using the updated

1005
00:37:15,070 --> 00:37:18,590
将使用更新的度量来推断，我们现在这个结构是
would be inferred using the updated measurement we now this structure is a

1006
00:37:18,590 --> 00:37:18,600
将使用更新的度量来推断，我们现在这个结构是
measurement we now this structure is a structure information that we would like

1007
00:37:18,600 --> 00:37:21,110
我们想在我们之前的两个中合并的结构信息
measurement we now this structure is a structure information that we would like

1008
00:37:21,110 --> 00:37:23,960
我们想在我们之前的两个中合并的结构信息
structure information that we would like to incorporate in the prior our two

1009
00:37:23,960 --> 00:37:23,970
我们想在我们之前的两个中合并的结构信息
to incorporate in the prior our two things

1010
00:37:23,970 --> 00:37:24,410
亲子关系第二件事
to incorporate in the prior our two things

1011
00:37:24,410 --> 00:37:27,410
亲子关系第二件事
things the parent-child relationship second one

1012
00:37:27,410 --> 00:37:27,420
亲子关系第二件事
the parent-child relationship second one this person's of the wavelet coefficient

1013
00:37:27,420 --> 00:37:31,060
这个人的小波系数可以用这些函数定义
the parent-child relationship second one this person's of the wavelet coefficient

1014
00:37:31,060 --> 00:37:34,220
这个人的小波系数可以用这些函数定义
this person's of the wavelet coefficient one can define it using these functions

1015
00:37:34,220 --> 00:37:34,230
这个人的小波系数可以用这些函数定义
one can define it using these functions that prior which is a combined

1016
00:37:34,230 --> 00:37:38,030
之前的是组合分布和组合
one can define it using these functions that prior which is a combined

1017
00:37:38,030 --> 00:37:40,670
之前的是组合分布和组合
that prior which is a combined distribution and which combined

1018
00:37:40,670 --> 00:37:40,680
之前的是组合分布和组合
distribution and which combined attribution which is a built in here is

1019
00:37:40,680 --> 00:37:45,170
内置于此的归因是匹配点，并且是高斯
distribution and which combined attribution which is a built in here is

1020
00:37:45,170 --> 00:37:52,940
内置于此的归因是匹配点，并且是高斯
attribution which is a built in here is a match point and and and is a Gaussian

1021
00:37:52,940 --> 00:37:52,950
内置于此的归因是匹配点，并且是高斯
a match point and and and is a Gaussian so we are saying that our rebel

1022
00:37:52,950 --> 00:37:54,950
所以我们说我们的反叛系数是从
a match point and and and is a Gaussian so we are saying that our rebel

1023
00:37:54,950 --> 00:37:57,380
所以我们说我们的反叛系数是从
so we are saying that our rebel coefficients are drawn from there are

1024
00:37:57,380 --> 00:37:57,390
所以我们说我们的反叛系数是从
coefficients are drawn from there are either zero with probability one minus

1025
00:37:57,390 --> 00:37:59,510
要么为零（概率为1减去PI I），要么是从高斯得出的
coefficients are drawn from there are either zero with probability one minus

1026
00:37:59,510 --> 00:38:03,410
要么为零（概率为1减去PI I），要么是从高斯得出的
either zero with probability one minus PI I or they are drawn from a Gaussian

1027
00:38:03,410 --> 00:38:03,420
要么为零（概率为1减去PI I），要么是从高斯得出的
PI I or they are drawn from a Gaussian distribution with some variance with

1028
00:38:03,420 --> 00:38:06,170
有概率PI且有一定方差的分布，所以
PI I or they are drawn from a Gaussian distribution with some variance with

1029
00:38:06,170 --> 00:38:11,829
有概率PI且有一定方差的分布，所以
distribution with some variance with probability PI okay so

1030
00:38:11,829 --> 00:38:11,839
有概率PI且有一定方差的分布，所以
probability PI okay so this first part represents the zero

1031
00:38:11,839 --> 00:38:15,949
这第一部分代表零系数，而这部分代表
probability PI okay so this first part represents the zero

1032
00:38:15,949 --> 00:38:19,370
这第一部分代表零系数，而这部分代表
this first part represents the zero coefficient and this part represents the

1033
00:38:19,370 --> 00:38:19,380
这第一部分代表零系数，而这部分代表
coefficient and this part represents the significant nonzero coefficient so each

1034
00:38:19,380 --> 00:38:24,079
显着的非零系数，所以每个这些都对应一个
coefficient and this part represents the significant nonzero coefficient so each

1035
00:38:24,079 --> 00:38:26,959
显着的非零系数，所以每个这些都对应一个
significant nonzero coefficient so each of these where are corresponds with one

1036
00:38:26,959 --> 00:38:26,969
显着的非零系数，所以每个这些都对应一个
of these where are corresponds with one of the guardians that really defined we

1037
00:38:26,969 --> 00:38:29,059
真正定义我们的监护人是在隐藏的市场中谈论的
of these where are corresponds with one of the guardians that really defined we

1038
00:38:29,059 --> 00:38:31,489
真正定义我们的监护人是在隐藏的市场中谈论的
of the guardians that really defined we were talking about in the hidden markov

1039
00:38:31,489 --> 00:38:31,499
真正定义我们的监护人是在隐藏的市场中谈论的
were talking about in the hidden markov tree and here the coefficients in the

1040
00:38:31,499 --> 00:38:36,559
树，此处处于低状态的系数设置为零，而不是
were talking about in the hidden markov tree and here the coefficients in the

1041
00:38:36,559 --> 00:38:40,519
树，此处处于低状态的系数设置为零，而不是
tree and here the coefficients in the low state are set to zero as opposed to

1042
00:38:40,519 --> 00:38:40,529
树，此处处于低状态的系数设置为零，而不是
low state are set to zero as opposed to hidden markov tree model which is what

1043
00:38:40,529 --> 00:38:42,769
隐藏的马尔可夫树模型，每个模型都是从低
low state are set to zero as opposed to hidden markov tree model which is what

1044
00:38:42,769 --> 00:38:45,670
隐藏的马尔可夫树模型，每个模型都是从低
hidden markov tree model which is what each was drawn from a Gaussian with low

1045
00:38:45,670 --> 00:38:45,680
隐藏的马尔可夫树模型，每个模型都是从低
each was drawn from a Gaussian with low variance now the children will be zero

1046
00:38:45,680 --> 00:38:52,779
方差现在，由于对
each was drawn from a Gaussian with low variance now the children will be zero

1047
00:38:52,779 --> 00:38:59,509
方差现在，由于对
variance now the children will be zero using some dependences across on the

1048
00:38:59,509 --> 00:38:59,519
方差现在，由于对
using some dependences across on the mixing way spike and prior in terms of

1049
00:38:59,519 --> 00:39:12,759
混合方式的峰值和先验条件是使用作为元素产品的热水
using some dependences across on the mixing way spike and prior in terms of

1050
00:39:12,759 --> 00:39:17,949
混合方式的峰值和先验条件是使用作为元素产品的热水
mixing way spike and prior in terms of using hot water which is element product

1051
00:39:17,949 --> 00:39:17,959
混合方式的峰值和先验条件是使用作为元素产品的热水
using hot water which is element product we have W equals W times W is the

1052
00:39:17,959 --> 00:39:24,759
我们有W等于W乘以W是从高斯得出的系数
using hot water which is element product we have W equals W times W is the

1053
00:39:24,759 --> 00:39:28,069
我们有W等于W乘以W是从高斯得出的系数
we have W equals W times W is the coefficient drawn from a Gaussian

1054
00:39:28,069 --> 00:39:28,079
我们有W等于W乘以W是从高斯得出的系数
coefficient drawn from a Gaussian distribution as Z is a Bernoulli

1055
00:39:28,079 --> 00:39:31,430
Z的分布是一个伯努利分布，它是一个或一系列
coefficient drawn from a Gaussian distribution as Z is a Bernoulli

1056
00:39:31,430 --> 00:39:34,900
Z的分布是一个伯努利分布，它是一个或一系列
distribution as Z is a Bernoulli distribution which is the one or series

1057
00:39:34,900 --> 00:39:34,910
Z的分布是一个伯努利分布，它是一个或一系列
distribution which is the one or series the one says that

1058
00:39:34,910 --> 00:39:37,549
有人说，反叛联盟处于很高的地位
distribution which is the one or series the one says that

1059
00:39:37,549 --> 00:39:40,160
有人说，反叛联盟处于很高的地位
the one says that okay the rebel coalition is in a high

1060
00:39:40,160 --> 00:39:40,170
有人说，反叛联盟处于很高的地位
okay the rebel coalition is in a high state and co-state status to low state

1061
00:39:40,170 --> 00:39:42,469
状态和共状态从低状态改为设置为零，并且我们的电源
okay the rebel coalition is in a high state and co-state status to low state

1062
00:39:42,469 --> 00:39:48,499
状态和共状态从低状态改为设置为零，并且我们的电源
state and co-state status to low state instead set to zero and the power in our

1063
00:39:48,499 --> 00:39:48,509
状态和共状态从低状态改为设置为零，并且我们的电源
instead set to zero and the power in our model we would like to define this

1064
00:39:48,509 --> 00:39:50,509
我们想定义这种混合模型浪费了它们的精度参数
instead set to zero and the power in our model we would like to define this

1065
00:39:50,509 --> 00:39:53,599
我们想定义这种混合模型浪费了它们的精度参数
model we would like to define this mixing waste their precision parameter

1066
00:39:53,599 --> 00:39:53,609
我们想定义这种混合模型浪费了它们的精度参数
mixing waste their precision parameter and precision for the noise we can

1067
00:39:53,609 --> 00:39:57,160
噪声的精度和精确度，我们可以将模型总结如下：
mixing waste their precision parameter and precision for the noise we can

1068
00:39:57,160 --> 00:40:00,289
噪声的精度和精确度，我们可以将模型总结如下：
and precision for the noise we can summarize the model as following we have

1069
00:40:00,289 --> 00:40:00,299
噪声的精度和精确度，我们可以将模型总结如下：
summarize the model as following we have our theta it is the product of WS d / w

1070
00:40:00,299 --> 00:40:04,789
我们的理论是WS d / w的乘积是来自高斯的有效位置
summarize the model as following we have our theta it is the product of WS d / w

1071
00:40:04,789 --> 00:40:07,219
我们的理论是WS d / w的乘积是来自高斯的有效位置
our theta it is the product of WS d / w is valid position from from a Gaussian

1072
00:40:07,219 --> 00:40:07,229
我们的理论是WS d / w的乘积是来自高斯的有效位置
is valid position from from a Gaussian distribution

1073
00:40:07,229 --> 00:40:07,969
分布z
is valid position from from a Gaussian distribution

1074
00:40:07,969 --> 00:40:09,000
分布z
distribution z

1075
00:40:09,000 --> 00:40:09,010
分布z
z is defining whether they are in high or

1076
00:40:09,010 --> 00:40:13,380
正在定义它们是处于高位还是低位，这是伯努利分布
z is defining whether they are in high or

1077
00:40:13,380 --> 00:40:17,130
正在定义它们是处于高位还是低位，这是伯努利分布
is defining whether they are in high or low and it's the Bernoulli distribution

1078
00:40:17,130 --> 00:40:17,140
正在定义它们是处于高位还是低位，这是伯努利分布
low and it's the Bernoulli distribution and pies are the over basically mixing

1079
00:40:17,140 --> 00:40:24,230
馅饼基本上是混合废物，现在我们可以将其划分为
low and it's the Bernoulli distribution and pies are the over basically mixing

1080
00:40:24,230 --> 00:40:28,320
馅饼基本上是混合废物，现在我们可以将其划分为
and pies are the over basically mixing mixing waste now we can divide the types

1081
00:40:28,320 --> 00:40:28,330
馅饼基本上是混合废物，现在我们可以将其划分为
mixing waste now we can divide the types of mixing weights into four categories

1082
00:40:28,330 --> 00:40:30,630
混合权重分为四类：一是填充的混合速率
mixing waste now we can divide the types of mixing weights into four categories

1083
00:40:30,630 --> 00:40:33,690
混合权重分为四类：一是填充的混合速率
of mixing weights into four categories one is the mixing rate for the filling

1084
00:40:33,690 --> 00:40:33,700
混合权重分为四类：一是填充的混合速率
one is the mixing rate for the filling coefficient second one is the mixing

1085
00:40:33,700 --> 00:40:36,270
系数第二个是他们的真实音符的混合速率，第三个是
one is the mixing rate for the filling coefficient second one is the mixing

1086
00:40:36,270 --> 00:40:39,690
系数第二个是他们的真实音符的混合速率，第三个是
coefficient second one is the mixing rate for their real note and third one

1087
00:40:39,690 --> 00:40:39,700
系数第二个是他们的真实音符的混合速率，第三个是
rate for their real note and third one is the mixing weight toward the all

1088
00:40:39,700 --> 00:40:43,170
是所有其他非零河流条件的混合权重
rate for their real note and third one is the mixing weight toward the all

1089
00:40:43,170 --> 00:40:46,760
是所有其他非零河流条件的混合权重
is the mixing weight toward the all other river conditions that have nonzero

1090
00:40:46,760 --> 00:40:46,770
是所有其他非零河流条件的混合权重
other river conditions that have nonzero basically parents and lastly is the ones

1091
00:40:46,770 --> 00:40:50,250
基本上是父母，最后是父母为零的父母，每个父母都是
other river conditions that have nonzero basically parents and lastly is the ones

1092
00:40:50,250 --> 00:40:54,290
基本上是父母，最后是父母为零的父母，每个父母都是
basically parents and lastly is the ones that have zero parent each of these are

1093
00:40:54,290 --> 00:40:54,300
基本上是父母，最后是父母为零的父母，每个父母都是
that have zero parent each of these are defined using from hyper trenchers which

1094
00:40:54,300 --> 00:40:58,550
定义使用超级挖沟机，通过选择这些超级挖沟机
that have zero parent each of these are defined using from hyper trenchers which

1095
00:40:58,550 --> 00:41:01,530
定义使用超级挖沟机，通过选择这些超级挖沟机
defined using from hyper trenchers which like to by choosing these hyper

1096
00:41:01,530 --> 00:41:01,540
定义使用超级挖沟机，通过选择这些超级挖沟机
like to by choosing these hyper parameters they would like to say okay

1097
00:41:01,540 --> 00:41:03,960
他们想说的参数好吗，我们对缩放有什么想法
like to by choosing these hyper parameters they would like to say okay

1098
00:41:03,960 --> 00:41:14,160
他们想说的参数好吗，我们对缩放有什么想法
parameters they would like to say okay what idea we have about the scaling

1099
00:41:14,160 --> 00:41:14,170
他们想说的参数好吗，我们对缩放有什么想法
what idea we have about the scaling coefficient normally nonzero and we

1100
00:41:14,170 --> 00:41:21,270
系数通常为非零，我们希望周围有一些聚类
what idea we have about the scaling coefficient normally nonzero and we

1101
00:41:21,270 --> 00:41:24,290
系数通常为非零，我们希望周围有一些聚类
coefficient normally nonzero and we would like something clustered around

1102
00:41:24,290 --> 00:41:24,300
系数通常为非零，我们希望周围有一些聚类
would like something clustered around for the same type of distribution so the

1103
00:41:24,300 --> 00:41:30,990
对于相同的分布类型，因此我们希望其父级为零的分布
would like something clustered around for the same type of distribution so the

1104
00:41:30,990 --> 00:41:33,420
对于相同的分布类型，因此我们希望其父级为零的分布
for the same type of distribution so the ones that have zero parent we would like

1105
00:41:33,420 --> 00:41:33,430
对于相同的分布类型，因此我们希望其父级为零的分布
ones that have zero parent we would like them to be clustered around 0 and for

1106
00:41:33,430 --> 00:41:36,900
它们将聚集在0周围，而其他的非零
ones that have zero parent we would like them to be clustered around 0 and for

1107
00:41:36,900 --> 00:41:39,690
它们将聚集在0周围，而其他的非零
them to be clustered around 0 and for the other ones we that have nonzero

1108
00:41:39,690 --> 00:41:39,700
它们将聚集在0周围，而其他的非零
the other ones we that have nonzero parents we don't impose any prior

1109
00:41:39,700 --> 00:41:42,240
父母，我们不强加任何事先信息，他们可以是这里的任何东西
the other ones we that have nonzero parents we don't impose any prior

1110
00:41:42,240 --> 00:41:46,290
父母，我们不强加任何事先信息，他们可以是这里的任何东西
parents we don't impose any prior information they can be anything here is

1111
00:41:46,290 --> 00:41:46,300
父母，我们不强加任何事先信息，他们可以是这里的任何东西
information they can be anything here is a graphical representation of the

1112
00:41:46,300 --> 00:41:48,660
问题博士的图形表示。模型看到这些是
information they can be anything here is a graphical representation of the

1113
00:41:48,660 --> 00:41:52,440
问题博士的图形表示。模型看到这些是
a graphical representation of the problem dr. model see these are the

1114
00:41:52,440 --> 00:41:52,450
问题博士的图形表示。模型看到这些是
problem dr. model see these are the hyper temperatures that we have with

1115
00:41:52,450 --> 00:41:54,990
我们使用这个超参数的超温度基本上被使用
problem dr. model see these are the hyper temperatures that we have with

1116
00:41:54,990 --> 00:41:57,240
我们使用这个超参数的超温度基本上被使用
hyper temperatures that we have with this hyper parameters are used basically

1117
00:41:57,240 --> 00:41:57,250
我们使用这个超参数的超温度基本上被使用
this hyper parameters are used basically to define the mixing rate and these are

1118
00:41:57,250 --> 00:42:00,960
定义混合速率，这些用于定义每个工作站，而V是
this hyper parameters are used basically to define the mixing rate and these are

1119
00:42:00,960 --> 00:42:06,090
定义混合速率，这些用于定义每个工作站，而V是
to define the mixing rate and these are for defining the per station and V is

1120
00:42:06,090 --> 00:42:06,100
定义混合速率，这些用于定义每个工作站，而V是
for defining the per station and V is our observation here so I describe these

1121
00:42:06,100 --> 00:42:10,230
我们在这里的观察，所以我在下面描述这些片段
for defining the per station and V is our observation here so I describe these

1122
00:42:10,230 --> 00:42:11,980
我们在这里的观察，所以我在下面描述这些片段
our observation here so I describe these clips right on

1123
00:42:11,980 --> 00:42:11,990
我们在这里的观察，所以我在下面描述这些片段
clips right on formulations like all right so the

1124
00:42:11,990 --> 00:42:15,140
像这样的公式，所以后验分布参数是
clips right on formulations like all right so the

1125
00:42:15,140 --> 00:42:17,599
像这样的公式，所以后验分布参数是
formulations like all right so the posterior distribution parameter here is

1126
00:42:17,599 --> 00:42:17,609
像这样的公式，所以后验分布参数是
posterior distribution parameter here is Theta and this is improv using the

1127
00:42:17,609 --> 00:42:20,930
Theta和使用来自海外测量的观察数据即兴
posterior distribution parameter here is Theta and this is improv using the

1128
00:42:20,930 --> 00:42:23,390
Theta和使用来自海外测量的观察数据即兴
Theta and this is improv using the observed data from overseas measurements

1129
00:42:23,390 --> 00:42:23,400
Theta和使用来自海外测量的观察数据即兴
observed data from overseas measurements and we can find the posterior

1130
00:42:23,400 --> 00:42:26,359
我们可以使用某种方法找到这个的后验分布
observed data from overseas measurements and we can find the posterior

1131
00:42:26,359 --> 00:42:28,520
我们可以使用某种方法找到这个的后验分布
and we can find the posterior distribution for this using some method

1132
00:42:28,520 --> 00:42:28,530
我们可以使用某种方法找到这个的后验分布
distribution for this using some method like a variational Bayesian method

1133
00:42:28,530 --> 00:42:32,890
像变分贝叶斯方法马尔可夫链马尔可夫链中的蒙特卡洛
distribution for this using some method like a variational Bayesian method

1134
00:42:32,890 --> 00:42:37,039
像变分贝叶斯方法马尔可夫链马尔可夫链中的蒙特卡洛
like a variational Bayesian method Markov chain Monte Carlo in a Markov

1135
00:42:37,039 --> 00:42:37,049
像变分贝叶斯方法马尔可夫链马尔可夫链中的蒙特卡洛
Markov chain Monte Carlo in a Markov chain Monte Carlo gives a more accurate

1136
00:42:37,049 --> 00:42:39,079
链Monte Carlo提供了一个更准确的解决方案，它基本上是
Markov chain Monte Carlo in a Markov chain Monte Carlo gives a more accurate

1137
00:42:39,079 --> 00:42:42,130
链Monte Carlo提供了一个更准确的解决方案，它基本上是
chain Monte Carlo gives a more accurate solution and it is basically

1138
00:42:42,130 --> 00:42:42,140
链Monte Carlo提供了一个更准确的解决方案，它基本上是
solution and it is basically computationally very expensive on the

1139
00:42:42,140 --> 00:42:46,940
另一方面，基于计算的计算非常昂贵
solution and it is basically computationally very expensive on the

1140
00:42:46,940 --> 00:42:49,339
另一方面，基于计算的计算非常昂贵
computationally very expensive on the other hand variational based give us a

1141
00:42:49,339 --> 00:42:49,349
另一方面，基于计算的计算非常昂贵
other hand variational based give us a sum and good approximation to the

1142
00:42:49,349 --> 00:42:52,099
求和与解决方案的良好近似值，它快速且具有
other hand variational based give us a sum and good approximation to the

1143
00:42:52,099 --> 00:42:53,900
求和与解决方案的良好近似值，它快速且具有
sum and good approximation to the solution and it's fast and it has

1144
00:42:53,900 --> 00:42:53,910
求和与解决方案的良好近似值，它快速且具有
solution and it's fast and it has convergence criterion and defined which

1145
00:42:53,910 --> 00:43:04,069
收敛准则并定义近似真实后验的准则，我们
solution and it's fast and it has convergence criterion and defined which

1146
00:43:04,069 --> 00:43:06,680
收敛准则并定义近似真实后验的准则，我们
convergence criterion and defined which approximate the true posterior and we

1147
00:43:06,680 --> 00:43:06,690
收敛准则并定义近似真实后验的准则，我们
approximate the true posterior and we have some lower bound f which

1148
00:43:06,690 --> 00:43:08,750
有一些下界f，近似于
approximate the true posterior and we have some lower bound f which

1149
00:43:08,750 --> 00:43:10,789
有一些下界f，近似于
have some lower bound f which approximates the what the trail of

1150
00:43:10,789 --> 00:43:10,799
有一些下界f，近似于
approximates the what the trail of likelihood and we do iterations until

1151
00:43:10,799 --> 00:43:13,190
可能性，然后进行迭代，直到我们几乎不接触DP为止。
approximates the what the trail of likelihood and we do iterations until

1152
00:43:13,190 --> 00:43:32,900
可能性，然后进行迭代，直到我们几乎不接触DP为止。
likelihood and we do iterations until our little about approaches the DP one

1153
00:43:32,900 --> 00:43:32,910
可能性，然后进行迭代，直到我们几乎不接触DP为止。
our little about approaches the DP one and the relative reconstruction error is

1154
00:43:32,910 --> 00:43:36,640
并使用此方法计算正在计算的相对重建误差
our little about approaches the DP one and the relative reconstruction error is

1155
00:43:36,640 --> 00:43:41,390
并使用此方法计算正在计算的相对重建误差
and the relative reconstruction error is calculating is calculated using this

1156
00:43:41,390 --> 00:43:41,799
好了，所以这是第一张图片，它是一百28 128张图片和一千张图片
and the relative reconstruction error is calculating is calculated using this

1157
00:43:41,799 --> 00:43:41,809
好了，所以这是第一张图片，它是一百28 128张图片和一千张图片


1158
00:43:41,809 --> 00:43:51,079
好了，所以这是第一张图片，它是一百28 128张图片和一千张图片
alright so here's the first image it's a hundred 28 128 image and thousand

1159
00:43:51,079 --> 00:43:51,089
好了，所以这是第一张图片，它是一百28 128张图片和一千张图片
hundred 28 128 image and thousand measurements have been used we can't

1160
00:43:51,089 --> 00:43:53,990
测量已经被使用了，我们基本上不能分解它，然后
hundred 28 128 image and thousand measurements have been used we can't

1161
00:43:53,990 --> 00:43:57,380
测量已经被使用了，我们基本上不能分解它，然后
measurements have been used we can't basically it's decomposed and then the

1162
00:43:57,380 --> 00:43:57,390
测量已经被使用了，我们基本上不能分解它，然后
basically it's decomposed and then the first coefficient story we constructed

1163
00:43:57,390 --> 00:43:59,599
我们构建的第一个系数故事，图像被恢复，这是
basically it's decomposed and then the first coefficient story we constructed

1164
00:43:59,599 --> 00:44:01,880
我们构建的第一个系数故事，图像被恢复，这是
first coefficient story we constructed and the image is recovered and this is

1165
00:44:01,880 --> 00:44:01,890
我们构建的第一个系数故事，图像被恢复，这是
and the image is recovered and this is the relative error second image is

1166
00:44:01,890 --> 00:44:05,059
相对误差第二个图像通过支持估计值向前倾斜，并且
and the image is recovered and this is the relative error second image is

1167
00:44:05,059 --> 00:44:08,559
相对误差第二个图像通过支持估计值向前倾斜，并且
the relative error second image is tilted forward by support estimate and

1168
00:44:08,559 --> 00:44:08,569
相对误差第二个图像通过支持估计值向前倾斜，并且
tilted forward by support estimate and 2500 measurements have been used for

1169
00:44:08,569 --> 00:44:10,880
此测试已使用2500次测量
tilted forward by support estimate and 2500 measurements have been used for

1170
00:44:10,880 --> 00:44:13,160
此测试已使用2500次测量
2500 measurements have been used for this test

1171
00:44:13,160 --> 00:44:13,170
此测试已使用2500次测量
this test and the last one is a 32 by 32 image

1172
00:44:13,170 --> 00:44:17,170
最后一个是32 x 32的图像，已使用两个图像进行了分解
this test and the last one is a 32 by 32 image

1173
00:44:17,170 --> 00:44:21,980
最后一个是32 x 32的图像，已使用两个图像进行了分解
and the last one is a 32 by 32 image which has been decomposed using two

1174
00:44:21,980 --> 00:44:21,990
最后一个是32 x 32的图像，已使用两个图像进行了分解
which has been decomposed using two chocolate reconstructed and then this is

1175
00:44:21,990 --> 00:44:26,960
巧克力重建，然后这是错误，我们已经使用了600
which has been decomposed using two chocolate reconstructed and then this is

1176
00:44:26,960 --> 00:44:29,690
巧克力重建，然后这是错误，我们已经使用了600
chocolate reconstructed and then this is the error and we have used 600

1177
00:44:29,690 --> 00:44:29,700
巧克力重建，然后这是错误，我们已经使用了600
the error and we have used 600 measurements for this all right these

1178
00:44:29,700 --> 00:44:32,900
这些的测量这些都是参考，非常感谢
the error and we have used 600 measurements for this all right these

1179
00:44:32,900 --> 00:44:35,539
这些的测量这些都是参考，非常感谢
measurements for this all right these are the references and thank you very

1180
00:44:35,539 --> 00:44:35,549
这些的测量这些都是参考，非常感谢
are the references and thank you very much any question

1181
00:44:35,549 --> 00:44:44,900
很多问题
are the references and thank you very much any question

1182
00:44:44,900 --> 00:45:51,300
您好，所有来蒂娜（Tina）的朋友，我正在做我的礼物
are the references and thank you very much any question

1183
00:45:51,300 --> 00:45:51,310
您好，所有来蒂娜（Tina）的朋友，我正在做我的礼物


1184
00:45:51,310 --> 00:45:54,760
您好，所有来蒂娜（Tina）的朋友，我正在做我的礼物
hello all visit Tina and I am doing my present

1185
00:45:54,760 --> 00:45:54,770
您好，所有来蒂娜（Tina）的朋友，我正在做我的礼物
present on the pairwise chose Michael Chang

1186
00:45:54,770 --> 00:45:59,280
在两人选择迈克尔·张（Michael Chang）的情况下，我实际上是通过
present on the pairwise chose Michael Chang

1187
00:45:59,280 --> 00:46:03,810
在两人选择迈克尔·张（Michael Chang）的情况下，我实际上是通过
on the pairwise chose Michael Chang actually I produced a paper by the

1188
00:46:03,810 --> 00:46:03,820
在两人选择迈克尔·张（Michael Chang）的情况下，我实际上是通过
actually I produced a paper by the grooving the Stanford University awarded

1189
00:46:03,820 --> 00:46:06,720
在斯坦福大学学习时，获得的奖励比他们向我发布的要多
actually I produced a paper by the grooving the Stanford University awarded

1190
00:46:06,720 --> 00:46:09,220
在斯坦福大学学习时，获得的奖励比他们向我发布的要多
grooving the Stanford University awarded more than they published it in to me

1191
00:46:09,220 --> 00:46:09,230
在斯坦福大学学习时，获得的奖励比他们向我发布的要多
more than they published it in to me next compliment 2016 which is a you know

1192
00:46:09,230 --> 00:46:14,530
下一个恭维2016年这是一个你知道的模型模型离散选择
more than they published it in to me next compliment 2016 which is a you know

1193
00:46:14,530 --> 00:46:17,680
下一个恭维2016年这是一个你知道的模型模型离散选择
next compliment 2016 which is a you know the model the model discrete choice

1194
00:46:17,680 --> 00:46:17,690
下一个恭维2016年这是一个你知道的模型模型离散选择
the model the model discrete choice models and there are developing gates

1195
00:46:17,690 --> 00:46:21,100
模型，现在加利福尼亚州正在开发盖茨
the model the model discrete choice models and there are developing gates

1196
00:46:21,100 --> 00:46:25,080
模型，现在加利福尼亚州正在开发盖茨
models and there are developing gates now in California

1197
00:46:25,080 --> 00:46:25,090
模型，现在加利福尼亚州正在开发盖茨
now in California Caltech used to Berkeley example

1198
00:46:25,090 --> 00:46:27,550
加州理工学院曾经以伯克利大学为例，您实际上会看到我
now in California Caltech used to Berkeley example

1199
00:46:27,550 --> 00:46:35,109
加州理工学院曾经以伯克利大学为例，您实际上会看到我
Caltech used to Berkeley example University and you will see actually I

1200
00:46:35,109 --> 00:46:35,119
加州理工学院曾经以伯克利大学为例，您实际上会看到我
University and you will see actually I want to first of all to I want to bring

1201
00:46:35,119 --> 00:46:37,540
首先，我想带来动力，因为模型
University and you will see actually I want to first of all to I want to bring

1202
00:46:37,540 --> 00:46:41,260
首先，我想带来动力，因为模型
want to first of all to I want to bring the motivation about because models

1203
00:46:41,260 --> 00:46:41,270
首先，我想带来动力，因为模型
the motivation about because models actually the growing the dataset

1204
00:46:41,270 --> 00:46:43,770
实际上，不断增长的数据集包含选择捕获
the motivation about because models actually the growing the dataset

1205
00:46:43,770 --> 00:46:47,140
实际上，不断增长的数据集包含选择捕获
actually the growing the dataset captaining the choice capturing the

1206
00:46:47,140 --> 00:46:47,150
实际上，不断增长的数据集包含选择捕获
captaining the choice capturing the human children in television especially

1207
00:46:47,150 --> 00:46:51,570
电视中的人类儿童，尤其是一些动机和付出的代价
captaining the choice capturing the human children in television especially

1208
00:46:51,570 --> 00:46:55,770
电视中的人类儿童，尤其是一些动机和付出的代价
human children in television especially some motivation and some cost for the

1209
00:46:55,770 --> 00:46:55,780
电视中的人类儿童，尤其是一些动机和付出的代价
some motivation and some cost for the increase meant of the

1210
00:46:55,780 --> 00:46:59,660
增加选择模型的含义，以逃避选择
some motivation and some cost for the increase meant of the

1211
00:46:59,660 --> 00:47:03,859
增加选择模型的含义，以逃避选择
increase meant of the choice model in order to escape from the

1212
00:47:03,859 --> 00:47:03,869
增加选择模型的含义，以逃避选择
choice model in order to escape from the traditional choice period accent for

1213
00:47:03,869 --> 00:47:07,039
传统选择时期的口音，例如规律性或随机性
choice model in order to escape from the traditional choice period accent for

1214
00:47:07,039 --> 00:47:11,319
传统选择时期的口音，例如规律性或随机性
traditional choice period accent for example regularity or stochastic and

1215
00:47:11,319 --> 00:47:11,329
传统选择时期的口音，例如规律性或随机性
example regularity or stochastic and Lucius church action so I want to

1216
00:47:11,329 --> 00:47:16,249
卢修斯教会的行动，所以我想讨论介绍的动机
example regularity or stochastic and Lucius church action so I want to

1217
00:47:16,249 --> 00:47:18,769
卢修斯教会的行动，所以我想讨论介绍的动机
Lucius church action so I want to discuss the motivations for introducing

1218
00:47:18,769 --> 00:47:18,779
卢修斯教会的行动，所以我想讨论介绍的动机
discuss the motivations for introducing this model prepare watch was Markov

1219
00:47:18,779 --> 00:47:21,380
这个模型准备手表是马尔可夫链轻轻地推论它是推论
discuss the motivations for introducing this model prepare watch was Markov

1220
00:47:21,380 --> 00:47:24,859
这个模型准备手表是马尔可夫链轻轻地推论它是推论
this model prepare watch was Markov chain is gently model it is inferential

1221
00:47:24,859 --> 00:47:24,869
这个模型准备手表是马尔可夫链轻轻地推论它是推论
chain is gently model it is inferential interactive graphical model and it does

1222
00:47:24,869 --> 00:47:28,249
交互式图形模型，但没有显示我提及公理生产者
chain is gently model it is inferential interactive graphical model and it does

1223
00:47:28,249 --> 00:47:32,299
交互式图形模型，但没有显示我提及公理生产者
interactive graphical model and it does not show me mention axiom producer

1224
00:47:32,299 --> 00:47:32,309
交互式图形模型，但没有显示我提及公理生产者
not show me mention axiom producer active and insisted upon the foundation

1225
00:47:32,309 --> 00:47:35,239
积极并坚持行动提取的基础，因此这种离散
not show me mention axiom producer active and insisted upon the foundation

1226
00:47:35,239 --> 00:47:43,009
积极并坚持行动提取的基础，因此这种离散
active and insisted upon the foundation of action extraction so this discrete

1227
00:47:43,009 --> 00:47:43,019
积极并坚持行动提取的基础，因此这种离散
of action extraction so this discrete choice models destroyed and actually

1228
00:47:43,019 --> 00:47:45,950
选择模型被破坏并实际上预测了受害者之间的决定
of action extraction so this discrete choice models destroyed and actually

1229
00:47:45,950 --> 00:47:51,289
选择模型被破坏并实际上预测了受害者之间的决定
choice models destroyed and actually predicted the decision between victim

1230
00:47:51,289 --> 00:47:51,670
替代方案以及应用程序或消费者购买决策，以及
choice models destroyed and actually predicted the decision between victim

1231
00:47:51,670 --> 00:47:51,680
替代方案以及应用程序或消费者购买决策，以及


1232
00:47:51,680 --> 00:47:57,099
替代方案以及应用程序或消费者购买决策，以及
alternatives and the applications or consumer purchasing decisions and

1233
00:47:57,099 --> 00:47:57,109
替代方案以及应用程序或消费者购买决策，以及
consumer purchasing decisions and community changes in the mode for

1234
00:47:57,109 --> 00:47:59,650
社区改变了向长途运输方式的运输方式
consumer purchasing decisions and community changes in the mode for

1235
00:47:59,650 --> 00:48:03,079
社区改变了向长途运输方式的运输方式
community changes in the mode for transportation to long available options

1236
00:48:03,079 --> 00:48:03,089
社区改变了向长途运输方式的运输方式
transportation to long available options so there is a pressing need for

1237
00:48:03,089 --> 00:48:05,900
因此迫切需要能够描述
transportation to long available options so there is a pressing need for

1238
00:48:05,900 --> 00:48:09,319
因此迫切需要能够描述
so there is a pressing need for practical model capable of is describing

1239
00:48:09,319 --> 00:48:09,329
因此迫切需要能够描述
practical model capable of is describing and predicting the choice behaviour

1240
00:48:09,329 --> 00:48:14,239
并预测选择行为
practical model capable of is describing and predicting the choice behaviour

1241
00:48:14,239 --> 00:48:15,809
因此，其中一位志愿者实际上可以说是最重要的
practical model capable of is describing and predicting the choice behaviour

1242
00:48:15,809 --> 00:48:15,819
因此，其中一位志愿者实际上可以说是最重要的


1243
00:48:15,819 --> 00:48:25,289
因此，其中一位志愿者实际上可以说是最重要的
so one of the volunteer very actually arguably one of the most important of

1244
00:48:25,289 --> 00:48:25,299
因此，其中一位志愿者实际上可以说是最重要的
arguably one of the most important of these excellent to our solutions Church

1245
00:48:25,299 --> 00:48:28,109
这些对我们的解决方案非常出色的教会公理，即独立性
arguably one of the most important of these excellent to our solutions Church

1246
00:48:28,109 --> 00:48:31,859
这些对我们的解决方案非常出色的教会公理，即独立性
these excellent to our solutions Church axiom which is known as the independence

1247
00:48:31,859 --> 00:48:31,869
这些对我们的解决方案非常出色的教会公理，即独立性
axiom which is known as the independence of irrelevant alternatives

1248
00:48:31,869 --> 00:48:35,159
不相关的替代品
axiom which is known as the independence of irrelevant alternatives

1249
00:48:35,159 --> 00:48:35,539
因此，举例来说，我们将此公理应用于物质替代品和史密斯
axiom which is known as the independence of irrelevant alternatives

1250
00:48:35,539 --> 00:48:35,549
因此，举例来说，我们将此公理应用于物质替代品和史密斯


1251
00:48:35,549 --> 00:48:43,649
因此，举例来说，我们将此公理应用于物质替代品和史密斯
so it's example we applied this axiom on the substance alternatives and Smith

1252
00:48:43,649 --> 00:48:43,659
因此，举例来说，我们将此公理应用于物质替代品和史密斯
the substance alternatives and Smith even broader universe you we want to

1253
00:48:43,659 --> 00:48:46,919
您想定义一些概率的更广阔的宇宙让pas PD
the substance alternatives and Smith even broader universe you we want to

1254
00:48:46,919 --> 00:48:50,399
您想定义一些概率的更广阔的宇宙让pas PD
even broader universe you we want to define some probabilities let pas PD

1255
00:48:50,399 --> 00:48:50,409
您想定义一些概率的更广阔的宇宙让pas PD
define some probabilities let pas PD process a chosen from the best beginner

1256
00:48:50,409 --> 00:48:55,819
从最佳初学者中选择一个最佳人选，并在基板视图上进行处理；
define some probabilities let pas PD process a chosen from the best beginner

1257
00:48:55,819 --> 00:48:58,439
从最佳初学者中选择一个最佳人选，并在基板视图上进行处理；
process a chosen from the best beginner as the best with the substrate view and

1258
00:48:58,439 --> 00:48:58,449
从最佳初学者中选择一个最佳人选，并在基板视图上进行处理；
as the best with the substrate view and peds the problem chosen a fine chosen

1259
00:48:58,449 --> 00:49:02,099
peds问题从这八个事件中选择了一个很好的问题，例如我们
as the best with the substrate view and peds the problem chosen a fine chosen

1260
00:49:02,099 --> 00:49:04,139
peds问题从这八个事件中选择了一个很好的问题，例如我们
peds the problem chosen a fine chosen from these eight events for example we

1261
00:49:04,139 --> 00:49:04,149
peds问题从这八个事件中选择了一个很好的问题，例如我们
from these eight events for example we have two elements there are two

1262
00:49:04,149 --> 00:49:09,209
有两个要素每个英语考试都有两个重要的陈述P
from these eight events for example we have two elements there are two

1263
00:49:09,209 --> 00:49:13,379
有两个要素每个英语考试都有两个重要的陈述P
have two elements there are two important statement English exam each P

1264
00:49:13,379 --> 00:49:13,389
有两个要素每个英语考试都有两个重要的陈述P
important statement English exam each P AV is equal to zero then pas will be 0

1265
00:49:13,389 --> 00:49:16,349
AV等于零，那么对于所有包含和B的进度，pas将为0
important statement English exam each P AV is equal to zero then pas will be 0

1266
00:49:16,349 --> 00:49:20,639
AV等于零，那么对于所有包含和B的进度，pas将为0
AV is equal to zero then pas will be 0 for all contain and B the progress of

1267
00:49:20,639 --> 00:49:20,649
AV等于零，那么对于所有包含和B的进度，pas将为0
for all contain and B the progress of choosing and from you condition on the

1268
00:49:20,649 --> 00:49:22,889
选择并根据您的条件选择线上的条件等于3/8，所以另一个
for all contain and B the progress of choosing and from you condition on the

1269
00:49:22,889 --> 00:49:28,319
选择并根据您的条件选择线上的条件等于3/8，所以另一个
choosing and from you condition on the choice line is equal to 3/8 so another

1270
00:49:28,319 --> 00:49:28,329
选择并根据您的条件选择线上的条件等于3/8，所以另一个
choice line is equal to 3/8 so another another model easy

1271
00:49:28,329 --> 00:49:30,799
另一个模型轻松的布拉德利转宽松模型实际上做了
choice line is equal to 3/8 so another another model easy

1272
00:49:30,799 --> 00:49:34,289
另一个模型轻松的布拉德利转宽松模型实际上做了
another model easy Bradley turn loose model actually did

1273
00:49:34,289 --> 00:49:34,299
另一个模型轻松的布拉德利转宽松模型实际上做了
Bradley turn loose model actually did this model I referred it it's got some

1274
00:49:34,299 --> 00:49:38,219
我提到的这个模型有一些关于等级封锁的想法
Bradley turn loose model actually did this model I referred it it's got some

1275
00:49:38,219 --> 00:49:42,329
我提到的这个模型有一些关于等级封锁的想法
this model I referred it it's got some idea about the rank blocking in detail

1276
00:49:42,329 --> 00:49:42,339
我提到的这个模型有一些关于等级封锁的想法
idea about the rank blocking in detail comparison so it has been published in

1277
00:49:42,339 --> 00:49:46,219
比较，因此它在1956年发布，实际上定义了PAE
idea about the rank blocking in detail comparison so it has been published in

1278
00:49:46,219 --> 00:49:50,399
比较，因此它在1956年发布，实际上定义了PAE
comparison so it has been published in 1956 it actually define the PAE

1279
00:49:50,399 --> 00:49:50,409
比较，因此它在1956年发布，实际上定义了PAE
1956 it actually define the PAE and gamma I over gamma a plus gamma

1280
00:49:50,409 --> 00:49:53,969
潜在质量参数伦敦之前，伽玛I超过伽玛加伽玛
1956 it actually define the PAE and gamma I over gamma a plus gamma

1281
00:49:53,969 --> 00:49:56,849
潜在质量参数伦敦之前，伽玛I超过伽玛加伽玛
and gamma I over gamma a plus gamma before latent quality parameters London

1282
00:49:56,849 --> 00:49:56,859
潜在质量参数伦敦之前，伽玛I超过伽玛加伽玛
before latent quality parameters London gamma I and he resulting

1283
00:49:56,859 --> 00:50:02,240
伽玛I和他产生的logit模型员工
before latent quality parameters London gamma I and he resulting

1284
00:50:02,240 --> 00:50:05,600
伽玛I和他产生的logit模型员工
gamma I and he resulting logit model employee

1285
00:50:05,600 --> 00:50:05,610
伽玛I和他产生的logit模型员工
logit model employee Visconti parameter gamma i for each i

1286
00:50:05,610 --> 00:50:08,810
每个i的Visconti参数gamma i都有您的数目，因此任何模型
logit model employee Visconti parameter gamma i for each i

1287
00:50:08,810 --> 00:50:13,280
每个i的Visconti参数gamma i都有您的数目，因此任何模型
Visconti parameter gamma i for each i has the number of you so any model that

1288
00:50:13,280 --> 00:50:13,290
每个i的Visconti参数gamma i都有您的数目，因此任何模型
has the number of you so any model that satisfied the dilution axiom is a cool

1289
00:50:13,290 --> 00:50:16,640
满足稀释公理是一个很酷的不等式
has the number of you so any model that satisfied the dilution axiom is a cool

1290
00:50:16,640 --> 00:50:17,720
满足稀释公理是一个很酷的不等式
satisfied the dilution axiom is a cool inequities

1291
00:50:17,720 --> 00:50:17,730
满足稀释公理是一个很酷的不等式
inequities mmm model so one consequence

1292
00:50:17,730 --> 00:50:23,980
mmm模型，所以实际上我在谈论一个结果
inequities mmm model so one consequence

1293
00:50:23,980 --> 00:50:26,980
mmm模型，所以实际上我在谈论一个结果
mmm model so one consequence actually I am talking about the

1294
00:50:26,980 --> 00:50:26,990
mmm模型，所以实际上我在谈论一个结果
actually I am talking about the different models traditional models and

1295
00:50:26,990 --> 00:50:30,290
不同的模式，传统的模式和后果，然后我想
actually I am talking about the different models traditional models and

1296
00:50:30,290 --> 00:50:32,480
不同的模式，传统的模式和后果，然后我想
different models traditional models and the consequences and then I want to

1297
00:50:32,480 --> 00:50:32,490
不同的模式，传统的模式和后果，然后我想
the consequences and then I want to preach the efficiency and to say that

1298
00:50:32,490 --> 00:50:35,330
讲效率，说鸽子做得更好，
the consequences and then I want to preach the efficiency and to say that

1299
00:50:35,330 --> 00:50:37,970
讲效率，说鸽子做得更好，
preach the efficiency and to say that pigeons is doing a better job and a

1300
00:50:37,970 --> 00:50:37,980
讲效率，说鸽子做得更好，
pigeons is doing a better job and a great job in comparison to the

1301
00:50:37,980 --> 00:50:39,920
与传统的选择模型相比，出色的工作之一是
pigeons is doing a better job and a great job in comparison to the

1302
00:50:39,920 --> 00:50:43,670
与传统的选择模型相比，出色的工作之一是
great job in comparison to the traditional choice model one consequence

1303
00:50:43,670 --> 00:50:43,680
与传统的选择模型相比，出色的工作之一是
traditional choice model one consequence of these lucious action model is a

1304
00:50:43,680 --> 00:50:46,430
这些柔和的行为模型之间的随机传递性是
traditional choice model one consequence of these lucious action model is a

1305
00:50:46,430 --> 00:50:48,620
这些柔和的行为模型之间的随机传递性是
of these lucious action model is a stochastic transitivity between

1306
00:50:48,620 --> 00:50:48,630
这些柔和的行为模型之间的随机传递性是
stochastic transitivity between alternatives chance dignity means for

1307
00:50:48,630 --> 00:50:51,200
替代品机会尊严意味着，例如，我们有两个要素，我们有一个
stochastic transitivity between alternatives chance dignity means for

1308
00:50:51,200 --> 00:50:54,200
替代品机会尊严意味着，例如，我们有两个要素，我们有一个
alternatives chance dignity means for example we have two elements we have an

1309
00:50:54,200 --> 00:50:54,210
替代品机会尊严意味着，例如，我们有两个要素，我们有一个
example we have two elements we have an a has a connection with the BBC we can

1310
00:50:54,210 --> 00:50:58,340
一个与英国广播公司有联系，我们可以说之间存在音乐关系
example we have two elements we have an a has a connection with the BBC we can

1311
00:50:58,340 --> 00:51:00,680
一个与英国广播公司有联系，我们可以说之间存在音乐关系
a has a connection with the BBC we can say that there is music relation between

1312
00:51:00,680 --> 00:51:00,690
一个与英国广播公司有联系，我们可以说之间存在音乐关系
say that there is music relation between a and C alternative so it's the

1313
00:51:00,690 --> 00:51:04,970
a和C替代，所以PID的概率大于等于
say that there is music relation between a and C alternative so it's the

1314
00:51:04,970 --> 00:51:10,070
a和C替代，所以PID的概率大于等于
a and C alternative so it's the probability of PID greater than equals

1315
00:51:10,070 --> 00:51:10,080
a和C替代，所以PID的概率大于等于
probability of PID greater than equals 1/2 and also the for P then th means

1316
00:51:10,080 --> 00:51:13,520
1/2以及P的th均等于或大于营销
probability of PID greater than equals 1/2 and also the for P then th means

1317
00:51:13,520 --> 00:51:16,670
1/2以及P的th均等于或大于营销
1/2 and also the for P then th means equal to or greater than the marketing

1318
00:51:16,670 --> 00:51:16,680
1/2以及P的th均等于或大于营销
equal to or greater than the marketing world ta bian BC a broad important class

1319
00:51:16,680 --> 00:51:20,750
世界ta bian BC在贸易展览研究中的重要类别的模型
equal to or greater than the marketing world ta bian BC a broad important class

1320
00:51:20,750 --> 00:51:22,910
世界ta bian BC在贸易展览研究中的重要类别的模型
world ta bian BC a broad important class of models in a study of the trade shows

1321
00:51:22,910 --> 00:51:22,920
世界ta bian BC在贸易展览研究中的重要类别的模型
of models in a study of the trade shows in this ranch house or us or random

1322
00:51:22,920 --> 00:51:26,960
在这个牧场房子或我们或随机公用事业模型中，其附属机构每个我
of models in a study of the trade shows in this ranch house or us or random

1323
00:51:26,960 --> 00:51:31,430
在这个牧场房子或我们或随机公用事业模型中，其附属机构每个我
in this ranch house or us or random utility models its affiliates each I at

1324
00:51:31,430 --> 00:51:31,440
在这个牧场房子或我们或随机公用事业模型中，其附属机构每个我
utility models its affiliates each I at the member of the broader universe you

1325
00:51:31,440 --> 00:51:33,530
您和更广泛的宇宙的成员你和一个随机变量I
utility models its affiliates each I at the member of the broader universe you

1326
00:51:33,530 --> 00:51:38,450
您和更广泛的宇宙的成员你和一个随机变量I
the member of the broader universe you and a random variable each I and it

1327
00:51:38,450 --> 00:51:38,460
您和更广泛的宇宙的成员你和一个随机变量I
and a random variable each I and it defines the probability of our children

1328
00:51:38,460 --> 00:51:41,060
定义s的子概率为
and a random variable each I and it defines the probability of our children

1329
00:51:41,060 --> 00:51:44,120
定义s的子概率为
defines the probability of our children from s as this expression probability of

1330
00:51:44,120 --> 00:51:44,130
定义s的子概率为
from s as this expression probability of X greater than or equal to XJ for any J

1331
00:51:44,130 --> 00:51:48,329
对于所有um的任何J，X都大于或等于XJ
from s as this expression probability of X greater than or equal to XJ for any J

1332
00:51:48,329 --> 00:51:51,569
对于所有um的任何J，X都大于或等于XJ
X greater than or equal to XJ for any J at all um

1333
00:51:51,569 --> 00:51:51,579
对于所有um的任何J，X都大于或等于XJ
at all um don't neither choice as in north the

1334
00:51:51,579 --> 00:51:54,029
既不像北方天主教传递性那样选择，所以现在PNC
at all um don't neither choice as in north the

1335
00:51:54,029 --> 00:52:03,479
既不像北方天主教传递性那样选择，所以现在PNC
don't neither choice as in north the Catholic transitivity so now the PNC

1336
00:52:03,479 --> 00:52:03,489
既不像北方天主教传递性那样选择，所以现在PNC
Catholic transitivity so now the PNC model it is computationally imple

1337
00:52:03,489 --> 00:52:08,269
建模，从概念上讲在计算上是简单的，而复杂的简单
Catholic transitivity so now the PNC model it is computationally imple

1338
00:52:08,269 --> 00:52:10,529
建模，从概念上讲在计算上是简单的，而复杂的简单
model it is computationally imple conceptually and complicated simple and

1339
00:52:10,529 --> 00:52:10,539
建模，从概念上讲在计算上是简单的，而复杂的简单
conceptually and complicated simple and in fresh a tractable model there are

1340
00:52:10,539 --> 00:52:13,349
在新鲜易处理的模型中，有一些参数我们有一些参数
conceptually and complicated simple and in fresh a tractable model there are

1341
00:52:13,349 --> 00:52:14,999
在新鲜易处理的模型中，有一些参数我们有一些参数
in fresh a tractable model there are some parameters we have some parameters

1342
00:52:14,999 --> 00:52:15,009
在新鲜易处理的模型中，有一些参数我们有一些参数
some parameters we have some parameters in this model the afterburner induced Qi

1343
00:52:15,009 --> 00:52:19,319
在此模型中，加力诱发的Qi生成矩阵Q指数值，并且
some parameters we have some parameters in this model the afterburner induced Qi

1344
00:52:19,319 --> 00:52:24,479
在此模型中，加力诱发的Qi生成矩阵Q指数值，并且
in this model the afterburner induced Qi generates matrix Q index value and also

1345
00:52:24,479 --> 00:52:24,489
在此模型中，加力诱发的Qi生成矩阵Q指数值，并且
generates matrix Q index value and also if this defines the P is the collection

1346
00:52:24,489 --> 00:52:27,359
如果这将P定义为替代品的收集概率为
generates matrix Q index value and also if this defines the P is the collection

1347
00:52:27,359 --> 00:52:30,719
如果这将P定义为替代品的收集概率为
if this defines the P is the collection probability of alternatives as the

1348
00:52:30,719 --> 00:52:30,729
如果这将P定义为替代品的收集概率为
probability of alternatives as the probability mass of the genetic eye of

1349
00:52:30,729 --> 00:52:33,870
遗传位点的概率质量及其分布
probability of alternatives as the probability mass of the genetic eye of

1350
00:52:33,870 --> 00:52:36,630
遗传位点的概率质量及其分布
probability mass of the genetic eye of take station and distribution of the

1351
00:52:36,630 --> 00:52:36,640
遗传位点的概率质量及其分布
take station and distribution of the continuous time Markov chain the

1352
00:52:36,640 --> 00:52:41,549
连续时间马尔可夫链的平稳分布实际上是
take station and distribution of the continuous time Markov chain the

1353
00:52:41,549 --> 00:52:43,950
连续时间马尔可夫链的平稳分布实际上是
continuous time Markov chain the stationary distribution actually the

1354
00:52:43,950 --> 00:52:43,960
连续时间马尔可夫链的平稳分布实际上是
stationary distribution actually the stationary distribution in the Mark of

1355
00:52:43,960 --> 00:52:45,809
平稳分布在变化标记中的概率可以是
stationary distribution actually the stationary distribution in the Mark of

1356
00:52:45,809 --> 00:52:48,920
平稳分布在变化标记中的概率可以是
stationary distribution in the Mark of change the probability which can be

1357
00:52:48,920 --> 00:52:48,930
平稳分布在变化标记中的概率可以是
change the probability which can be shown between Mexico and the in this

1358
00:52:48,930 --> 00:52:53,130
显示在墨西哥和这个虚拟的之间，我们有一些问题
change the probability which can be shown between Mexico and the in this

1359
00:52:53,130 --> 00:52:55,229
显示在墨西哥和这个虚拟的之间，我们有一些问题
shown between Mexico and the in this virtual we have some problems with

1360
00:52:55,229 --> 00:52:55,239
显示在墨西哥和这个虚拟的之间，我们有一些问题
virtual we have some problems with distribution coming to one and if if you

1361
00:52:55,239 --> 00:52:58,519
分布为一，如果将Phi换位乘以DQ
virtual we have some problems with distribution coming to one and if if you

1362
00:52:58,519 --> 00:53:04,079
分布为一，如果将Phi换位乘以DQ
distribution coming to one and if if you multiply the Phi transpose to DQ between

1363
00:53:04,079 --> 00:53:04,089
分布为一，如果将Phi换位乘以DQ
multiply the Phi transpose to DQ between the rate matrix you get the you get

1364
00:53:04,089 --> 00:53:06,569
您获得的费率矩阵就离开了，因此
multiply the Phi transpose to DQ between the rate matrix you get the you get

1365
00:53:06,569 --> 00:53:10,040
您获得的费率矩阵就离开了，因此
the rate matrix you get the you get depart so

1366
00:53:10,040 --> 00:53:10,050
您获得的费率矩阵就离开了，因此
depart so the station is the reason change to

1367
00:53:10,050 --> 00:53:12,650
车站是找到满足固定需求的原因
depart so the station is the reason change to

1368
00:53:12,650 --> 00:53:15,950
车站是找到满足固定需求的原因
the station is the reason change to found to satisfy the stationary

1369
00:53:15,950 --> 00:53:15,960
车站是找到满足固定需求的原因
found to satisfy the stationary condition of the eminent likelihood

1370
00:53:15,960 --> 00:53:17,990
似然函数的条件并建立一个强
found to satisfy the stationary condition of the eminent likelihood

1371
00:53:17,990 --> 00:53:20,360
似然函数的条件并建立一个强
condition of the eminent likelihood function and establishing a strong

1372
00:53:20,360 --> 00:53:20,370
似然函数的条件并建立一个强
function and establishing a strong connection between another model and

1373
00:53:20,370 --> 00:53:23,350
尽管pcrc模型概括了另一个模型之间的连接
function and establishing a strong connection between another model and

1374
00:53:23,350 --> 00:53:27,230
尽管pcrc模型概括了另一个模型之间的连接
connection between another model and though the pcrc model generalizes

1375
00:53:27,230 --> 00:53:27,240
尽管pcrc模型概括了另一个模型之间的连接
though the pcrc model generalizes disconnection between terminal

1376
00:53:27,240 --> 00:53:29,030
终端再营销之间的脱节是Shema所做的
though the pcrc model generalizes disconnection between terminal

1377
00:53:29,030 --> 00:53:35,060
终端再营销之间的脱节是Shema所做的
disconnection between terminal remarketing this is the Shema did the

1378
00:53:35,060 --> 00:53:35,070
终端再营销之间的脱节是Shema所做的
remarketing this is the Shema did the left side is the schematic view of the

1379
00:53:35,070 --> 00:53:36,980
左侧是马尔可夫链的四个选择a和b BN c的示意图
remarketing this is the Shema did the left side is the schematic view of the

1380
00:53:36,980 --> 00:53:40,580
左侧是马尔可夫链的四个选择a和b BN c的示意图
left side is the schematic view of the markov chains four choices a and b BN c

1381
00:53:40,580 --> 00:53:40,590
左侧是马尔可夫链的四个选择a和b BN c的示意图
markov chains four choices a and b BN c EST those arrows the thickness of those

1382
00:53:40,590 --> 00:53:44,000
EST那些箭头的粗细是那些箭头的比率
markov chains four choices a and b BN c EST those arrows the thickness of those

1383
00:53:44,000 --> 00:53:48,200
EST那些箭头的粗细是那些箭头的比率
EST those arrows the thickness of those arrows are the rate the rate of

1384
00:53:48,200 --> 00:53:48,210
EST那些箭头的粗细是那些箭头的比率
arrows are the rate the rate of transition the right side is the

1385
00:53:48,210 --> 00:53:52,010
过渡的右侧正是这些选择的集合
arrows are the rate the rate of transition the right side is the

1386
00:53:52,010 --> 00:53:55,370
过渡的右侧正是这些选择的集合
transition the right side is the assembly of these exactly these choices

1387
00:53:55,370 --> 00:53:55,380
过渡的右侧正是这些选择的集合
assembly of these exactly these choices in the descrition triangle shape Vince

1388
00:53:55,380 --> 00:54:02,350
在描述三角形形状的文斯过渡速率中，因此我们定义了一些
assembly of these exactly these choices in the descrition triangle shape Vince

1389
00:54:02,350 --> 00:54:06,350
在描述三角形形状的文斯过渡速率中，因此我们定义了一些
in the descrition triangle shape Vince transition rates so we define some

1390
00:54:06,350 --> 00:54:06,360
在描述三角形形状的文斯过渡速率中，因此我们定义了一些
transition rates so we define some actually imposed some constraint here

1391
00:54:06,360 --> 00:54:09,050
实际上在这里施加了一些约束，这是他们经历过的一个气
transition rates so we define some actually imposed some constraint here

1392
00:54:09,050 --> 00:54:11,900
实际上在这里施加了一些约束，这是他们经历过的一个气
actually imposed some constraint here which is a Qi they've lived through plus

1393
00:54:11,900 --> 00:54:11,910
实际上在这里施加了一些约束，这是他们经历过的一个气
which is a Qi they've lived through plus QJ r is equal to greater than 1 for all

1394
00:54:11,910 --> 00:54:15,050
对于所有填充IJ，QJ r均大于1，这是
which is a Qi they've lived through plus QJ r is equal to greater than 1 for all

1395
00:54:15,050 --> 00:54:20,510
对于所有填充IJ，QJ r均大于1，这是
QJ r is equal to greater than 1 for all fills IJ which is the reducibility in

1396
00:54:20,510 --> 00:54:20,520
对于所有填充IJ，QJ r均大于1，这是
fills IJ which is the reducibility in short the irreducibility in our model so

1397
00:54:20,520 --> 00:54:23,300
简短说明了我们模型的不可约性，因此给定了s并记为
fills IJ which is the reducibility in short the irreducibility in our model so

1398
00:54:23,300 --> 00:54:25,730
简短说明了我们模型的不可约性，因此给定了s并记为
short the irreducibility in our model so given a set s and remember as a

1399
00:54:25,730 --> 00:54:25,740
简短说明了我们模型的不可约性，因此给定了s并记为
given a set s and remember as a substitute view we want to know we can

1400
00:54:25,740 --> 00:54:28,550
我们想知道的替代视图可以通过以下方式控制Cure的构造函数
given a set s and remember as a substitute view we want to know we can

1401
00:54:28,550 --> 00:54:31,160
我们想知道的替代视图可以通过以下方式控制Cure的构造函数
substitute view we want to know we can control the Cure's constructors by

1402
00:54:31,160 --> 00:54:31,170
我们想知道的替代视图可以通过以下方式控制Cure的构造函数
control the Cure's constructors by restricting you can do that but

1403
00:54:31,170 --> 00:54:33,620
限制您可以执行此操作，但要重新训练q 2的行和列
control the Cure's constructors by restricting you can do that but

1404
00:54:33,620 --> 00:54:38,600
限制您可以执行此操作，但要重新训练q 2的行和列
restricting you can do that but retraining the rows and columns of q 2

1405
00:54:38,600 --> 00:54:38,610
限制您可以执行此操作，但要重新训练q 2的行和列
retraining the rows and columns of q 2 elements instead and set the Q III as

1406
00:54:38,610 --> 00:54:41,630
取而代之的是将Q III设置为这样的表达和我们的观点是
retraining the rows and columns of q 2 elements instead and set the Q III as

1407
00:54:41,630 --> 00:54:45,970
取而代之的是将Q III设置为这样的表达和我们的观点是
elements instead and set the Q III as this expression and peopIe of us is

1408
00:54:45,970 --> 00:54:45,980
取而代之的是将Q III设置为这样的表达和我们的观点是
this expression and peopIe of us is these

1409
00:54:45,980 --> 00:54:47,360
这些达到固定分布
this expression and peopIe of us is these

1410
00:54:47,360 --> 00:54:49,880
这些达到固定分布
these reaching the stationary distribution of

1411
00:54:49,880 --> 00:54:49,890
这些达到固定分布
reaching the stationary distribution of people

1412
00:54:49,890 --> 00:54:51,069
人们要改变，所以跑步的选择
reaching the stationary distribution of people

1413
00:54:51,069 --> 00:54:55,029
人们要改变，所以跑步的选择
people to change so the running the choice

1414
00:54:55,029 --> 00:54:55,039
人们要改变，所以跑步的选择
to change so the running the choice probability P is which is equal to PI of

1415
00:54:55,039 --> 00:54:58,209
P的概率等于I的PI，现在我们要证明
to change so the running the choice probability P is which is equal to PI of

1416
00:54:58,209 --> 00:55:01,209
P的概率等于I的PI，现在我们要证明
probability P is which is equal to PI of I we now want to show that the piece

1417
00:55:01,209 --> 00:55:01,219
P的概率等于I的PI，现在我们要证明
I we now want to show that the piece density model is the del define so

1418
00:55:01,219 --> 00:55:05,829
密度模型是del定义的，因此我们想证明一个命题
I we now want to show that the piece density model is the del define so

1419
00:55:05,829 --> 00:55:08,349
密度模型是del定义的，因此我们想证明一个命题
density model is the del define so proposition one we want to show that

1420
00:55:08,349 --> 00:55:08,359
密度模型是del定义的，因此我们想证明一个命题
proposition one we want to show that these nice choice probabilities are

1421
00:55:08,359 --> 00:55:09,999
这些很好的选择概率对于I作为as的成员是明确定义的
proposition one we want to show that these nice choice probabilities are

1422
00:55:09,999 --> 00:55:13,959
这些很好的选择概率对于I作为as的成员是明确定义的
these nice choice probabilities are well-defined for the I as a member of as

1423
00:55:13,959 --> 00:55:13,969
这些很好的选择概率对于I作为as的成员是明确定义的
well-defined for the I as a member of as an all-access as some of you this is

1424
00:55:13,969 --> 00:55:17,859
你们当中有些人无所不能，这是某种问题，
well-defined for the I as a member of as an all-access as some of you this is

1425
00:55:17,859 --> 00:55:19,870
你们当中有些人无所不能，这是某种问题，
an all-access as some of you this is some sort of problem that in order to

1426
00:55:19,870 --> 00:55:19,880
你们当中有些人无所不能，这是某种问题，
some sort of problem that in order to prove it B we need to assume something

1427
00:55:19,880 --> 00:55:24,549
证明它B我们需要对我们要证明的目标采取一些假设
some sort of problem that in order to prove it B we need to assume something

1428
00:55:24,549 --> 00:55:26,920
证明它B我们需要对我们要证明的目标采取一些假设
prove it B we need to assume something against the target that we want to prove

1429
00:55:26,920 --> 00:55:26,930
证明它B我们需要对我们要证明的目标采取一些假设
against the target that we want to prove and continually some contradiction so in

1430
00:55:26,930 --> 00:55:33,069
并不断出现一些矛盾，因此为了证明这一点是明确的
against the target that we want to prove and continually some contradiction so in

1431
00:55:33,069 --> 00:55:35,499
并不断出现一些矛盾，因此为了证明这一点是明确的
and continually some contradiction so in order to prove that this is well-defined

1432
00:55:35,499 --> 00:55:35,509
并不断出现一些矛盾，因此为了证明这一点是明确的
order to prove that this is well-defined I need to show that it there is just

1433
00:55:35,509 --> 00:55:38,859
我需要证明，只有一门我们知道的交流课
order to prove that this is well-defined I need to show that it there is just

1434
00:55:38,859 --> 00:55:41,920
我需要证明，只有一门我们知道的交流课
I need to show that it there is just only one communication class we know

1435
00:55:41,920 --> 00:55:41,930
我需要证明，只有一门我们知道的交流课
only one communication class we know that s finite so there must be on just

1436
00:55:41,930 --> 00:55:46,479
那是有限的，所以这里必须只有一个交流课，所以我知道
only one communication class we know that s finite so there must be on just

1437
00:55:46,479 --> 00:55:50,049
那是有限的，所以这里必须只有一个交流课，所以我知道
that s finite so there must be on just one communication class here so I know

1438
00:55:50,049 --> 00:55:50,059
那是有限的，所以这里必须只有一个交流课，所以我知道
one communication class here so I know that to me more than one through

1439
00:55:50,059 --> 00:55:52,930
通过实验课对我来说不止一个，但是我知道
one communication class here so I know that to me more than one through

1440
00:55:52,930 --> 00:55:55,630
通过实验课对我来说不止一个，但是我知道
that to me more than one through experimentation class but I know that

1441
00:55:55,630 --> 00:55:55,640
通过实验课对我来说不止一个，但是我知道
experimentation class but I know that face under a disability link constraint

1442
00:55:55,640 --> 00:55:58,749
施加残障的残障链接约束下的脸，我知道QIJ
experimentation class but I know that face under a disability link constraint

1443
00:55:58,749 --> 00:56:02,650
施加残障的残障链接约束下的脸，我知道QIJ
face under a disability link constraint imposing a disability I know that Q I J

1444
00:56:02,650 --> 00:56:02,660
施加残障的残障链接约束下的脸，我知道QIJ
imposing a disability I know that Q I J plus 2 J I is greater than or equal to 1

1445
00:56:02,660 --> 00:56:05,979
加2 JI大于或等于1，因此这些q IJ中的至少一个或两个
imposing a disability I know that Q I J plus 2 J I is greater than or equal to 1

1446
00:56:05,979 --> 00:56:09,579
加2 JI大于或等于1，因此这些q IJ中的至少一个或两个
plus 2 J I is greater than or equal to 1 and so at least one of these q IJ or two

1447
00:56:09,579 --> 00:56:09,589
加2 JI大于或等于1，因此这些q IJ中的至少一个或两个
and so at least one of these q IJ or two jurors should be strictly positive and

1448
00:56:09,589 --> 00:56:12,099
陪审员应该严格肯定，这意味着有一些
and so at least one of these q IJ or two jurors should be strictly positive and

1449
00:56:12,099 --> 00:56:16,089
陪审员应该严格肯定，这意味着有一些
jurors should be strictly positive and this implies that there is there is some

1450
00:56:16,089 --> 00:56:16,099
陪审员应该严格肯定，这意味着有一些
this implies that there is there is some screeching distinct communication

1451
00:56:16,099 --> 00:56:17,650
努力学习不同的交流课程，等等
this implies that there is there is some screeching distinct communication

1452
00:56:17,650 --> 00:56:20,840
努力学习不同的交流课程，等等
screeching distinct communication classes and so

1453
00:56:20,840 --> 00:56:20,850
努力学习不同的交流课程，等等
classes and so this is undetermined which would be done

1454
00:56:20,850 --> 00:56:23,720
这是不确定的，可以通过变速箱完成
classes and so this is undetermined which would be done

1455
00:56:23,720 --> 00:56:25,340
这是不确定的，可以通过变速箱完成
this is undetermined which would be done through the transmission

1456
00:56:25,340 --> 00:56:25,350
这是不确定的，可以通过变速箱完成
through the transmission it's tricky positively which is the

1457
00:56:25,350 --> 00:56:26,960
肯定是棘手的，这是矛盾的，这里需要注意的是，
through the transmission it's tricky positively which is the

1458
00:56:26,960 --> 00:56:31,690
肯定是棘手的，这是矛盾的，这里需要注意的是，
it's tricky positively which is the contradictory and some note here is that

1459
00:56:31,690 --> 00:56:31,700
肯定是棘手的，这是矛盾的，这里需要注意的是，
contradictory and some note here is that for the irreducibility argument this

1460
00:56:31,700 --> 00:56:35,840
对于不可约性参数，此表达式应为正而不是
contradictory and some note here is that for the irreducibility argument this

1461
00:56:35,840 --> 00:56:38,750
对于不可约性参数，此表达式应为正而不是
for the irreducibility argument this expression should be positive not

1462
00:56:38,750 --> 00:56:38,760
对于不可约性参数，此表达式应为正而不是
expression should be positive not necessarily one as I as we brought in

1463
00:56:38,760 --> 00:56:42,350
一定是我提出的命题证明中的一个，所以它可以
expression should be positive not necessarily one as I as we brought in

1464
00:56:42,350 --> 00:56:45,650
一定是我提出的命题证明中的一个，所以它可以
necessarily one as I as we brought in the proof of our proposition so it could

1465
00:56:45,650 --> 00:56:45,660
一定是我提出的命题证明中的一个，所以它可以
the proof of our proposition so it could be some constrain like this and for some

1466
00:56:45,660 --> 00:56:50,660
像这样的约束，对于某些积极的事物，我们可以乘以
the proof of our proposition so it could be some constrain like this and for some

1467
00:56:50,660 --> 00:56:53,750
像这样的约束，对于某些积极的事物，我们可以乘以
be some constrain like this and for some positive it's belong and we can multiply

1468
00:56:53,750 --> 00:56:53,760
像这样的约束，对于某些积极的事物，我们可以乘以
positive it's belong and we can multiply by the one origin as a constant and it

1469
00:56:53,760 --> 00:56:57,290
一个常数作为常数，它不会影响我们的患者分布
positive it's belong and we can multiply by the one origin as a constant and it

1470
00:56:57,290 --> 00:57:01,790
一个常数作为常数，它不会影响我们的患者分布
by the one origin as a constant and it does not affect our patient distribution

1471
00:57:01,790 --> 00:57:02,140
提议让gamma成为将您孕育的细节的参数
by the one origin as a constant and it does not affect our patient distribution

1472
00:57:02,140 --> 00:57:02,150
提议让gamma成为将您孕育的细节的参数


1473
00:57:02,150 --> 00:57:09,110
提议让gamma成为将您孕育的细节的参数
proposition to let gamma be the parameter of the detail mothering you to

1474
00:57:09,110 --> 00:57:09,120
提议让gamma成为将您孕育的细节的参数
parameter of the detail mothering you to chew IJ equal to gamma over gamma plus

1475
00:57:09,120 --> 00:57:12,020
咀嚼IJ等于γ超过γ加γJ，请查看进度
parameter of the detail mothering you to chew IJ equal to gamma over gamma plus

1476
00:57:12,020 --> 00:57:14,150
咀嚼IJ等于γ超过γ加γJ，请查看进度
chew IJ equal to gamma over gamma plus gamma J please can see progress

1477
00:57:14,150 --> 00:57:14,160
咀嚼IJ等于γ超过γ加γJ，请查看进度
gamma J please can see progress experience or consistent because even

1478
00:57:14,160 --> 00:57:16,460
经验还是一致的，因为甚至我们的模型，所以我们想证明Pius的
gamma J please can see progress experience or consistent because even

1479
00:57:16,460 --> 00:57:21,830
经验还是一致的，因为甚至我们的模型，所以我们想证明Pius的
experience or consistent because even our model so we want to show that Pius s

1480
00:57:21,830 --> 00:57:21,840
经验还是一致的，因为甚至我们的模型，所以我们想证明Pius的
our model so we want to show that Pius s is equal to gamma over the Manhattan

1481
00:57:21,840 --> 00:57:25,550
等于伽玛在曼哈顿范数上的伽玛，这是求和
our model so we want to show that Pius s is equal to gamma over the Manhattan

1482
00:57:25,550 --> 00:57:27,980
等于伽玛在曼哈顿范数上的伽玛，这是求和
is equal to gamma over the Manhattan norm of the gamma which is the summation

1483
00:57:27,980 --> 00:57:27,990
等于伽玛在曼哈顿范数上的伽玛，这是求和
norm of the gamma which is the summation of the gamma a gamma R for I equal to 1

1484
00:57:27,990 --> 00:57:31,580
的伽玛R等于I等于1到N，所以我们要表示抱歉
norm of the gamma which is the summation of the gamma a gamma R for I equal to 1

1485
00:57:31,580 --> 00:57:37,820
的伽玛R等于I等于1到N，所以我们要表示抱歉
of the gamma a gamma R for I equal to 1 to N so we want to show that sorry we

1486
00:57:37,820 --> 00:57:37,830
的伽玛R等于I等于1到N，所以我们要表示抱歉
to N so we want to show that sorry we want to show that that pi is

1487
00:57:37,830 --> 00:57:39,590
想要证明pi是...的解释分布
to N so we want to show that sorry we want to show that that pi is

1488
00:57:39,590 --> 00:57:41,019
想要证明pi是...的解释分布
want to show that that pi is interpretation distribution of

1489
00:57:41,019 --> 00:57:41,029
想要证明pi是...的解释分布
interpretation distribution of the chance to change but I will I want

1490
00:57:41,029 --> 00:57:44,289
改变的机会，但我要达到的PS传输是平等的
interpretation distribution of the chance to change but I will I want

1491
00:57:44,289 --> 00:57:48,249
改变的机会，但我要达到的PS传输是平等的
the chance to change but I will I want to reach that PS transmission is equal

1492
00:57:48,249 --> 00:57:48,259
改变的机会，但我要达到的PS传输是平等的
to reach that PS transmission is equal to zero so for this expression I have

1493
00:57:48,259 --> 00:57:53,669
零，所以对于这个表达式我有一个，所以我们可以拉出这个lambda
to reach that PS transmission is equal to zero so for this expression I have

1494
00:57:53,669 --> 00:57:58,029
零，所以对于这个表达式我有一个，所以我们可以拉出这个lambda
to zero so for this expression I have this one so we can pull out this lambda

1495
00:57:58,029 --> 00:57:58,039
零，所以对于这个表达式我有一个，所以我们可以拉出这个lambda
this one so we can pull out this lambda I and so we know the values of q ji q ji

1496
00:57:58,039 --> 00:58:02,380
我所以我们知道q ji q ji的值，所以这里等于零，
this one so we can pull out this lambda I and so we know the values of q ji q ji

1497
00:58:02,380 --> 00:58:07,949
我所以我们知道q ji q ji的值，所以这里等于零，
I and so we know the values of q ji q ji and here so this is equal to zero that

1498
00:58:07,949 --> 00:58:07,959
我所以我们知道q ji q ji的值，所以这里等于零，
and here so this is equal to zero that PI RS is always the additional

1499
00:58:07,959 --> 00:58:11,349
我现在想将PI RS始终作为链条的附加分销渠道
and here so this is equal to zero that PI RS is always the additional

1500
00:58:11,349 --> 00:58:17,319
我现在想将PI RS始终作为链条的附加分销渠道
PI RS is always the additional distribution of the chain now I want to

1501
00:58:17,319 --> 00:58:17,329
我现在想将PI RS始终作为链条的附加分销渠道
distribution of the chain now I want to talk about some properties of this piece

1502
00:58:17,329 --> 00:58:19,719
谈论这个整体的一些属性，我们想证明
distribution of the chain now I want to talk about some properties of this piece

1503
00:58:19,719 --> 00:58:23,979
谈论这个整体的一些属性，我们想证明
talk about some properties of this piece unity we want to demonstrate that

1504
00:58:23,979 --> 00:58:23,989
谈论这个整体的一些属性，我们想证明
unity we want to demonstrate that pigeons he exists this structure of the

1505
00:58:23,989 --> 00:58:26,919
鸽子，他存在这种第四合同能力的结构，这意味着
unity we want to demonstrate that pigeons he exists this structure of the

1506
00:58:26,919 --> 00:58:30,219
鸽子，他存在这种第四合同能力的结构，这意味着
pigeons he exists this structure of the fourth contract ability which implies

1507
00:58:30,219 --> 00:58:30,229
鸽子，他存在这种第四合同能力的结构，这意味着
fourth contract ability which implies uniform expansion so for the universe

1508
00:58:30,229 --> 00:58:34,479
均匀扩展，所以对于宇宙的斜线，我们应该谈论两个
fourth contract ability which implies uniform expansion so for the universe

1509
00:58:34,479 --> 00:58:36,669
均匀扩展，所以对于宇宙的斜线，我们应该谈论两个
uniform expansion so for the universe slash and we should talk about two

1510
00:58:36,669 --> 00:58:36,679
均匀扩展，所以对于宇宙的斜线，我们应该谈论两个
slash and we should talk about two definitions first of all first of all it

1511
00:58:36,679 --> 00:58:40,630
首先，定义是我的副本的定义
slash and we should talk about two definitions first of all first of all it

1512
00:58:40,630 --> 00:58:43,870
首先，定义是我的副本的定义
definitions first of all first of all it is the definition of the copies for I

1513
00:58:43,870 --> 00:58:43,880
首先，定义是我的副本的定义
is the definition of the copies for I and J in a structure view we take that

1514
00:58:43,880 --> 00:58:48,929
和J在结构视图中，如果
is the definition of the copies for I and J in a structure view we take that

1515
00:58:48,929 --> 00:58:52,239
和J在结构视图中，如果
and J in a structure view we take that iron general cookies with each other if

1516
00:58:52,239 --> 00:58:52,249
和J在结构视图中，如果
iron general cookies with each other if for all K as the member of s minus I

1517
00:58:52,249 --> 00:58:55,870
对于所有K作为s减I减J的成员，我们有以下两个表达式
iron general cookies with each other if for all K as the member of s minus I

1518
00:58:55,870 --> 00:59:02,380
对于所有K作为s减I减J的成员，我们有以下两个表达式
for all K as the member of s minus I minus J we have these two expressions

1519
00:59:02,380 --> 00:59:02,390
对于所有K作为s减I减J的成员，我们有以下两个表达式
minus J we have these two expressions so because there are upper of example

1520
00:59:02,390 --> 00:59:05,260
因此，因为有很多例子，KI的记忆选择就没有了
minus J we have these two expressions so because there are upper of example

1521
00:59:05,260 --> 00:59:07,960
因此，因为有很多例子，KI的记忆选择就没有了
so because there are upper of example choice of memories for K I didn't have

1522
00:59:07,960 --> 00:59:07,970
因此，因为有很多例子，KI的记忆选择就没有了
choice of memories for K I didn't have stuff perfectly identified tough stuff

1523
00:59:07,970 --> 00:59:10,090
东西完全识别出坚硬的东西，他和K都是相同的牛奶腺
choice of memories for K I didn't have stuff perfectly identified tough stuff

1524
00:59:10,090 --> 00:59:13,300
东西完全识别出坚硬的东西，他和K都是相同的牛奶腺
stuff perfectly identified tough stuff he and K identical glands of milk so

1525
00:59:13,300 --> 00:59:13,310
东西完全识别出坚硬的东西，他和K都是相同的牛奶腺
he and K identical glands of milk so they say it's her niche content that the

1526
00:59:13,310 --> 00:59:17,590
他们说读者使用某种类型的概率是她的利基内容
he and K identical glands of milk so they say it's her niche content that the

1527
00:59:17,590 --> 00:59:20,080
他们说读者使用某种类型的概率是她的利基内容
they say it's her niche content that the probability that the reader uses a type

1528
00:59:20,080 --> 00:59:20,090
他们说读者使用某种类型的概率是她的利基内容
probability that the reader uses a type of beverage in this scenario it is the

1529
00:59:20,090 --> 00:59:24,190
在这种情况下的饮料数量与仅显示一个饮料的情况相同
probability that the reader uses a type of beverage in this scenario it is the

1530
00:59:24,190 --> 00:59:26,890
在这种情况下的饮料数量与仅显示一个饮料的情况相同
of beverage in this scenario it is the same as if they was shown just only one

1531
00:59:26,890 --> 00:59:26,900
在这种情况下的饮料数量与仅显示一个饮料的情况相同
same as if they was shown just only one cup of some sort of the beverage and

1532
00:59:26,900 --> 00:59:32,940
一杯某种饮料，并且无论k的值等于
same as if they was shown just only one cup of some sort of the beverage and

1533
00:59:32,940 --> 00:59:36,130
一杯某种饮料，并且无论k的值等于
cup of some sort of the beverage and regardless of the the values of k equal

1534
00:59:36,130 --> 00:59:36,140
一杯某种饮料，并且无论k的值等于
regardless of the the values of k equal to or greater than one definition to is

1535
00:59:36,140 --> 00:59:39,640
等于或大于一个定义为是均匀展开，因为
regardless of the the values of k equal to or greater than one definition to is

1536
00:59:39,640 --> 00:59:43,000
等于或大于一个定义为是均匀展开，因为
to or greater than one definition to is the uniform expansion because there a

1537
00:59:43,000 --> 00:59:43,010
等于或大于一个定义为是均匀展开，因为
the uniform expansion because there a choice between an element in a set as

1538
00:59:43,010 --> 00:59:46,720
从爱荷华州一个元素中选择一个元素，然后熨烫一个元素，然后
the uniform expansion because there a choice between an element in a set as

1539
00:59:46,720 --> 00:59:49,390
从爱荷华州一个元素中选择一个元素，然后熨烫一个元素，然后
choice between an element in a set as one from Iowa one to iron one and

1540
00:59:49,390 --> 00:59:49,400
从爱荷华州一个元素中选择一个元素，然后熨烫一个元素，然后
one from Iowa one to iron one and another choice promise that okay

1541
00:59:49,400 --> 00:59:52,480
另一个选择承诺，包含K cookie的好东西会爱上每个
one from Iowa one to iron one and another choice promise that okay

1542
00:59:52,480 --> 00:59:54,940
另一个选择承诺，包含K cookie的好东西会爱上每个
another choice promise that okay containing K cookie love each of those

1543
00:59:54,940 --> 00:59:54,950
另一个选择承诺，包含K cookie的好东西会爱上每个
containing K cookie love each of those and n elements the axiom of uniform

1544
00:59:54,950 --> 00:59:58,930
和n个元素分别表示M和所有K的均匀扩张状态的公理
containing K cookie love each of those and n elements the axiom of uniform

1545
00:59:58,930 --> 01:00:02,230
和n个元素分别表示M和所有K的均匀扩张状态的公理
and n elements the axiom of uniform expansion States as put each M and all K

1546
01:00:02,230 --> 01:00:02,240
和n个元素分别表示M和所有K的均匀扩张状态的公理
expansion States as put each M and all K greater than or equal to 1 we have this

1547
01:00:02,240 --> 01:00:04,540
大于或等于1我们有这个表达式
expansion States as put each M and all K greater than or equal to 1 we have this

1548
01:00:04,540 --> 01:00:07,180
大于或等于1我们有这个表达式
greater than or equal to 1 we have this expression

1549
01:00:07,180 --> 01:00:09,390
因此我们得出结论，PTSD模型仅表现出更一般的特性
greater than or equal to 1 we have this expression

1550
01:00:09,390 --> 01:00:09,400
因此我们得出结论，PTSD模型仅表现出更一般的特性


1551
01:00:09,400 --> 01:00:15,510
因此我们得出结论，PTSD模型仅表现出更一般的特性
so we conclude that PTSD model only exhibiting more general property of

1552
01:00:15,510 --> 01:00:15,520
因此我们得出结论，PTSD模型仅表现出更一般的特性
exhibiting more general property of contract ability which it's always

1553
01:00:15,520 --> 01:00:20,550
收缩能力，总是表现出均匀的膨胀，所以我想要
exhibiting more general property of contract ability which it's always

1554
01:00:20,550 --> 01:00:27,060
收缩能力，总是表现出均匀的膨胀，所以我想要
contract ability which it's always exhibit uniform expansion so me I want

1555
01:00:27,060 --> 01:00:27,070
收缩能力，总是表现出均匀的膨胀，所以我想要
exhibit uniform expansion so me I want to hear bring the preposition tree for

1556
01:00:27,070 --> 01:00:31,800
聆听给定伽玛的介词树，这就是lambda IJ让
exhibit uniform expansion so me I want to hear bring the preposition tree for

1557
01:00:31,800 --> 01:00:36,510
聆听给定伽玛的介词树，这就是lambda IJ让
to hear bring the preposition tree for given gamma which is the lambda IJ let

1558
01:00:36,510 --> 01:00:36,520
聆听给定伽玛的介词树，这就是lambda IJ让
given gamma which is the lambda IJ let a1 to a2 be a contractible partition for

1559
01:00:36,520 --> 01:00:39,870
a1到a2是PT的可收缩分区，与您所代表的分区相似
given gamma which is the lambda IJ let a1 to a2 be a contractible partition for

1560
01:00:39,870 --> 01:00:43,290
a1到a2是PT的可收缩分区，与您所代表的分区相似
a1 to a2 be a contractible partition for to PT and similar than you represented

1561
01:00:43,290 --> 01:00:43,300
a1到a2是PT的可收缩分区，与您所代表的分区相似
to PT and similar than you represented by Q and Q Prime with the station

1562
01:00:43,300 --> 01:00:45,600
由Q和Q Prime使用工作站分布Python，然后针对任何AI
to PT and similar than you represented by Q and Q Prime with the station

1563
01:00:45,600 --> 01:00:48,840
由Q和Q Prime使用工作站分布Python，然后针对任何AI
by Q and Q Prime with the station distribution Python then for any AI we

1564
01:00:48,840 --> 01:00:48,850
由Q和Q Prime使用工作站分布Python，然后针对任何AI
distribution Python then for any AI we have this expression or equivalently we

1565
01:00:48,850 --> 01:00:51,000
有这个表达式或等效地，我们说PI AI等于-嘿Ari所以
distribution Python then for any AI we have this expression or equivalently we

1566
01:00:51,000 --> 01:00:58,470
有这个表达式或等效地，我们说PI AI等于-嘿Ari所以
have this expression or equivalently we say that PI AI is equal to - hey Ari so

1567
01:00:58,470 --> 01:00:58,480
有这个表达式或等效地，我们说PI AI等于-嘿Ari所以
say that PI AI is equal to - hey Ari so for the proof these patrols that Q has

1568
01:00:58,480 --> 01:01:02,610
为了证明这些巡逻，Q相对于
say that PI AI is equal to - hey Ari so for the proof these patrols that Q has

1569
01:01:02,610 --> 01:01:06,620
为了证明这些巡逻，Q相对于
for the proof these patrols that Q has partition a 1 to a K with respect to

1570
01:01:06,620 --> 01:01:06,630
为了证明这些巡逻，Q相对于
partition a 1 to a K with respect to gamma if it be composed the balanced

1571
01:01:06,630 --> 01:01:10,290
伽马如果由平衡方程组成未来美德的各定律
partition a 1 to a K with respect to gamma if it be composed the balanced

1572
01:01:10,290 --> 01:01:12,990
伽马如果由平衡方程组成未来美德的各定律
gamma if it be composed the balanced equation each law of the future virtue

1573
01:01:12,990 --> 01:01:13,000
伽马如果由平衡方程组成未来美德的各定律
equation each law of the future virtue which is equal to 0 for each member of a

1574
01:01:13,000 --> 01:01:16,170
对于1的每个成员等于0而又不失一般性
equation each law of the future virtue which is equal to 0 for each member of a

1575
01:01:16,170 --> 01:01:18,450
对于1的每个成员等于0而又不失一般性
which is equal to 0 for each member of a 1 without loss of generality we can

1576
01:01:18,450 --> 01:01:18,460
对于1的每个成员等于0而又不失一般性
1 without loss of generality we can obtain these expression so

1577
01:01:18,460 --> 01:01:24,660
获得这些表达式，这样
1 without loss of generality we can obtain these expression so

1578
01:01:24,660 --> 01:01:25,180
这里要注意的是，对于印度的一小片地区，首都地区的成员和同性恋者
1 without loss of generality we can obtain these expression so

1579
01:01:25,180 --> 01:01:25,190
这里要注意的是，对于印度的一小片地区，首都地区的成员和同性恋者


1580
01:01:25,190 --> 01:01:31,329
这里要注意的是，对于印度的一小片地区，首都地区的成员和同性恋者
here noting that for the a small area in India the member of Capital Area and gay

1581
01:01:31,329 --> 01:01:31,339
这里要注意的是，对于印度的一小片地区，首都地区的成员和同性恋者
India the member of Capital Area and gay and AJ is equal to lambda IJ here we can

1582
01:01:31,339 --> 01:01:38,010
并且AJ等于lambda IJ在这里我们可以实际分解它
India the member of Capital Area and gay and AJ is equal to lambda IJ here we can

1583
01:01:38,010 --> 01:01:41,579
并且AJ等于lambda IJ在这里我们可以实际分解它
and AJ is equal to lambda IJ here we can we can actually decompose it

1584
01:01:41,579 --> 01:01:41,589
并且AJ等于lambda IJ在这里我们可以实际分解它
we can actually decompose it multivariate each coil 60 each of these

1585
01:01:41,589 --> 01:01:45,700
在这个表达式中将每个线圈60多变量这些项中的每一项，然后得出
we can actually decompose it multivariate each coil 60 each of these

1586
01:01:45,700 --> 01:01:48,910
在这个表达式中将每个线圈60多变量这些项中的每一项，然后得出
multivariate each coil 60 each of these terms in this expression and then coming

1587
01:01:48,910 --> 01:01:48,920
在这个表达式中将每个线圈60多变量这些项中的每一项，然后得出
terms in this expression and then coming over act as a member of a one we we will

1588
01:01:48,920 --> 01:01:52,660
作为一个成员的行为，我们将达到这个长表达
terms in this expression and then coming over act as a member of a one we we will

1589
01:01:52,660 --> 01:01:57,160
作为一个成员的行为，我们将达到这个长表达
over act as a member of a one we we will reach this this long expression the

1590
01:01:57,160 --> 01:01:57,170
作为一个成员的行为，我们将达到这个长表达
reach this this long expression the leftmost Titanic II studies equal so

1591
01:01:57,170 --> 01:02:00,640
最左边的泰坦尼克号II研究相等，所以这一项和这一项，我们可以
reach this this long expression the leftmost Titanic II studies equal so

1592
01:02:00,640 --> 01:02:03,760
最左边的泰坦尼克号II研究相等，所以这一项和这一项，我们可以
leftmost Titanic II studies equal so this one and this one so we have we can

1593
01:02:03,760 --> 01:02:03,770
最左边的泰坦尼克号II研究相等，所以这一项和这一项，我们可以
this one and this one so we have we can get the PA one which which makes the pay

1594
01:02:03,770 --> 01:02:11,200
得到一个PA，它使一个人的工资作为解决方案
this one and this one so we have we can get the PA one which which makes the pay

1595
01:02:11,200 --> 01:02:16,119
得到一个PA，它使一个人的工资作为解决方案
get the PA one which which makes the pay feed upon a one as the solution to

1596
01:02:16,119 --> 01:02:17,220
平衡方程以上命题与协调契约的能力。
get the PA one which which makes the pay feed upon a one as the solution to

1597
01:02:17,220 --> 01:02:17,230
平衡方程以上命题与协调契约的能力。


1598
01:02:17,230 --> 01:02:22,990
平衡方程以上命题与协调契约的能力。
balanced equation the above proposition and the concert the contract the ability

1599
01:02:22,990 --> 01:02:23,000
平衡方程以上命题与协调契约的能力。
and the concert the contract the ability of efficiency model so it implies that

1600
01:02:23,000 --> 01:02:26,260
模型的效率，因此它暗示PDMP模型表现出统一的
and the concert the contract the ability of efficiency model so it implies that

1601
01:02:26,260 --> 01:02:30,069
模型的效率，因此它暗示PDMP模型表现出统一的
of efficiency model so it implies that the PDMP model exhibits uniform

1602
01:02:30,069 --> 01:02:30,079
模型的效率，因此它暗示PDMP模型表现出统一的
the PDMP model exhibits uniform expansion

1603
01:02:30,079 --> 01:02:32,260
扩张
the PDMP model exhibits uniform expansion

1604
01:02:32,260 --> 01:02:34,359
印度人的推理和预测部分是我们的最终目标是通过谴责它
the PDMP model exhibits uniform expansion

1605
01:02:34,359 --> 01:02:34,369
印度人的推理和预测部分是我们的最终目标是通过谴责它


1606
01:02:34,369 --> 01:02:40,250
印度人的推理和预测部分是我们的最终目标是通过谴责它
Indians inference and prediction part our ultimate goal is through berating it

1607
01:02:40,250 --> 01:02:40,260
印度人的推理和预测部分是我们的最终目标是通过谴责它
our ultimate goal is through berating it model to make predictions using past

1608
01:02:40,260 --> 01:02:42,950
建模以使用过去从不同子集中的选择进行预测
our ultimate goal is through berating it model to make predictions using past

1609
01:02:42,950 --> 01:02:45,800
建模以使用过去从不同子集中的选择进行预测
model to make predictions using past choices from different subsets to

1610
01:02:45,800 --> 01:02:45,810
建模以使用过去从不同子集中的选择进行预测
choices from different subsets to predict future choices there are three

1611
01:02:45,810 --> 01:02:49,340
预测未来的选择，其中三分之三接受印度
choices from different subsets to predict future choices there are three

1612
01:02:49,340 --> 01:02:51,680
预测未来的选择，其中三分之三接受印度
predict future choices there are three part three accept India in the

1613
01:02:51,680 --> 01:02:51,690
预测未来的选择，其中三分之三接受印度
part three accept India in the prediction part leaving the no blank

1614
01:02:51,690 --> 01:02:55,910
预测部分，留下无空白函数，即速率矩阵Q
part three accept India in the prediction part leaving the no blank

1615
01:02:55,910 --> 01:03:00,859
预测部分，留下无空白函数，即速率矩阵Q
prediction part leaving the no blank function which is the rate matrix Q

1616
01:03:00,859 --> 01:03:00,869
预测部分，留下无空白函数，即速率矩阵Q
function which is the rate matrix Q given a choice data collection of the

1617
01:03:00,869 --> 01:03:03,710
给定形式T的选择数据集合，其中IK是SK的成员
function which is the rate matrix Q given a choice data collection of the

1618
01:03:03,710 --> 01:03:09,950
给定形式T的选择数据集合，其中IK是SK的成员
given a choice data collection of the form T where the I K is the member of SK

1619
01:03:09,950 --> 01:03:09,960
给定形式T的选择数据集合，其中IK是SK的成员
form T where the I K is the member of SK was the eyes and chosen from escaped

1620
01:03:09,960 --> 01:03:12,040
是眼睛，是从逃脱的调查中选择的，了解每个人的能力
form T where the I K is the member of SK was the eyes and chosen from escaped

1621
01:03:12,040 --> 01:03:14,330
是眼睛，是从逃脱的调查中选择的，了解每个人的能力
was the eyes and chosen from escaped investigating the ability of learnt each

1622
01:03:14,330 --> 01:03:14,340
是眼睛，是从逃脱的调查中选择的，了解每个人的能力
investigating the ability of learnt each day and tomorrow to make choice

1623
01:03:14,340 --> 01:03:15,650
每天和明天根据经验数据基准进行选择预测
investigating the ability of learnt each day and tomorrow to make choice

1624
01:03:15,650 --> 01:03:18,440
每天和明天根据经验数据基准进行选择预测
day and tomorrow to make choice prediction on empirical data benchmark

1625
01:03:18,440 --> 01:03:18,450
每天和明天根据经验数据基准进行选择预测
prediction on empirical data benchmark against learn ml and then interpreting

1626
01:03:18,450 --> 01:03:24,260
反对学习毫升，然后解释内容丰富的诺言
prediction on empirical data benchmark against learn ml and then interpreting

1627
01:03:24,260 --> 01:03:30,530
反对学习毫升，然后解释内容丰富的诺言
against learn ml and then interpreting the informative promises to have for the

1628
01:03:30,530 --> 01:03:30,540
反对学习毫升，然后解释内容丰富的诺言
the informative promises to have for the muscular fluids

1629
01:03:30,540 --> 01:03:31,670
让我们将T定义为项目的数量
the informative promises to have for the muscular fluids

1630
01:03:31,670 --> 01:03:38,470
让我们将T定义为项目的数量
muscular fluids let's define T is as the number of items

1631
01:03:38,470 --> 01:03:38,480
让我们将T定义为项目的数量
let's define T is as the number of items number of times in the data that I was

1632
01:03:38,480 --> 01:03:42,109
从成功中选择我的数据的次数，我也将其视为
let's define T is as the number of items number of times in the data that I was

1633
01:03:42,109 --> 01:03:45,920
从成功中选择我的数据的次数，我也将其视为
number of times in the data that I was chosen from the success I also see it as

1634
01:03:45,920 --> 01:03:45,930
从成功中选择我的数据的次数，我也将其视为
chosen from the success I also see it as the number of times that X was chosen

1635
01:03:45,930 --> 01:03:49,280
如上所讨论，为每个X选择X的次数，因此
chosen from the success I also see it as the number of times that X was chosen

1636
01:03:49,280 --> 01:03:56,240
如上所讨论，为每个X选择X的次数，因此
the number of times that X was chosen for each as discussed above you so there

1637
01:03:56,240 --> 01:03:56,250
如上所讨论，为每个X选择X的次数，因此
for each as discussed above you so there are two recordings here for each as if P

1638
01:03:56,250 --> 01:04:00,800
这里有两个录音，就好像P是Q是
for each as discussed above you so there are two recordings here for each as if P

1639
01:04:00,800 --> 01:04:04,609
这里有两个录音，就好像P是Q是
are two recordings here for each as if P is a Q is the probability for the

1640
01:04:04,609 --> 01:04:04,619
这里有两个录音，就好像P是Q是
is a Q is the probability for the selection of s as a function of the rate

1641
01:04:04,619 --> 01:04:07,400
随利率市场q的变化而选择s，然后将所有
is a Q is the probability for the selection of s as a function of the rate

1642
01:04:07,400 --> 01:04:11,120
随利率市场q的变化而选择s，然后将所有
selection of s as a function of the rate market q and after dropping all the

1643
01:04:11,120 --> 01:04:11,130
随利率市场q的变化而选择s，然后将所有
market q and after dropping all the constants the loaf likely would have Q

1644
01:04:11,130 --> 01:04:13,310
给定数据T时，面包可能具有Q的常数
market q and after dropping all the constants the loaf likely would have Q

1645
01:04:13,310 --> 01:04:16,040
给定数据T时，面包可能具有Q的常数
constants the loaf likely would have Q given the data T which have been here

1646
01:04:16,040 --> 01:04:16,050
给定数据T时，面包可能具有Q的常数
given the data T which have been here derived from the probability

1647
01:04:16,050 --> 01:04:19,630
从多项式分布的概率函数得出
given the data T which have been here derived from the probability

1648
01:04:19,630 --> 01:04:21,999
从多项式分布的概率函数得出
derived from the probability function of the multinomial distribution

1649
01:04:21,999 --> 01:04:22,009
从多项式分布的概率函数得出
function of the multinomial distribution which is and we get this expression and

1650
01:04:22,009 --> 01:04:27,729
就是这个，我们得到这个表达式并记录到第45个条目中
function of the multinomial distribution which is and we get this expression and

1651
01:04:27,729 --> 01:04:30,739
就是这个，我们得到这个表达式并记录到第45个条目中
which is and we get this expression and for the recording to the 45th entry

1652
01:04:30,739 --> 01:04:30,749
就是这个，我们得到这个表达式并记录到第45个条目中
for the recording to the 45th entry model we have we want to be we have D

1653
01:04:30,749 --> 01:04:35,180
模型，我们要成为我们，我们要拥有D净化器是我们的关注点
for the recording to the 45th entry model we have we want to be we have D

1654
01:04:35,180 --> 01:04:38,509
模型，我们要成为我们，我们要拥有D净化器是我们的关注点
model we have we want to be we have D the purifier is the attention

1655
01:04:38,509 --> 01:04:38,519
模型，我们要成为我们，我们要拥有D净化器是我们的关注点
the purifier is the attention distribution for the continuous time

1656
01:04:38,519 --> 01:04:39,949
连续时间马尔可夫链的分布，实际上他们有它们
the purifier is the attention distribution for the continuous time

1657
01:04:39,949 --> 01:04:45,769
连续时间马尔可夫链的分布，实际上他们有它们
distribution for the continuous time Markov chain and actually they have they

1658
01:04:45,769 --> 01:04:45,779
连续时间马尔可夫链的分布，实际上他们有它们
Markov chain and actually they have they have used the non taped problem

1659
01:04:45,779 --> 01:04:48,620
已经使用了非录音问题的优化问题，如果有人
Markov chain and actually they have they have used the non taped problem

1660
01:04:48,620 --> 01:04:51,680
已经使用了非录音问题的优化问题，如果有人
have used the non taped problem optimization problem and if anyone is

1661
01:04:51,680 --> 01:04:51,690
已经使用了非录音问题的优化问题，如果有人
optimization problem and if anyone is interested just for the informational

1662
01:04:51,690 --> 01:04:53,690
只是对他们使用SLS Q感兴趣的信息感兴趣
optimization problem and if anyone is interested just for the informational

1663
01:04:53,690 --> 01:04:57,789
只是对他们使用SLS Q感兴趣的信息感兴趣
interested just for the informational thing that they have used the SLS Q

1664
01:04:57,789 --> 01:04:57,799
只是对他们使用SLS Q感兴趣的信息感兴趣
thing that they have used the SLS Q programming the credential it is for

1665
01:04:57,799 --> 01:05:00,259
对凭证进行编程，以便对它们进行优化
thing that they have used the SLS Q programming the credential it is for

1666
01:05:00,259 --> 01:05:02,539
对凭证进行编程，以便对它们进行优化
programming the credential it is for programming in order to optimize them

1667
01:05:02,539 --> 01:05:02,549
对凭证进行编程，以便对它们进行优化
programming in order to optimize them they use the type file that minimize a

1668
01:05:02,549 --> 01:05:06,019
他们使用类型文件来最小化Python中的函数，或者您可以使用
programming in order to optimize them they use the type file that minimize a

1669
01:05:06,019 --> 01:05:10,249
他们使用类型文件来最小化Python中的函数，或者您可以使用
they use the type file that minimize a function in the Python or you can use

1670
01:05:10,249 --> 01:05:10,259
他们使用类型文件来最小化Python中的函数，或者您可以使用
function in the Python or you can use the minimize the method the security

1671
01:05:10,259 --> 01:05:15,349
最小化方法的安全性
function in the Python or you can use the minimize the method the security

1672
01:05:15,349 --> 01:05:15,579
那里有经验数据结果，他们评估了程序，还有三个
function in the Python or you can use the minimize the method the security

1673
01:05:15,579 --> 01:05:15,589
那里有经验数据结果，他们评估了程序，还有三个


1674
01:05:15,589 --> 01:05:21,199
那里有经验数据结果，他们评估了程序，还有三个
there the empirical data results they evaluate the procedure and three

1675
01:05:21,199 --> 01:05:21,209
那里有经验数据结果，他们评估了程序，还有三个
evaluate the procedure and three empirical data sets from surveillance

1676
01:05:21,209 --> 01:05:25,630
来自San周围交通运输监督调查的经验数据集
evaluate the procedure and three empirical data sets from surveillance

1677
01:05:25,630 --> 01:05:28,729
来自San周围交通运输监督调查的经验数据集
empirical data sets from surveillance survey of Transportation around the San

1678
01:05:28,729 --> 01:05:28,739
来自San周围交通运输监督调查的经验数据集
survey of Transportation around the San Francisco Bay Area

1679
01:05:28,739 --> 01:05:31,269
旧金山湾地区旧金山战争受到遏制
survey of Transportation around the San Francisco Bay Area

1680
01:05:31,269 --> 01:05:35,589
旧金山湾地区旧金山战争受到遏制
Francisco Bay Area the San Francisco war is contained

1681
01:05:35,589 --> 01:05:35,599
旧金山湾地区旧金山战争受到遏制
the San Francisco war is contained twelve thousand twenty nine of the

1682
01:05:35,599 --> 01:05:38,299
该关系的一万二千二百九十九个由社区选择组成
the San Francisco war is contained twelve thousand twenty nine of the

1683
01:05:38,299 --> 01:05:40,219
该关系的一万二千二百九十九个由社区选择组成
twelve thousand twenty nine of the relation consists of community options

1684
01:05:40,219 --> 01:05:40,229
该关系的一万二千二百九十九个由社区选择组成
relation consists of community options and the choice mode on a given community

1685
01:05:40,229 --> 01:05:42,380
以及给定社区的选择模式，因为我们将包含3157
relation consists of community options and the choice mode on a given community

1686
01:05:42,380 --> 01:05:48,499
以及给定社区的选择模式，因为我们将包含3157
and the choice mode on a given community and as we shall contain 3157

1687
01:05:48,499 --> 01:05:48,509
以及给定社区的选择模式，因为我们将包含3157
and as we shall contain 3157 observations each consistent choice set

1688
01:05:48,509 --> 01:05:51,079
观察每个可供选择的运输备选方案的一致选择
and as we shall contain 3157 observations each consistent choice set

1689
01:05:51,079 --> 01:05:52,849
观察每个可供选择的运输备选方案的一致选择
observations each consistent choice set of transportation alternatives available

1690
01:05:52,849 --> 01:05:52,859
观察每个可供选择的运输备选方案的一致选择
of transportation alternatives available to individuals traveling and returning

1691
01:05:52,859 --> 01:05:55,969
给从购物中心旅行和返回的个人
of transportation alternatives available to individuals traveling and returning

1692
01:05:55,969 --> 01:05:59,299
给从购物中心旅行和返回的个人
to individuals traveling and returning from a shopping center

1693
01:05:59,299 --> 01:05:59,979
为了使我们的现代观察成为可能，她进行了培训和评估
to individuals traveling and returning from a shopping center

1694
01:05:59,979 --> 01:05:59,989
为了使我们的现代观察成为可能，她进行了培训和评估


1695
01:05:59,989 --> 01:06:06,309
为了使我们的现代观察成为可能，她进行了培训和评估
for the training for turning our modern observation she trained and evaluate

1696
01:06:06,309 --> 01:06:06,319
为了使我们的现代观察成为可能，她进行了培训和评估
observation she trained and evaluate unattested

1697
01:06:06,319 --> 01:06:07,670
未经认证的老师，这是
observation she trained and evaluate unattested

1698
01:06:07,670 --> 01:06:10,729
未经认证的老师，这是
unattested teachers this is be the bearer of

1699
01:06:10,729 --> 01:06:10,739
未经认证的老师，这是
teachers this is be the bearer of teacher and teachers that we want to

1700
01:06:10,739 --> 01:06:12,769
老师和我们要评估的老师实际上是比较厨房
teachers this is be the bearer of teacher and teachers that we want to

1701
01:06:12,769 --> 01:06:14,930
老师和我们要评估的老师实际上是比较厨房
teacher and teachers that we want to evaluate actually comparative kitchens

1702
01:06:14,930 --> 01:06:14,940
老师和我们要评估的老师实际上是比较厨房
evaluate actually comparative kitchens amount of a conditional be others model

1703
01:06:14,940 --> 01:06:18,459
在此表达式中，有条件的其他人的数量为Q
evaluate actually comparative kitchens amount of a conditional be others model

1704
01:06:18,459 --> 01:06:21,859
在此表达式中，有条件的其他人的数量为Q
amount of a conditional be others model beach in in this expression the Q

1705
01:06:21,859 --> 01:06:21,869
在此表达式中，有条件的其他人的数量为Q
beach in in this expression the Q hottest teacher an estimate for view

1706
01:06:21,869 --> 01:06:23,509
最热的老师从对厨房和厨房的观察中获得的视野估计值
beach in in this expression the Q hottest teacher an estimate for view

1707
01:06:23,509 --> 01:06:25,660
最热的老师从对厨房和厨房的观察中获得的视野估计值
hottest teacher an estimate for view obtained from observation of kitchen and

1708
01:06:25,660 --> 01:06:25,670
最热的老师从对厨房和厨房的观察中获得的视野估计值
obtained from observation of kitchen and P tilde is theta is equal to cos

1709
01:06:25,670 --> 01:06:29,209
P tilde是theta等于截至今天为止熟练的cos老师
obtained from observation of kitchen and P tilde is theta is equal to cos

1710
01:06:29,209 --> 01:06:31,670
P tilde是theta等于截至今天为止熟练的cos老师
P tilde is theta is equal to cos teachers who were skilled as of today

1711
01:06:31,670 --> 01:06:31,680
P tilde是theta等于截至今天为止熟练的cos老师
teachers who were skilled as of today which is the empirical probability of I

1712
01:06:31,680 --> 01:06:34,279
从比例中选择I的经验概率
teachers who were skilled as of today which is the empirical probability of I

1713
01:06:34,279 --> 01:06:37,130
从比例中选择I的经验概率
which is the empirical probability of I was selected from as among of the ratio

1714
01:06:37,130 --> 01:06:37,140
从比例中选择I的经验概率
was selected from as among of the ratio cheetahs this is actually I have done it

1715
01:06:37,140 --> 01:06:47,329
猎豹，这实际上是我首先为一些弗朗西斯做的
was selected from as among of the ratio cheetahs this is actually I have done it

1716
01:06:47,329 --> 01:06:49,939
猎豹，这实际上是我首先为一些弗朗西斯做的
cheetahs this is actually I have done it for first of all for some Frances to

1717
01:06:49,939 --> 01:06:49,949
猎豹，这实际上是我首先为一些弗朗西斯做的
for first of all for some Frances to work data and first the number of

1718
01:06:49,949 --> 01:06:53,420
工作数据，首先是错误的模拟数量，这是十，这是
for first of all for some Frances to work data and first the number of

1719
01:06:53,420 --> 01:06:56,120
工作数据，首先是错误的模拟数量，这是十，这是
work data and first the number of simulations wrong it's ten this is the

1720
01:06:56,120 --> 01:06:56,130
工作数据，首先是错误的模拟数量，这是十，这是
simulations wrong it's ten this is the comparison between the error versus the

1721
01:06:56,130 --> 01:06:58,430
误差与用于训练的数据百分比之间的比较
simulations wrong it's ten this is the comparison between the error versus the

1722
01:06:58,430 --> 01:07:00,199
误差与用于训练的数据百分比之间的比较
comparison between the error versus the percentage of data used for training

1723
01:07:00,199 --> 01:07:00,209
误差与用于训练的数据百分比之间的比较
percentage of data used for training from five to seventy five percent

1724
01:07:00,209 --> 01:07:04,009
从百分之五到百分之七十五的百分之十九
percentage of data used for training from five to seventy five percent

1725
01:07:04,009 --> 01:07:05,689
从百分之五到百分之七十五的百分之十九
from five to seventy five percent nineteen seventy five percent of the

1726
01:07:05,689 --> 01:07:05,699
从百分之五到百分之七十五的百分之十九
nineteen seventy five percent of the data for training and 25 for the test

1727
01:07:05,699 --> 01:07:08,920
训练数据，25个测试数据和15个模型都做得很好
nineteen seventy five percent of the data for training and 25 for the test

1728
01:07:08,920 --> 01:07:11,989
训练数据，25个测试数据和15个模型都做得很好
data for training and 25 for the test and fifteen see model is doing great job

1729
01:07:11,989 --> 01:07:11,999
训练数据，25个测试数据和15个模型都做得很好
and fifteen see model is doing great job hearing in comparison to mmm a nano

1730
01:07:11,999 --> 01:07:14,749
相较于mmm，您会听到纳米混合器的声音，他的热量是
and fifteen see model is doing great job hearing in comparison to mmm a nano

1731
01:07:14,749 --> 01:07:17,959
相较于mmm，您会听到纳米混合器的声音，他的热量是
hearing in comparison to mmm a nano mixer manner and his are they the heat

1732
01:07:17,959 --> 01:07:17,969
相较于mmm，您会听到纳米混合器的声音，他的热量是
mixer manner and his are they the heat match for the forty probability for each

1733
01:07:17,969 --> 01:07:22,069
匹配每一侧实际水平和垂直的四十概率
mixer manner and his are they the heat match for the forty probability for each

1734
01:07:22,069 --> 01:07:25,789
匹配每一侧实际水平和垂直的四十概率
match for the forty probability for each side actually horizontal and vertical we

1735
01:07:25,789 --> 01:07:25,799
匹配每一侧实际水平和垂直的四十概率
side actually horizontal and vertical we have dick

1736
01:07:25,799 --> 01:07:27,519
鸡巴，我们选择了苍白的选择
side actually horizontal and vertical we have dick

1737
01:07:27,519 --> 01:07:31,759
鸡巴，我们选择了苍白的选择
have dick we have picked pale of the options which

1738
01:07:31,759 --> 01:07:31,769
鸡巴，我们选择了苍白的选择
we have picked pale of the options which are driving alone and sharing around

1739
01:07:31,769 --> 01:07:35,390
独自开车，彼此共享，先在公共场所工作
we have picked pale of the options which are driving alone and sharing around

1740
01:07:35,390 --> 01:07:37,160
独自开车，彼此共享，先在公共场所工作
are driving alone and sharing around with one another first to work in public

1741
01:07:37,160 --> 01:07:37,170
独自开车，彼此共享，先在公共场所工作
with one another first to work in public transit biking and carpooling with at

1742
01:07:37,170 --> 01:07:39,380
与至少两个其他人一起骑行和拼车的过境活动，我们正在展示
with one another first to work in public transit biking and carpooling with at

1743
01:07:39,380 --> 01:07:42,979
与至少两个其他人一起骑行和拼车的过境活动，我们正在展示
transit biking and carpooling with at least two others and we are showing the

1744
01:07:42,979 --> 01:07:42,989
与至少两个其他人一起骑行和拼车的过境活动，我们正在展示
least two others and we are showing the probability of need relative risk rate

1745
01:07:42,989 --> 01:07:46,760
成对项目之间的相对风险率的需求概率以及如何
least two others and we are showing the probability of need relative risk rate

1746
01:07:46,760 --> 01:07:48,980
成对项目之间的相对风险率的需求概率以及如何
probability of need relative risk rate between pairs of items as well as how

1747
01:07:48,980 --> 01:07:48,990
成对项目之间的相对风险率的需求概率以及如何
between pairs of items as well as how the total rates between first and

1748
01:07:48,990 --> 01:07:50,900
在这里编辑其他页面的第一位和个人导师之间的总费用I
between pairs of items as well as how the total rates between first and

1749
01:07:50,900 --> 01:07:56,990
在这里编辑其他页面的第一位和个人导师之间的总费用I
the total rates between first and personal tutor editing other page here I

1750
01:07:56,990 --> 01:07:57,000
在这里编辑其他页面的第一位和个人导师之间的总费用I
personal tutor editing other page here I did the simulation for number of equal

1751
01:07:57,000 --> 01:08:01,700
进行了等于50的模拟，所以当我们激活时
personal tutor editing other page here I did the simulation for number of equal

1752
01:08:01,700 --> 01:08:07,420
进行了等于50的模拟，所以当我们激活时
did the simulation for number of equal to 50 so when we activate when we

1753
01:08:07,420 --> 01:08:07,430
进行了等于50的模拟，所以当我们激活时
to 50 so when we activate when we increase the number of stimulation it

1754
01:08:07,430 --> 01:08:10,130
增加刺激的数量将与上一个刺激相同
to 50 so when we activate when we increase the number of stimulation it

1755
01:08:10,130 --> 01:08:18,440
增加刺激的数量将与上一个刺激相同
increase the number of stimulation it will be so in the previous one with the

1756
01:08:18,440 --> 01:08:18,450
增加刺激的数量将与上一个刺激相同
will be so in the previous one with the tenth simulation we see here that first

1757
01:08:18,450 --> 01:08:21,830
第十次仿真，我们在这里看到，我们的TNT模型的第一个开始更多
will be so in the previous one with the tenth simulation we see here that first

1758
01:08:21,830 --> 01:08:25,490
第十次仿真，我们在这里看到，我们的TNT模型的第一个开始更多
tenth simulation we see here that first of our TNT model starts with little more

1759
01:08:25,490 --> 01:08:25,500
第十次仿真，我们在这里看到，我们的TNT模型的第一个开始更多
of our TNT model starts with little more but then we increase the increase the

1760
01:08:25,500 --> 01:08:29,900
但是随后我们增加了开始模拟的次数
of our TNT model starts with little more but then we increase the increase the

1761
01:08:29,900 --> 01:08:33,860
但是随后我们增加了开始模拟的次数
but then we increase the increase the number of simulations they start on

1762
01:08:33,860 --> 01:08:33,870
但是随后我们增加了开始模拟的次数
number of simulations they start on something the same but after that

1763
01:08:33,870 --> 01:08:39,200
相同的东西，但是相比其他效率模型
number of simulations they start on something the same but after that

1764
01:08:39,200 --> 01:08:41,510
相同的东西，但是相比其他效率模型
something the same but after that efficiency model in comparison to other

1765
01:08:41,510 --> 01:08:41,520
相同的东西，但是相比其他效率模型
efficiency model in comparison to other mothers during the great job so even in

1766
01:08:41,520 --> 01:08:46,280
母亲们在出色的工作中，即使在违反IIA的数据中，
efficiency model in comparison to other mothers during the great job so even in

1767
01:08:46,280 --> 01:08:50,720
母亲们在出色的工作中，即使在违反IIA的数据中，
mothers during the great job so even in data with violations of iia that was the

1768
01:08:50,720 --> 01:08:50,730
母亲们在出色的工作中，即使在违反IIA的数据中，
data with violations of iia that was the that was known for the lucia first axiom

1769
01:08:50,730 --> 01:08:54,140
以最近我谈论的露西亚第一公理而闻名，这是
data with violations of iia that was the that was known for the lucia first axiom

1770
01:08:54,140 --> 01:08:56,120
以最近我谈论的露西亚第一公理而闻名，这是
that was known for the lucia first axiom that i talked about lately which is the

1771
01:08:56,120 --> 01:08:56,130
以最近我谈论的露西亚第一公理而闻名，这是
that i talked about lately which is the independence relevant of alternatives

1772
01:08:56,130 --> 01:08:58,210
与替代品相关的独立性PMT的性能提高20％到30％
that i talked about lately which is the independence relevant of alternatives

1773
01:08:58,210 --> 01:09:02,030
与替代品相关的独立性PMT的性能提高20％到30％
independence relevant of alternatives PMT does 20 to 30 percent better at

1774
01:09:02,030 --> 01:09:02,040
与替代品相关的独立性PMT的性能提高20％到30％
PMT does 20 to 30 percent better at prediction out-of-sample without

1775
01:09:02,040 --> 01:09:04,430
预测超出样本，且不违反PT，然后返回到
PMT does 20 to 30 percent better at prediction out-of-sample without

1776
01:09:04,430 --> 01:09:07,490
预测超出样本，且不违反PT，然后返回到
prediction out-of-sample without violations PT and is followed back to a

1777
01:09:07,490 --> 01:09:07,500
预测超出样本，且不违反PT，然后返回到
violations PT and is followed back to a manner and is it for san francisco shock

1778
01:09:07,500 --> 01:09:13,790
方式，是否用于旧金山冲击数据，并再次访问八分之八？
violations PT and is followed back to a manner and is it for san francisco shock

1779
01:09:13,790 --> 01:09:19,090
方式，是否用于旧金山冲击数据，并再次访问八分之八？
manner and is it for san francisco shock data and again visit for eight of eight

1780
01:09:19,090 --> 01:09:19,100
方式，是否用于旧金山冲击数据，并再次访问八分之八？
data and again visit for eight of eight actually ordered options and previous

1781
01:09:19,100 --> 01:09:22,910
实际订购的选件和之前的将近60件，因此这里再次为15 T型号
data and again visit for eight of eight actually ordered options and previous

1782
01:09:22,910 --> 01:09:27,290
实际订购的选件和之前的将近60件，因此这里再次为15 T型号
actually ordered options and previous almost 60 so here again the 15 T model

1783
01:09:27,290 --> 01:09:27,300
实际订购的选件和之前的将近60件，因此这里再次为15 T型号
almost 60 so here again the 15 T model is doing better than two other models

1784
01:09:27,300 --> 01:09:32,720
比其他两个模型做得更好
almost 60 so here again the 15 T model is doing better than two other models

1785
01:09:32,720 --> 01:09:34,269
所以我们可以说，随着学习程序的应用，数据上的错误
almost 60 so here again the 15 T model is doing better than two other models

1786
01:09:34,269 --> 01:09:34,279
所以我们可以说，随着学习程序的应用，数据上的错误


1787
01:09:34,279 --> 01:09:40,700
所以我们可以说，随着学习程序的应用，数据上的错误
so which we can say that error on the data as the learning procedures applied

1788
01:09:40,700 --> 01:09:40,710
所以我们可以说，随着学习程序的应用，数据上的错误
data as the learning procedures applied to increase the amount of data the

1789
01:09:40,710 --> 01:09:43,579
增加数据量，结果平均超过1,000
data as the learning procedures applied to increase the amount of data the

1790
01:09:43,579 --> 01:09:45,590
增加数据量，结果平均超过1,000
to increase the amount of data the results are averaged over 1,000

1791
01:09:45,590 --> 01:09:45,600
增加数据量，结果平均超过1,000
results are averaged over 1,000 different permutations of the data to be

1792
01:09:45,600 --> 01:09:47,870
应变和文本数据在7520中数据的不同排列
results are averaged over 1,000 different permutations of the data to be

1793
01:09:47,870 --> 01:09:51,189
应变和文本数据在7520中数据的不同排列
different permutations of the data to be in the 7520 upon strain and text data

1794
01:09:51,189 --> 01:09:51,199
应变和文本数据在7520中数据的不同排列
in the 7520 upon strain and text data prediction error on a 25 percent hold of

1795
01:09:51,199 --> 01:09:54,860
PNC M＆L和mmm混合数据保留25％的预测误差
in the 7520 upon strain and text data prediction error on a 25 percent hold of

1796
01:09:54,860 --> 01:09:58,490
PNC M＆L和mmm混合数据保留25％的预测误差
prediction error on a 25 percent hold of the data for the PNC M&amp;L and mmm mix

1797
01:09:58,490 --> 01:09:58,500
PNC M＆L和mmm混合数据保留25％的预测误差
the data for the PNC M&amp;L and mmm mix terminal models have been shown and 50

1798
01:09:58,500 --> 01:10:01,880
终端模型已经显示出来，而50毫克母亲的这些改善了30
the data for the PNC M&amp;L and mmm mix terminal models have been shown and 50

1799
01:10:01,880 --> 01:10:05,209
终端模型已经显示出来，而50毫克母亲的这些改善了30
terminal models have been shown and 50 mg mother's these improvement of thirty

1800
01:10:05,209 --> 01:10:05,219
终端模型已经显示出来，而50毫克母亲的这些改善了30
mg mother's these improvement of thirty five point nine percent and twenty four

1801
01:10:05,219 --> 01:10:07,729
五分百分之九的百分之二十四点百分之五的预测误差
mg mother's these improvement of thirty five point nine percent and twenty four

1802
01:10:07,729 --> 01:10:09,709
五分百分之九的百分之二十四点百分之五的预测误差
five point nine percent and twenty four point five percent in prediction error

1803
01:10:09,709 --> 01:10:09,719
五分百分之九的百分之二十四点百分之五的预测误差
point five percent in prediction error over M&amp;L and mix terminal respectively

1804
01:10:09,719 --> 01:10:12,830
在M＆L和混合终端上训练时，分别训练百分之七十五
point five percent in prediction error over M&amp;L and mix terminal respectively

1805
01:10:12,830 --> 01:10:15,890
在M＆L和混合终端上训练时，分别训练百分之七十五
over M&amp;L and mix terminal respectively when training on seven five percent as a

1806
01:10:15,890 --> 01:10:15,900
在M＆L和混合终端上训练时，分别训练百分之七十五
when training on seven five percent as a danger for this summary we introduced a

1807
01:10:15,900 --> 01:10:19,729
危险的是，我们介绍了一个非常明智的选择马尔可夫链模型，并且
when training on seven five percent as a danger for this summary we introduced a

1808
01:10:19,729 --> 01:10:22,130
危险的是，我们介绍了一个非常明智的选择马尔可夫链模型，并且
danger for this summary we introduced a very wise choice Markov chain models and

1809
01:10:22,130 --> 01:10:22,140
危险的是，我们介绍了一个非常明智的选择马尔可夫链模型，并且
very wise choice Markov chain models and the speed choice which define selection

1810
01:10:22,140 --> 01:10:24,860
根据断言定义选择属性的速度选择
very wise choice Markov chain models and the speed choice which define selection

1811
01:10:24,860 --> 01:10:26,780
根据断言定义选择属性的速度选择
the speed choice which define selection properties according to the assertion

1812
01:10:26,780 --> 01:10:26,790
根据断言定义选择属性的速度选择
properties according to the assertion distribution of a continuous time Markov

1813
01:10:26,790 --> 01:10:30,020
连续时间的分布马尔可夫链的灵活性
properties according to the assertion distribution of a continuous time Markov

1814
01:10:30,020 --> 01:10:34,340
连续时间的分布马尔可夫链的灵活性
distribution of a continuous time Markov chains the flexibility for which the

1815
01:10:34,340 --> 01:10:34,350
连续时间的分布马尔可夫链的灵活性
chains the flexibility for which the flexibility we demonstrate that tthe

1816
01:10:34,350 --> 01:10:37,760
灵活性，我们证明该模型展现出理想的结构是
chains the flexibility for which the flexibility we demonstrate that tthe

1817
01:10:37,760 --> 01:10:42,950
灵活性，我们证明该模型展现出理想的结构是
flexibility we demonstrate that tthe model exhibits desirable structure was

1818
01:10:42,950 --> 01:10:42,960
灵活性，我们证明该模型展现出理想的结构是
model exhibits desirable structure was preceding the uniform expansion property

1819
01:10:42,960 --> 01:10:45,740
之前仅在M＆L模型中发现的均匀膨胀特性之前
model exhibits desirable structure was preceding the uniform expansion property

1820
01:10:45,740 --> 01:10:48,740
之前仅在M＆L模型中发现的均匀膨胀特性之前
preceding the uniform expansion property previously found only in the M&amp;L model

1821
01:10:48,740 --> 01:10:48,750
之前仅在M＆L模型中发现的均匀膨胀特性之前
previously found only in the M&amp;L model and elimination by aspects model the

1822
01:10:48,750 --> 01:10:52,729
和消除方面建模工作状态，厨房
previously found only in the M&amp;L model and elimination by aspects model the

1823
01:10:52,729 --> 01:10:54,200
和消除方面建模工作状态，厨房
and elimination by aspects model the working on states that the kitchen

1824
01:10:54,200 --> 01:10:54,210
和消除方面建模工作状态，厨房
working on states that the kitchen remodel exhibits concern

1825
01:10:54,210 --> 01:10:55,959
改型表现出关注的可建设性，这意味着统一
working on states that the kitchen remodel exhibits concern

1826
01:10:55,959 --> 01:10:58,280
改型表现出关注的可建设性，这意味着统一
remodel exhibits concern constructability which implies uniform

1827
01:10:58,280 --> 01:10:58,290
改型表现出关注的可建设性，这意味着统一
constructability which implies uniform expansion we have to show that the

1828
01:10:58,290 --> 01:11:00,950
扩展，我们必须证明鸽子的报价数量
constructability which implies uniform expansion we have to show that the

1829
01:11:00,950 --> 01:11:02,600
扩展，我们必须证明鸽子的报价数量
expansion we have to show that the pigeons amount of offers

1830
01:11:02,600 --> 01:11:02,610
扩展，我们必须证明鸽子的报价数量
pigeons amount of offers thenceforward inference through Emily

1831
01:11:02,610 --> 01:11:06,200
然后通过艾米丽（Emily）进行推论，这将学习代理模型
pigeons amount of offers thenceforward inference through Emily

1832
01:11:06,200 --> 01:11:08,540
然后通过艾米丽（Emily）进行推论，这将学习代理模型
thenceforward inference through Emily and that will learn the agency model

1833
01:11:08,540 --> 01:11:08,550
然后通过艾米丽（Emily）进行推论，这将学习代理模型
and that will learn the agency model predicts

1834
01:11:08,550 --> 01:11:09,290
预测会改善她的选择
and that will learn the agency model predicts

1835
01:11:09,290 --> 01:11:11,180
预测会改善她的选择
predicts improve her choice it will be

1836
01:11:11,180 --> 01:11:11,190
预测会改善她的选择
improve her choice it will be significantly higher utility the respect

1837
01:11:11,190 --> 01:11:14,149
与其他两种型号相比，实用性高得多
improve her choice it will be significantly higher utility the respect

1838
01:11:14,149 --> 01:11:16,830
与其他两种型号相比，实用性高得多
significantly higher utility the respect to two other models

1839
01:11:16,830 --> 01:11:16,840
与其他两种型号相比，实用性高得多
to two other models for the future because this is a very

1840
01:11:16,840 --> 01:11:18,959
对于未来，因为这是样本组的一个非常新颖的想法，
to two other models for the future because this is a very

1841
01:11:18,959 --> 01:11:23,970
对于未来，因为这是样本组的一个非常新颖的想法，
for the future because this is a very novel idea by the sample group the

1842
01:11:23,970 --> 01:11:23,980
对于未来，因为这是样本组的一个非常新颖的想法，
novel idea by the sample group the possibility and tractability of the PCs

1843
01:11:23,980 --> 01:11:27,479
PC的可能性和易处理性该模型开放了许多计算
novel idea by the sample group the possibility and tractability of the PCs

1844
01:11:27,479 --> 01:11:30,330
PC的可能性和易处理性该模型开放了许多计算
possibility and tractability of the PCs the model opens up many computing

1845
01:11:30,330 --> 01:11:30,340
PC的可能性和易处理性该模型开放了许多计算
the model opens up many computing research directions the efficiency of

1846
01:11:30,340 --> 01:11:33,000
研究方向TMC模型的效率建议探索其他
the model opens up many computing research directions the efficiency of

1847
01:11:33,000 --> 01:11:35,069
研究方向TMC模型的效率建议探索其他
research directions the efficiency of the TMC model suggests exploring other

1848
01:11:35,069 --> 01:11:35,079
研究方向TMC模型的效率建议探索其他
the TMC model suggests exploring other effective parameterization for q the

1849
01:11:35,079 --> 01:11:37,470
q的有效参数化速率矩阵，包括展开L
the TMC model suggests exploring other effective parameterization for q the

1850
01:11:37,470 --> 01:11:40,080
q的有效参数化速率矩阵，包括展开L
effective parameterization for q the rate matrix including developing L

1851
01:11:40,080 --> 01:11:40,090
q的有效参数化速率矩阵，包括展开L
rate matrix including developing L special methods which excludability

1852
01:11:40,090 --> 01:11:42,649
排他性的特殊方法有两个开放式计算
rate matrix including developing L special methods which excludability

1853
01:11:42,649 --> 01:11:45,149
排他性的特殊方法有两个开放式计算
special methods which excludability there are two open computational

1854
01:11:45,149 --> 01:11:45,159
排他性的特殊方法有两个开放式计算
there are two open computational questions such as extremely large lining

1855
01:11:45,159 --> 01:11:47,879
诸如极大衬里的大型Luud最大化之类的问题
there are two open computational questions such as extremely large lining

1856
01:11:47,879 --> 01:11:50,189
诸如极大衬里的大型Luud最大化之类的问题
questions such as extremely large lining the large Luud maximization using

1857
01:11:50,189 --> 01:11:50,199
诸如极大衬里的大型Luud最大化之类的问题
the large Luud maximization using gradients of the implicit function

1858
01:11:50,199 --> 01:11:53,640
隐式函数定义的渐变，这些是参考
the large Luud maximization using gradients of the implicit function

1859
01:11:53,640 --> 01:11:57,510
隐式函数定义的渐变，这些是参考
gradients of the implicit function definitions and these are the references

1860
01:11:57,510 --> 01:11:57,520
隐式函数定义的渐变，这些是参考
definitions and these are the references for for this room thank you

1861
01:11:57,520 --> 01:12:02,340
对于这个房间谢谢
definitions and these are the references for for this room thank you

1862
01:12:02,340 --> 01:12:02,760
[掌声]
definitions and these are the references for for this room thank you

1863
01:12:02,760 --> 01:12:02,770
[掌声]


1864
01:12:02,770 --> 01:12:06,020
[掌声]
[Applause]

