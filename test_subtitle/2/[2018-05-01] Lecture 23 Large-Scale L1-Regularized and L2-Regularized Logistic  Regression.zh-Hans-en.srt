1
00:01:17,340 --> 00:01:22,110
Pancho的舒适科学工程，这就是我们的项目是
Pancho's comfort sciences engineering and that's our project is the father of

2
00:01:22,110 --> 00:01:22,120
Pancho的舒适科学工程，这就是我们的项目是
and that's our project is the father of I scale it allows realization

3
00:01:22,120 --> 00:01:28,590
我缩放它可以实现
and that's our project is the father of I scale it allows realization

4
00:01:28,590 --> 00:01:31,010
这个内容和巴比伦怎么办
and that's our project is the father of I scale it allows realization

5
00:01:31,010 --> 00:01:31,020
这个内容和巴比伦怎么办


6
00:01:31,020 --> 00:01:38,550
这个内容和巴比伦怎么办
what with this content and Babylon

7
00:01:38,550 --> 00:01:47,480
我们的氧气在物理上并置
what with this content and Babylon

8
00:01:47,480 --> 00:01:47,490
我们的氧气在物理上并置


9
00:01:47,490 --> 00:01:52,310
我们的氧气在物理上并置
our oxygens are collocated physically

10
00:01:52,310 --> 00:01:54,600
他们很高兴
our oxygens are collocated physically

11
00:01:54,600 --> 00:01:54,610
他们很高兴


12
00:01:54,610 --> 00:01:57,480
他们很高兴
and they were happy

13
00:01:57,480 --> 00:02:04,390
主要是我们在2014年去了发送者和参议院
and they were happy

14
00:02:04,390 --> 00:02:04,400
主要是我们在2014年去了发送者和参议院


15
00:02:04,400 --> 00:02:17,209
主要是我们在2014年去了发送者和参议院
it's mostly we go to the sender and Senate in 2014

16
00:02:17,209 --> 00:02:17,219
主要是我们在2014年去了发送者和参议院
we go to the sender and Senate in 2014 and we go stock unit director for my

17
00:02:17,219 --> 00:02:21,260
因为我有许多不同的救恩方式，所以我去了股票部门主管
we go to the sender and Senate in 2014 and we go stock unit director for my

18
00:02:21,260 --> 00:02:25,910
因为我有许多不同的救恩方式，所以我去了股票部门主管
and we go stock unit director for my because many different still salvation

19
00:02:25,910 --> 00:02:25,920
因为我有许多不同的救恩方式，所以我去了股票部门主管
because many different still salvation so only one feel alive today and so

20
00:02:25,920 --> 00:02:31,310
所以今天只有一个人还活着，所以没有国家或实施
because many different still salvation so only one feel alive today and so

21
00:02:31,310 --> 00:02:33,890
所以今天只有一个人还活着，所以没有国家或实施
so only one feel alive today and so there is no countries or implementation

22
00:02:33,890 --> 00:02:33,900
所以今天只有一个人还活着，所以没有国家或实施
there is no countries or implementation in 2014 but a remarkable achievements

23
00:02:33,900 --> 00:02:37,220
在2014年，但在国际
there is no countries or implementation in 2014 but a remarkable achievements

24
00:02:37,220 --> 00:02:38,960
在2014年，但在国际
in 2014 but a remarkable achievements can be provided in international

25
00:02:38,960 --> 00:02:38,970
在2014年，但在国际
can be provided in international measures where there are enormous

26
00:02:38,970 --> 00:02:41,870
工业界和工业界付出巨大努力的措施
can be provided in international measures where there are enormous

27
00:02:41,870 --> 00:02:46,010
工业界和工业界付出巨大努力的措施
measures where there are enormous efforts both from industry and

28
00:02:46,010 --> 00:02:46,020
工业界和工业界付出巨大努力的措施
efforts both from industry and they invested to this field so a lot of

29
00:02:46,020 --> 00:02:49,280
他们在这个领域投入了很多知识，否则你会回答
efforts both from industry and they invested to this field so a lot of

30
00:02:49,280 --> 00:02:50,960
他们在这个领域投入了很多知识，否则你会回答
they invested to this field so a lot of learnings and else you're gonna answer

31
00:02:50,960 --> 00:02:50,970
他们在这个领域投入了很多知识，否则你会回答
learnings and else you're gonna answer on experience

32
00:02:50,970 --> 00:02:53,990
靠经验哦，真的
learnings and else you're gonna answer on experience

33
00:02:53,990 --> 00:02:59,330
靠经验哦，真的
on experience oh really

34
00:02:59,330 --> 00:02:59,340
靠经验哦，真的
oh really so my whole thing to follow him he'll

35
00:02:59,340 --> 00:03:02,310
所以我跟随他的整个事情他都会明白
oh really so my whole thing to follow him he'll

36
00:03:02,310 --> 00:03:04,980
所以我跟随他的整个事情他都会明白
so my whole thing to follow him he'll understand

37
00:03:04,980 --> 00:03:13,150
和
so my whole thing to follow him he'll understand

38
00:03:13,150 --> 00:03:13,160
和


39
00:03:13,160 --> 00:03:16,160
和
with

40
00:03:16,160 --> 00:03:30,470
[音乐]
with

41
00:03:30,470 --> 00:03:30,480
[音乐]


42
00:03:30,480 --> 00:03:33,590
[音乐]
[Music]

43
00:03:33,590 --> 00:03:35,830
他们也程序
[Music]

44
00:03:35,830 --> 00:03:35,840
他们也程序


45
00:03:35,840 --> 00:03:39,560
他们也程序
they also procedure

46
00:03:39,560 --> 00:03:56,780
居民激励
they also procedure

47
00:03:56,780 --> 00:03:56,790
居民激励


48
00:03:56,790 --> 00:04:00,840
居民激励
the resident incentive

49
00:04:00,840 --> 00:04:06,480
冒险实际上一直在试图使一些
the resident incentive

50
00:04:06,480 --> 00:04:06,490
冒险实际上一直在试图使一些


51
00:04:06,490 --> 00:04:11,830
冒险实际上一直在试图使一些
adventures it's actually been trying to make some

52
00:04:11,830 --> 00:04:11,840
冒险实际上一直在试图使一些
it's actually been trying to make some sort of internship

53
00:04:11,840 --> 00:04:14,680
实习
it's actually been trying to make some sort of internship

54
00:04:14,680 --> 00:04:16,349
只是表情符号句子可以在此块中描述，并且这些停顿之间
it's actually been trying to make some sort of internship

55
00:04:16,349 --> 00:04:16,359
只是表情符号句子可以在此块中描述，并且这些停顿之间


56
00:04:16,359 --> 00:04:22,050
只是表情符号句子可以在此块中描述，并且这些停顿之间
just emoticon sentences can be described in this block and these pauses between

57
00:04:22,050 --> 00:04:22,060
只是表情符号句子可以在此块中描述，并且这些停顿之间
in this block and these pauses between world

58
00:04:22,060 --> 00:04:25,060
世界
in this block and these pauses between world

59
00:04:25,060 --> 00:04:28,650
[音乐]
in this block and these pauses between world

60
00:04:28,650 --> 00:04:28,660
[音乐]


61
00:04:28,660 --> 00:04:35,710
[音乐]
[Music]

62
00:04:35,710 --> 00:04:35,720
[音乐]


63
00:04:35,720 --> 00:04:38,929
[音乐]
[Music]

64
00:04:38,929 --> 00:04:38,930
和
[Music]

65
00:04:38,930 --> 00:04:38,940
和


66
00:04:38,940 --> 00:04:41,940
和
and

67
00:04:41,940 --> 00:04:45,020
两个大比目鱼的儿子，但你只知道他们想
and

68
00:04:45,020 --> 00:04:45,030
两个大比目鱼的儿子，但你只知道他们想


69
00:04:45,030 --> 00:04:52,419
两个大比目鱼的儿子，但你只知道他们想
the son of two halibut you only knew they wanted to

70
00:04:52,419 --> 00:04:56,090
哦
the son of two halibut you only knew they wanted to

71
00:04:56,090 --> 00:04:56,100
哦


72
00:04:56,100 --> 00:04:58,130
哦
Oh

73
00:04:58,130 --> 00:04:59,429
这里有一个很高的单一配方
Oh

74
00:04:59,429 --> 00:04:59,439
这里有一个很高的单一配方


75
00:04:59,439 --> 00:05:04,649
这里有一个很高的单一配方
there's a high single formula up here

76
00:05:04,649 --> 00:05:07,190
[音乐]
there's a high single formula up here

77
00:05:07,190 --> 00:05:07,200
[音乐]


78
00:05:07,200 --> 00:05:10,300
[音乐]
[Music]

79
00:05:10,300 --> 00:06:13,690
功能丧失
[Music]

80
00:06:13,690 --> 00:06:13,700
功能丧失


81
00:06:13,700 --> 00:06:16,300
功能丧失
lost function

82
00:06:16,300 --> 00:06:21,119
最后
lost function

83
00:06:21,119 --> 00:06:21,129
最后


84
00:06:21,129 --> 00:06:27,989
最后
and finally

85
00:06:27,989 --> 00:06:30,920
[音乐]
and finally

86
00:06:30,920 --> 00:06:30,930
[音乐]


87
00:06:30,930 --> 00:06:34,040
[音乐]
[Music]

88
00:06:34,040 --> 00:06:41,200
和
[Music]

89
00:06:41,200 --> 00:06:41,210
和


90
00:06:41,210 --> 00:06:44,210
和
and

91
00:06:44,210 --> 00:06:44,410
有一些场合
and

92
00:06:44,410 --> 00:06:44,420
有一些场合


93
00:06:44,420 --> 00:06:49,090
有一些场合
there are some occasions

94
00:06:49,090 --> 00:06:58,830
[音乐]
there are some occasions

95
00:06:58,830 --> 00:06:58,840
[音乐]


96
00:06:58,840 --> 00:07:01,910
[音乐]
[Music]

97
00:07:01,910 --> 00:07:01,989
在今天的前五名中，我们太复杂了，模型太简单了，我们
[Music]

98
00:07:01,989 --> 00:07:01,999
在今天的前五名中，我们太复杂了，模型太简单了，我们


99
00:07:01,999 --> 00:07:08,839
在今天的前五名中，我们太复杂了，模型太简单了，我们
in today's top five we were too complicated model simple very hot and we

100
00:07:08,839 --> 00:07:08,849
在今天的前五名中，我们太复杂了，模型太简单了，我们
complicated model simple very hot and we can

101
00:07:08,849 --> 00:07:11,300
能够
complicated model simple very hot and we can

102
00:07:11,300 --> 00:07:14,050
[音乐]
complicated model simple very hot and we can

103
00:07:14,050 --> 00:07:14,060
[音乐]


104
00:07:14,060 --> 00:07:17,120
[音乐]
[Music]

105
00:07:17,120 --> 00:07:18,040
直觉等于还是很简单
[Music]

106
00:07:18,040 --> 00:07:18,050
直觉等于还是很简单


107
00:07:18,050 --> 00:07:22,840
直觉等于还是很简单
the intuitive is equal to is still simple

108
00:07:22,840 --> 00:07:32,580
太多了
the intuitive is equal to is still simple

109
00:07:32,580 --> 00:07:32,590
太多了


110
00:07:32,590 --> 00:07:35,800
太多了
too much

111
00:07:35,800 --> 00:07:36,340
否或
too much

112
00:07:36,340 --> 00:07:36,350
否或


113
00:07:36,350 --> 00:07:38,980
否或
no or

114
00:07:38,980 --> 00:07:38,989
并使用我的形式
no or

115
00:07:38,989 --> 00:07:38,999
并使用我的形式


116
00:07:38,999 --> 00:07:44,159
并使用我的形式
and using the form of my

117
00:07:44,159 --> 00:07:45,570
[音乐]
and using the form of my

118
00:07:45,570 --> 00:07:45,580
[音乐]


119
00:07:45,580 --> 00:07:48,740
[音乐]
[Music]

120
00:07:48,740 --> 00:07:48,870
一个显然
[Music]

121
00:07:48,870 --> 00:07:48,880
一个显然


122
00:07:48,880 --> 00:07:52,270
一个显然
one apparently

123
00:07:52,270 --> 00:07:58,879
和
one apparently

124
00:07:58,879 --> 00:07:58,889
和


125
00:07:58,889 --> 00:08:01,580
和
and

126
00:08:01,580 --> 00:08:13,420
[音乐]他们想忽略
and

127
00:08:13,420 --> 00:08:13,430
[音乐]他们想忽略


128
00:08:13,430 --> 00:08:18,350
[音乐]他们想忽略
[Music] they'll want to ignore

129
00:08:18,350 --> 00:08:18,360
[音乐]他们想忽略
they'll want to ignore oh please for geography

130
00:08:18,360 --> 00:08:21,439
哦，请查询地理哦
they'll want to ignore oh please for geography

131
00:08:21,439 --> 00:08:23,509
哦，请查询地理哦
oh please for geography Oh

132
00:08:23,509 --> 00:08:32,790
电永远不会穿他们，因为他们喜欢来
oh please for geography Oh

133
00:08:32,790 --> 00:08:32,800
电永远不会穿他们，因为他们喜欢来


134
00:08:32,800 --> 00:08:37,529
电永远不会穿他们，因为他们喜欢来
electric never wear em because they like to come by

135
00:08:37,529 --> 00:08:41,810
如果您要编辑我的尺寸
electric never wear em because they like to come by

136
00:08:41,810 --> 00:08:41,820
如果您要编辑我的尺寸


137
00:08:41,820 --> 00:08:47,780
如果您要编辑我的尺寸
if you'll edit my size

138
00:08:47,780 --> 00:08:52,380
事实上电影《幻想曲》中的野牛
if you'll edit my size

139
00:08:52,380 --> 00:08:52,390
事实上电影《幻想曲》中的野牛


140
00:08:52,390 --> 00:08:56,910
事实上电影《幻想曲》中的野牛
in fact a buffalo in film Fantasia extra

141
00:08:56,910 --> 00:09:01,490
所以所有那些
in fact a buffalo in film Fantasia extra

142
00:09:01,490 --> 00:09:01,500
所以所有那些


143
00:09:01,500 --> 00:09:07,340
所以所有那些
so with all those

144
00:09:07,340 --> 00:09:11,860
和四种不同的颜色
so with all those

145
00:09:11,860 --> 00:09:11,870
和四种不同的颜色


146
00:09:11,870 --> 00:09:20,210
和四种不同的颜色
and four different color

147
00:09:20,210 --> 00:09:23,040
但如果不仅有像比尔这样的人告诉梦想中的家，
and four different color

148
00:09:23,040 --> 00:09:23,050
但如果不仅有像比尔这样的人告诉梦想中的家，


149
00:09:23,050 --> 00:09:31,190
但如果不仅有像比尔这样的人告诉梦想中的家，
but if there's no only feel like a people like Bill told the dream home

150
00:09:31,190 --> 00:09:31,200
但如果不仅有像比尔这样的人告诉梦想中的家，
people like Bill told the dream home life's real castle

151
00:09:31,200 --> 00:09:35,130
生活的真实城堡
people like Bill told the dream home life's real castle

152
00:09:35,130 --> 00:09:55,200
他的生活可能很美，也许对其他客人来说
people like Bill told the dream home life's real castle

153
00:09:55,200 --> 00:09:55,210
他的生活可能很美，也许对其他客人来说


154
00:09:55,210 --> 00:10:04,920
他的生活可能很美，也许对其他客人来说
his life can be beautiful maybe for other guests

155
00:10:04,920 --> 00:10:06,699
与其他常识互动很令人兴奋
his life can be beautiful maybe for other guests

156
00:10:06,699 --> 00:10:06,709
与其他常识互动很令人兴奋


157
00:10:06,709 --> 00:10:20,439
与其他常识互动很令人兴奋
it's been exciting to interact with other common sense

158
00:10:20,439 --> 00:10:24,480
一切
it's been exciting to interact with other common sense

159
00:10:24,480 --> 00:10:24,490
一切


160
00:10:24,490 --> 00:10:27,490
一切
everything

161
00:10:27,490 --> 00:10:29,080
你们都平常吗
everything

162
00:10:29,080 --> 00:10:29,090
你们都平常吗


163
00:10:29,090 --> 00:10:33,770
你们都平常吗
are you all common

164
00:10:33,770 --> 00:10:38,100
因为当帐单在那儿的时候
are you all common

165
00:10:38,100 --> 00:10:38,110
因为当帐单在那儿的时候


166
00:10:38,110 --> 00:10:43,589
因为当帐单在那儿的时候
because when the bill was right there

167
00:10:43,589 --> 00:10:46,680
整个阶段都吃华夫饼的自然色
because when the bill was right there

168
00:10:46,680 --> 00:10:46,690
整个阶段都吃华夫饼的自然色


169
00:10:46,690 --> 00:10:52,420
整个阶段都吃华夫饼的自然色
and eat natural color of waffle work all over the stage that

170
00:10:52,420 --> 00:10:52,430
整个阶段都吃华夫饼的自然色
over the stage that [Music]

171
00:10:52,430 --> 00:10:53,960
[音乐]不同于大多数
over the stage that [Music]

172
00:10:53,960 --> 00:10:58,290
[音乐]不同于大多数
[Music] unlike most all of it

173
00:10:58,290 --> 00:10:58,300
[音乐]不同于大多数
unlike most all of it [Music]

174
00:10:58,300 --> 00:11:00,510
[音乐]哦
unlike most all of it [Music]

175
00:11:00,510 --> 00:11:02,550
[音乐]哦
[Music] Oh

176
00:11:02,550 --> 00:11:05,260
与海洋对齐
[Music] Oh

177
00:11:05,260 --> 00:11:05,270
与海洋对齐


178
00:11:05,270 --> 00:11:09,070
与海洋对齐
with ocean alignment

179
00:11:09,070 --> 00:11:10,200
你好
with ocean alignment

180
00:11:10,200 --> 00:11:10,210
你好


181
00:11:10,210 --> 00:11:13,210
你好
hi

182
00:11:13,210 --> 00:11:26,160
哦
hi

183
00:11:26,160 --> 00:11:26,170
哦


184
00:11:26,170 --> 00:11:28,170
哦
Oh

185
00:11:28,170 --> 00:11:45,690
在我的面前，这是一个疯狂的科学家或老师，毫无疑问地讲了这么多话
Oh

186
00:11:45,690 --> 00:11:45,700
在我的面前，这是一个疯狂的科学家或老师，毫无疑问地讲了这么多话


187
00:11:45,700 --> 00:11:52,329
在我的面前，这是一个疯狂的科学家或老师，毫无疑问地讲了这么多话
in my face this is a crazy scientist or teacher telling without question so much

188
00:11:52,329 --> 00:11:52,339
在我的面前，这是一个疯狂的科学家或老师，毫无疑问地讲了这么多话
teacher telling without question so much all those tickets are a year of conquer

189
00:11:52,339 --> 00:11:56,019
所有这些门票都是征服欧洲的一年。
teacher telling without question so much all those tickets are a year of conquer

190
00:11:56,019 --> 00:12:00,009
所有这些门票都是征服欧洲的一年。
all those tickets are a year of conquer Europe this fortune different features

191
00:12:00,009 --> 00:12:00,019
所有这些门票都是征服欧洲的一年。
Europe this fortune different features and opportunity of all penalties amazing

192
00:12:00,019 --> 00:12:02,860
和所有惩罚的机会，惊人的生物
Europe this fortune different features and opportunity of all penalties amazing

193
00:12:02,860 --> 00:12:04,600
和所有惩罚的机会，惊人的生物
and opportunity of all penalties amazing creatures

194
00:12:04,600 --> 00:12:04,610
和所有惩罚的机会，惊人的生物
creatures all the clothing falling in touch with

195
00:12:04,610 --> 00:12:06,490
所有的衣服都与艾米和
creatures all the clothing falling in touch with

196
00:12:06,490 --> 00:12:09,070
所有的衣服都与艾米和
all the clothing falling in touch with both Amy and

197
00:12:09,070 --> 00:12:09,930
那些孩子在那里有25,000个牙科学院
all the clothing falling in touch with both Amy and

198
00:12:09,930 --> 00:12:09,940
那些孩子在那里有25,000个牙科学院


199
00:12:09,940 --> 00:12:14,830
那些孩子在那里有25,000个牙科学院
and those kids are along on 25,000 college of dentistry there

200
00:12:14,830 --> 00:12:14,840
那些孩子在那里有25,000个牙科学院
college of dentistry there that's slightly on faceted and the very

201
00:12:14,840 --> 00:12:18,610
略微切面，并且此框提供的人员非常多
college of dentistry there that's slightly on faceted and the very

202
00:12:18,610 --> 00:12:21,250
略微切面，并且此框提供的人员非常多
that's slightly on faceted and the very people that are provided by this box

203
00:12:21,250 --> 00:12:21,260
略微切面，并且此框提供的人员非常多
people that are provided by this box it's also a binary package equivalent

204
00:12:21,260 --> 00:12:23,740
这也是一个二进制程序包等效测试，仅像哦100个样本和
people that are provided by this box it's also a binary package equivalent

205
00:12:23,740 --> 00:12:27,850
这也是一个二进制程序包等效测试，仅像哦100个样本和
it's also a binary package equivalent test only like Oh 100 samples and the

206
00:12:27,850 --> 00:12:27,860
这也是一个二进制程序包等效测试，仅像哦100个样本和
test only like Oh 100 samples and the relative truth of 1810 was 14

207
00:12:27,860 --> 00:12:34,600
1810年的相对真相是14
test only like Oh 100 samples and the relative truth of 1810 was 14

208
00:12:34,600 --> 00:12:35,880
以及反对的立场和619的附带常数
test only like Oh 100 samples and the relative truth of 1810 was 14

209
00:12:35,880 --> 00:12:35,890
以及反对的立场和619的附带常数


210
00:12:35,890 --> 00:12:45,000
以及反对的立场和619的附带常数
and the yeah stance against it and the incidental constants of 619

211
00:12:45,000 --> 00:12:45,010
以及反对的立场和619的附带常数
and the incidental constants of 619 position we completed the first one you

212
00:12:45,010 --> 00:12:47,639
位置我们完成了第一个你有我的罪过
and the incidental constants of 619 position we completed the first one you

213
00:12:47,639 --> 00:12:50,730
位置我们完成了第一个你有我的罪过
position we completed the first one you have my sin

214
00:12:50,730 --> 00:12:56,660
哦
position we completed the first one you have my sin

215
00:12:56,660 --> 00:12:56,670
哦


216
00:12:56,670 --> 00:12:58,700
哦
Oh

217
00:12:58,700 --> 00:13:01,760
超过人
Oh

218
00:13:01,760 --> 00:13:01,770
超过人


219
00:13:01,770 --> 00:13:05,090
超过人
over people

220
00:13:05,090 --> 00:13:06,980
却无法满足图片尺寸和
over people

221
00:13:06,980 --> 00:13:06,990
却无法满足图片尺寸和


222
00:13:06,990 --> 00:13:11,720
却无法满足图片尺寸和
without fulfilling to image size and

223
00:13:11,720 --> 00:13:18,350
我们将配件与迭代器保持在一起，并且
without fulfilling to image size and

224
00:13:18,350 --> 00:13:18,360
我们将配件与迭代器保持在一起，并且


225
00:13:18,360 --> 00:13:22,750
我们将配件与迭代器保持在一起，并且
we kept our accessories with the iterator and

226
00:13:22,750 --> 00:13:22,760
我们将配件与迭代器保持在一起，并且
iterator and it's the most function value and this is

227
00:13:22,760 --> 00:13:25,920
这是最实用的价值，这只是一种宗教，
iterator and it's the most function value and this is

228
00:13:25,920 --> 00:13:30,490
这是最实用的价值，这只是一种宗教，
it's the most function value and this is only one religion and

229
00:13:30,490 --> 00:13:38,590
所以积累和旋转
it's the most function value and this is only one religion and

230
00:13:38,590 --> 00:13:38,600
所以积累和旋转


231
00:13:38,600 --> 00:13:48,850
所以积累和旋转
and

232
00:13:48,850 --> 00:13:48,860
所以积累和旋转


233
00:13:48,860 --> 00:13:54,459
所以积累和旋转
so the accumulation and spinning and

234
00:13:54,459 --> 00:13:59,080
与所有的黄金
so the accumulation and spinning and

235
00:13:59,080 --> 00:13:59,090
与所有的黄金


236
00:13:59,090 --> 00:14:02,080
与所有的黄金
with all the gold

237
00:14:02,080 --> 00:14:08,220
[音乐]
with all the gold

238
00:14:08,220 --> 00:14:08,230
[音乐]


239
00:14:08,230 --> 00:14:11,379
[音乐]
[Music]

240
00:14:11,379 --> 00:14:12,900
这里
[Music]

241
00:14:12,900 --> 00:14:12,910
这里


242
00:14:12,910 --> 00:14:15,910
这里
here

243
00:14:15,910 --> 00:14:16,320
还有这个苹果
here

244
00:14:16,320 --> 00:14:16,330
还有这个苹果


245
00:14:16,330 --> 00:14:19,470
还有这个苹果
and this Apple

246
00:14:19,470 --> 00:14:32,280
[音乐]
and this Apple

247
00:14:32,280 --> 00:14:32,290
[音乐]


248
00:14:32,290 --> 00:14:39,300
[音乐]
[Music]

249
00:14:39,300 --> 00:14:39,310
[音乐]


250
00:14:39,310 --> 00:14:42,370
[音乐]
[Music]

251
00:14:42,370 --> 00:14:56,050
我们有有趣的残疾令人恶心
[Music]

252
00:14:56,050 --> 00:14:56,060
我们有有趣的残疾令人恶心


253
00:14:56,060 --> 00:15:04,000
我们有有趣的残疾令人恶心
we have fun disabilities that's disgusting

254
00:15:04,000 --> 00:15:05,700
例如
we have fun disabilities that's disgusting

255
00:15:05,700 --> 00:15:05,710
例如


256
00:15:05,710 --> 00:15:09,990
例如
for example

257
00:15:09,990 --> 00:15:19,460
[音乐]
for example

258
00:15:19,460 --> 00:15:19,470
[音乐]


259
00:15:19,470 --> 00:15:22,629
[音乐]
[Music]

260
00:15:22,629 --> 00:15:22,850
我们爱
[Music]

261
00:15:22,850 --> 00:15:22,860
我们爱


262
00:15:22,860 --> 00:15:26,130
我们爱
we love

263
00:15:26,130 --> 00:15:28,980
通过您的基本思想对我的知识的看法
we love

264
00:15:28,980 --> 00:15:28,990
通过您的基本思想对我的知识的看法


265
00:15:28,990 --> 00:15:34,090
通过您的基本思想对我的知识的看法
the opinion of my knowledge through your basic thinking

266
00:15:34,090 --> 00:15:34,990
是的
the opinion of my knowledge through your basic thinking

267
00:15:34,990 --> 00:15:35,000
是的


268
00:15:35,000 --> 00:15:37,780
是的
yeah

269
00:15:37,780 --> 00:15:50,040
没看到
yeah

270
00:15:50,040 --> 00:15:50,050
没看到


271
00:15:50,050 --> 00:15:53,100
没看到
didn't see

272
00:15:53,100 --> 00:15:53,620
我们可以看到我的孩子度过的时光
didn't see

273
00:15:53,620 --> 00:15:53,630
我们可以看到我的孩子度过的时光


274
00:15:53,630 --> 00:15:59,019
我们可以看到我的孩子度过的时光
we can see the times of my children go through

275
00:15:59,019 --> 00:16:01,530
1:44哦
we can see the times of my children go through

276
00:16:01,530 --> 00:16:01,540
1:44哦


277
00:16:01,540 --> 00:16:04,040
1:44哦
1:44 Oh

278
00:16:04,040 --> 00:16:04,050
1:44哦
Oh to

279
00:16:04,050 --> 00:16:07,050
至
Oh to

280
00:16:07,050 --> 00:16:09,210
如果你喜欢他们正在调查他们的家人，那是因为
Oh to

281
00:16:09,210 --> 00:16:09,220
如果你喜欢他们正在调查他们的家人，那是因为


282
00:16:09,220 --> 00:16:13,650
如果你喜欢他们正在调查他们的家人，那是因为
and if you like a little like you're investigating their family huh because

283
00:16:13,650 --> 00:16:13,660
如果你喜欢他们正在调查他们的家人，那是因为
investigating their family huh because every

284
00:16:13,660 --> 00:16:16,259
每一个
investigating their family huh because every

285
00:16:16,259 --> 00:16:17,970
是的，感觉就像
investigating their family huh because every

286
00:16:17,970 --> 00:16:17,980
是的，感觉就像


287
00:16:17,980 --> 00:16:22,410
是的，感觉就像
and yeah feels like

288
00:16:22,410 --> 00:16:22,760
[音乐]
and yeah feels like

289
00:16:22,760 --> 00:16:22,770
[音乐]


290
00:16:22,770 --> 00:16:25,870
[音乐]
[Music]

291
00:16:25,870 --> 00:16:30,990
听这些更多的阐述
[Music]

292
00:16:30,990 --> 00:16:31,000
听这些更多的阐述


293
00:16:31,000 --> 00:16:34,890
听这些更多的阐述
listen to these more elaboration

294
00:16:34,890 --> 00:16:37,100
考虑到工作地点范围内的选拔代理人标准
listen to these more elaboration

295
00:16:37,100 --> 00:16:37,110
考虑到工作地点范围内的选拔代理人标准


296
00:16:37,110 --> 00:16:46,820
考虑到工作地点范围内的选拔代理人标准
think about choice agent standard within the assignment over the freaking place

297
00:16:46,820 --> 00:16:46,930
确切地说，我们了解更多[音乐]
think about choice agent standard within the assignment over the freaking place

298
00:16:46,930 --> 00:16:46,940
确切地说，我们了解更多[音乐]


299
00:16:46,940 --> 00:16:52,240
确切地说，我们了解更多[音乐]
exactly we learn more [Music]

300
00:16:52,240 --> 00:17:07,870
解决方案更小
exactly we learn more [Music]

301
00:17:07,870 --> 00:17:07,880
解决方案更小


302
00:17:07,880 --> 00:17:13,610
解决方案更小
the solution is smaller and

303
00:17:13,610 --> 00:17:19,610
是确切的问题
the solution is smaller and

304
00:17:19,610 --> 00:17:19,620
是确切的问题


305
00:17:19,620 --> 00:17:23,509
是确切的问题
is the exact problem

306
00:17:23,509 --> 00:17:26,900
[音乐]很多艺术家
is the exact problem

307
00:17:26,900 --> 00:17:26,910
[音乐]很多艺术家


308
00:17:26,910 --> 00:17:31,899
[音乐]很多艺术家
[Music] a lot of artists

309
00:17:31,899 --> 00:17:32,580
美丽或
[Music] a lot of artists

310
00:17:32,580 --> 00:17:32,590
美丽或


311
00:17:32,590 --> 00:17:37,539
美丽或
beautiful or

312
00:17:37,539 --> 00:17:46,600
哦
beautiful or

313
00:17:46,600 --> 00:17:46,610
哦


314
00:17:46,610 --> 00:17:48,640
哦
Oh

315
00:17:48,640 --> 00:18:01,850
几乎
Oh

316
00:18:01,850 --> 00:18:01,860
几乎


317
00:18:01,860 --> 00:18:04,280
几乎
almost

318
00:18:04,280 --> 00:18:10,490
[掌声]
almost

319
00:18:10,490 --> 00:18:10,500
[掌声]


320
00:18:10,500 --> 00:18:13,700
[掌声]
[Applause]

321
00:18:13,700 --> 00:18:39,920
哦，是的，我想我很喜欢，因为你曾经
[Applause]

322
00:18:39,920 --> 00:18:39,930
哦，是的，我想我很喜欢，因为你曾经


323
00:18:39,930 --> 00:18:46,610
哦，是的，我想我很喜欢，因为你曾经
Oh agency yeah I suppose me feel fancy because you're ever

324
00:18:46,610 --> 00:18:46,620
哦，是的，我想我很喜欢，因为你曾经
because you're ever the beginning stage of commotion on a

325
00:18:46,620 --> 00:18:50,770
领导者抵制的真正的通勤的开始阶段
because you're ever the beginning stage of commotion on a

326
00:18:50,770 --> 00:18:54,230
领导者抵制的真正的通勤的开始阶段
the beginning stage of commotion on a real I resisted by the leaders for

327
00:18:54,230 --> 00:18:54,240
领导者抵制的真正的通勤的开始阶段
real I resisted by the leaders for passive occasions like some conflicts

328
00:18:54,240 --> 00:18:57,920
像一些冲突这样的消极场合今天相互吸引了我的图像网格
real I resisted by the leaders for passive occasions like some conflicts

329
00:18:57,920 --> 00:19:00,410
像一些冲突这样的消极场合今天相互吸引了我的图像网格
passive occasions like some conflicts attracted each other today my image mesh

330
00:19:00,410 --> 00:19:00,420
像一些冲突这样的消极场合今天相互吸引了我的图像网格
attracted each other today my image mesh also attracted by

331
00:19:00,420 --> 00:19:04,040
也被吸引
attracted each other today my image mesh also attracted by

332
00:19:04,040 --> 00:19:04,160
在我的旅行分类示例中，通常有很多南美
attracted each other today my image mesh also attracted by

333
00:19:04,160 --> 00:19:04,170
在我的旅行分类示例中，通常有很多南美


334
00:19:04,170 --> 00:19:11,390
在我的旅行分类示例中，通常有很多南美
in my example to classify a trip there are typically a lot of South America

335
00:19:11,390 --> 00:19:11,400
在我的旅行分类示例中，通常有很多南美
are typically a lot of South America have different features of action and

336
00:19:11,400 --> 00:19:13,520
有不同的动作特征和谈论是否倾向
are typically a lot of South America have different features of action and

337
00:19:13,520 --> 00:19:15,980
有不同的动作特征和谈论是否倾向
have different features of action and the tendencies to talk about whether

338
00:19:15,980 --> 00:19:15,990
有不同的动作特征和谈论是否倾向
the tendencies to talk about whether this is good or not

339
00:19:15,990 --> 00:19:19,610
这是好还是不好
the tendencies to talk about whether this is good or not

340
00:19:19,610 --> 00:21:16,500
好的，大家好，我说我是尼克·日内瓦（Nick Geneva），我想介绍一下
the tendencies to talk about whether this is good or not

341
00:21:16,500 --> 00:21:16,510
好的，大家好，我说我是尼克·日内瓦（Nick Geneva），我想介绍一下


342
00:21:16,510 --> 00:21:25,020
好的，大家好，我说我是尼克·日内瓦（Nick Geneva），我想介绍一下
all right hello everyone says I'm Nick Geneva and I want to presenting on

343
00:21:25,020 --> 00:21:25,030
好的，大家好，我说我是尼克·日内瓦（Nick Geneva），我想介绍一下
Geneva and I want to presenting on comprising graphical models with my

344
00:21:25,030 --> 00:21:28,930
用我的原始标题组成的图形模型是神经网络，但是
Geneva and I want to presenting on comprising graphical models with my

345
00:21:28,930 --> 00:21:31,060
用我的原始标题组成的图形模型是神经网络，但是
comprising graphical models with my original title was neural networks but

346
00:21:31,060 --> 00:21:31,070
用我的原始标题组成的图形模型是神经网络，但是
original title was neural networks but we're going to generalize it to machine

347
00:21:31,070 --> 00:21:32,800
我们将其推广到机器学习中以进行结构化表示
original title was neural networks but we're going to generalize it to machine

348
00:21:32,800 --> 00:21:37,990
我们将其推广到机器学习中以进行结构化表示
we're going to generalize it to machine learning for structural representation

349
00:21:37,990 --> 00:21:38,910
好的，所以本来我想这个演讲是一个故事
we're going to generalize it to machine learning for structural representation

350
00:21:38,910 --> 00:21:38,920
好的，所以本来我想这个演讲是一个故事


351
00:21:38,920 --> 00:21:45,070
好的，所以本来我想这个演讲是一个故事
all right so originally this I guess this presentation is kind of a story of

352
00:21:45,070 --> 00:21:45,080
好的，所以本来我想这个演讲是一个故事
this presentation is kind of a story of how I was originally going to focus on

353
00:21:45,080 --> 00:21:48,070
我本来打算如何在2016年这里重点关注这篇论文的
this presentation is kind of a story of how I was originally going to focus on

354
00:21:48,070 --> 00:21:50,140
我本来打算如何在2016年这里重点关注这篇论文的
how I was originally going to focus on this paper up here this 2016 there's

355
00:21:50,140 --> 00:21:50,150
我本来打算如何在2016年这里重点关注这篇论文的
this paper up here this 2016 there's paper then basically got lost in one of

356
00:21:50,150 --> 00:21:52,240
基本上，这些论文实际上就被其中的一篇参考文献所迷惑了。
this paper up here this 2016 there's paper then basically got lost in one of

357
00:21:52,240 --> 00:21:54,940
基本上，这些论文实际上就被其中的一篇参考文献所迷惑了。
paper then basically got lost in one of the references which actually ended up

358
00:21:54,940 --> 00:21:54,950
基本上，这些论文实际上就被其中的一篇参考文献所迷惑了。
the references which actually ended up proposing that did I found kind of

359
00:21:54,950 --> 00:21:56,560
提议我发现了一种有趣且难以理解的东西
the references which actually ended up proposing that did I found kind of

360
00:21:56,560 --> 00:21:57,910
提议我发现了一种有趣且难以理解的东西
proposing that did I found kind of interesting and hard to understand

361
00:21:57,910 --> 00:21:57,920
提议我发现了一种有趣且难以理解的东西
interesting and hard to understand because it motivated a lot of what kind

362
00:21:57,920 --> 00:22:00,940
因为它激发了很多正在发生的想法
interesting and hard to understand because it motivated a lot of what kind

363
00:22:00,940 --> 00:22:02,350
因为它激发了很多正在发生的想法
because it motivated a lot of what kind of ideas that are happening up in this

364
00:22:02,350 --> 00:22:02,360
因为它激发了很多正在发生的想法
of ideas that are happening up in this one so yeah all right starting off when

365
00:22:02,360 --> 00:22:07,270
是的，是的，当我们建立模型时，可以开始
of ideas that are happening up in this one so yeah all right starting off when

366
00:22:07,270 --> 00:22:09,040
是的，是的，当我们建立模型时，可以开始
one so yeah all right starting off when we're building a model where the model

367
00:22:09,040 --> 00:22:09,050
是的，是的，当我们建立模型时，可以开始
we're building a model where the model to represent data a model to generate

368
00:22:09,050 --> 00:22:10,540
表示数据的模型通常会生成您想要的任何一天
we're building a model where the model to represent data a model to generate

369
00:22:10,540 --> 00:22:13,150
表示数据的模型通常会生成您想要的任何一天
to represent data a model to generate day of whatever you want generally you

370
00:22:13,150 --> 00:22:13,160
表示数据的模型通常会生成您想要的任何一天
day of whatever you want generally you may have two different goals you may

371
00:22:13,160 --> 00:22:14,740
可能有两个不同的目标，您可能需要一个灵活的方法，所以
day of whatever you want generally you may have two different goals you may

372
00:22:14,740 --> 00:22:17,350
可能有两个不同的目标，您可能需要一个灵活的方法，所以
may have two different goals you may want to have a flexible approach so

373
00:22:17,350 --> 00:22:17,360
可能有两个不同的目标，您可能需要一个灵活的方法，所以
want to have a flexible approach so let's say you have some non parametric

374
00:22:17,360 --> 00:22:19,260
假设您有一些复杂的高的非参数表示
want to have a flexible approach so let's say you have some non parametric

375
00:22:19,260 --> 00:22:21,520
假设您有一些复杂的高的非参数表示
let's say you have some non parametric representation of some complex high

376
00:22:21,520 --> 00:22:21,530
假设您有一些复杂的高的非参数表示
representation of some complex high dimensional data or you may want to

377
00:22:21,530 --> 00:22:23,590
维数据，或者您可能希望构建我们的方法，这可能是
representation of some complex high dimensional data or you may want to

378
00:22:23,590 --> 00:22:25,360
维数据，或者您可能希望构建我们的方法，这可能是
dimensional data or you may want to structure our approach and this may be

379
00:22:25,360 --> 00:22:25,370
维数据，或者您可能希望构建我们的方法，这可能是
structure our approach and this may be to find a structure representation of

380
00:22:25,370 --> 00:22:27,520
查找可以概括的数据的结构表示形式
structure our approach and this may be to find a structure representation of

381
00:22:27,520 --> 00:22:29,110
查找可以概括的数据的结构表示形式
to find a structure representation of data that can then be generalized

382
00:22:29,110 --> 00:22:29,120
查找可以概括的数据的结构表示形式
data that can then be generalized perhaps so in terms of platform model

383
00:22:29,120 --> 00:22:32,080
也许就平台模型而言，这就是我所说的灵活模型时的意思。
data that can then be generalized perhaps so in terms of platform model

384
00:22:32,080 --> 00:22:33,670
也许就平台模型而言，这就是我所说的灵活模型时的意思。
perhaps so in terms of platform model that's when I say flexible models I mean

385
00:22:33,670 --> 00:22:33,680
也许就平台模型而言，这就是我所说的灵活模型时的意思。
that's when I say flexible models I mean like I said I'm talking about these

386
00:22:33,680 --> 00:22:35,410
就像我说的我在谈论这些黑匣子方法，所以机器学习
that's when I say flexible models I mean like I said I'm talking about these

387
00:22:35,410 --> 00:22:37,210
就像我说的我在谈论这些黑匣子方法，所以机器学习
like I said I'm talking about these black box methods so machine learning

388
00:22:37,210 --> 00:22:37,220
就像我说的我在谈论这些黑匣子方法，所以机器学习
black box methods so machine learning you're looking for buzzword like neural

389
00:22:37,220 --> 00:22:38,770
您正在寻找像神经网络卷积网络这样的流行词
black box methods so machine learning you're looking for buzzword like neural

390
00:22:38,770 --> 00:22:40,530
您正在寻找像神经网络卷积网络这样的流行词
you're looking for buzzword like neural networks convolutional Network

391
00:22:40,530 --> 00:22:40,540
您正在寻找像神经网络卷积网络这样的流行词
networks convolutional Network autoencoders Gans support vector

392
00:22:40,540 --> 00:22:44,080
自动编码器Gans支持向量机aa网站结构模型
networks convolutional Network autoencoders Gans support vector

393
00:22:44,080 --> 00:22:47,920
自动编码器Gans支持向量机aa网站结构模型
autoencoders Gans support vector machines aa website structure model

394
00:22:47,920 --> 00:22:47,930
自动编码器Gans支持向量机aa网站结构模型
machines aa website structure model course PGM class so it's all about

395
00:22:47,930 --> 00:22:50,740
当然是PGM课程，所以这全都与概率图形模型有关
machines aa website structure model course PGM class so it's all about

396
00:22:50,740 --> 00:22:52,300
当然是PGM课程，所以这全都与概率图形模型有关
course PGM class so it's all about probabilistic graphical models stuff

397
00:22:52,300 --> 00:22:52,310
当然是PGM课程，所以这全都与概率图形模型有关
probabilistic graphical models stuff where we actually have values that means

398
00:22:52,310 --> 00:22:54,730
在这里，我们实际拥有的价值意味着某些东西，而不仅仅是随机的
probabilistic graphical models stuff where we actually have values that means

399
00:22:54,730 --> 00:22:56,260
在这里，我们实际拥有的价值意味着某些东西，而不仅仅是随机的
where we actually have values that means something rather than just random

400
00:22:56,260 --> 00:22:56,270
在这里，我们实际拥有的价值意味着某些东西，而不仅仅是随机的
something rather than just random weights and stuff that they're just kind

401
00:22:56,270 --> 00:22:58,160
权重和东西，它们只是某种功能的匹配，所以这个问题
something rather than just random weights and stuff that they're just kind

402
00:22:58,160 --> 00:23:02,960
权重和东西，它们只是某种功能的匹配，所以这个问题
weights and stuff that they're just kind matching up a function so the question

403
00:23:02,960 --> 00:23:02,970
权重和东西，它们只是某种功能的匹配，所以这个问题
matching up a function so the question is what do we want what happens if we

404
00:23:02,970 --> 00:23:05,990
我们想要的是什么如果我们既想要A的灵活性又想要
matching up a function so the question is what do we want what happens if we

405
00:23:05,990 --> 00:23:08,030
我们想要的是什么如果我们既想要A的灵活性又想要
is what do we want what happens if we want both A's flexible yet also

406
00:23:08,030 --> 00:23:08,040
我们想要的是什么如果我们既想要A的灵活性又想要
want both A's flexible yet also structured approach so this means

407
00:23:08,040 --> 00:23:10,190
结构化的方法，所以这实际上意味着，如果我想让我们
want both A's flexible yet also structured approach so this means

408
00:23:10,190 --> 00:23:12,860
结构化的方法，所以这实际上意味着，如果我想让我们
structured approach so this means essentially like if I want like let's

409
00:23:12,860 --> 00:23:12,870
结构化的方法，所以这实际上意味着，如果我想让我们
essentially like if I want like let's say like I have some high dimensional

410
00:23:12,870 --> 00:23:14,120
就像我有一些需要映射的高维数据一样
essentially like if I want like let's say like I have some high dimensional

411
00:23:14,120 --> 00:23:16,130
就像我有一些需要映射的高维数据一样
say like I have some high dimensional data that I need to map or something

412
00:23:16,130 --> 00:23:16,140
就像我有一些需要映射的高维数据一样
data that I need to map or something with some flexible method but I also

413
00:23:16,140 --> 00:23:17,870
用一些灵活的方法，但是我还想要一些值，然后
data that I need to map or something with some flexible method but I also

414
00:23:17,870 --> 00:23:20,090
用一些灵活的方法，但是我还想要一些值，然后
with some flexible method but I also want some sort of values I can then

415
00:23:20,090 --> 00:23:20,100
用一些灵活的方法，但是我还想要一些值，然后
want some sort of values I can then relate to maybe physical dynamics

416
00:23:20,100 --> 00:23:21,350
与物理动力有关，实际舞会有些事
want some sort of values I can then relate to maybe physical dynamics

417
00:23:21,350 --> 00:23:23,420
与物理动力有关，实际舞会有些事
relate to maybe physical dynamics there's something about the actual prom

418
00:23:23,420 --> 00:23:23,430
与物理动力有关，实际舞会有些事
there's something about the actual prom because of that price so just the

419
00:23:23,430 --> 00:23:26,540
因为这个价格，所以问题只是作为一种激励
there's something about the actual prom because of that price so just the

420
00:23:26,540 --> 00:23:28,610
因为这个价格，所以问题只是作为一种激励
because of that price so just the problem to kind of motivate this as an

421
00:23:28,610 --> 00:23:28,620
因为这个价格，所以问题只是作为一种激励
problem to kind of motivate this as an example so let's suppose that we have

422
00:23:28,620 --> 00:23:31,640
这个例子，让我们假设我们在这座山的内部
problem to kind of motivate this as an example so let's suppose that we have

423
00:23:31,640 --> 00:23:33,860
这个例子，让我们假设我们在这座山的内部
example so let's suppose that we have this mountain that's inside of this

424
00:23:33,860 --> 00:23:33,870
这个例子，让我们假设我们在这座山的内部
this mountain that's inside of this spherical container moving around and

425
00:23:33,870 --> 00:23:36,110
球形容器移动，我们的输入数据将是一些
this mountain that's inside of this spherical container moving around and

426
00:23:36,110 --> 00:23:38,240
球形容器移动，我们的输入数据将是一些
spherical container moving around and our input data is going to be some

427
00:23:38,240 --> 00:23:38,250
球形容器移动，我们的输入数据将是一些
our input data is going to be some height so basically our input is this

428
00:23:38,250 --> 00:23:40,160
高度，所以基本上我们的输入就是这张图片，而当我们输出时
our input data is going to be some height so basically our input is this

429
00:23:40,160 --> 00:23:43,610
高度，所以基本上我们的输入就是这张图片，而当我们输出时
height so basically our input is this image and from that when our output

430
00:23:43,610 --> 00:23:43,620
高度，所以基本上我们的输入就是这张图片，而当我们输出时
image and from that when our output debase be the interest in trouble

431
00:23:43,620 --> 00:23:46,130
降低对本质上鼠标的故障结构的兴趣
image and from that when our output debase be the interest in trouble

432
00:23:46,130 --> 00:23:47,930
降低对本质上鼠标的故障结构的兴趣
debase be the interest in trouble structure of essentially the mouse's

433
00:23:47,930 --> 00:23:47,940
降低对本质上鼠标的故障结构的兴趣
structure of essentially the mouse's actual behavior so these may be the

434
00:23:47,940 --> 00:23:51,200
实际行为，因此可能是当前的舞蹈编辑或动作
structure of essentially the mouse's actual behavior so these may be the

435
00:23:51,200 --> 00:23:54,800
实际行为，因此可能是当前的舞蹈编辑或动作
actual behavior so these may be the current of dance edits in or movement no

436
00:23:54,800 --> 00:23:54,810
实际行为，因此可能是当前的舞蹈编辑或动作
current of dance edits in or movement no I'm not so as they clearly have this

437
00:23:54,810 --> 00:23:56,690
我不是这样，因为他们清楚地收到了这个高维图像，所以我们
current of dance edits in or movement no I'm not so as they clearly have this

438
00:23:56,690 --> 00:23:59,210
我不是这样，因为他们清楚地收到了这个高维图像，所以我们
I'm not so as they clearly have this high dimensional image coming in so we

439
00:23:59,210 --> 00:23:59,220
我不是这样，因为他们清楚地收到了这个高维图像，所以我们
high dimensional image coming in so we kind of want a flexible model to learn

440
00:23:59,220 --> 00:24:00,830
我想要一个灵活的模型来学习，但是我们想要的输出
high dimensional image coming in so we kind of want a flexible model to learn

441
00:24:00,830 --> 00:24:03,800
我想要一个灵活的模型来学习，但是我们想要的输出
kind of want a flexible model to learn that but then our output we want to have

442
00:24:03,800 --> 00:24:03,810
我想要一个灵活的模型来学习，但是我们想要的输出
that but then our output we want to have some sort of probabilistic inference on

443
00:24:03,810 --> 00:24:05,750
关于鼠标动作可能的某种概率推断
that but then our output we want to have some sort of probabilistic inference on

444
00:24:05,750 --> 00:24:07,700
关于鼠标动作可能的某种概率推断
some sort of probabilistic inference on what's probably of the mouse's actions

445
00:24:07,700 --> 00:24:07,710
关于鼠标动作可能的某种概率推断
what's probably of the mouse's actions sitting up on its hind legs or if it's

446
00:24:07,710 --> 00:24:09,470
坐在它的后腿上，或者如果它在挠耳和类似的东西
what's probably of the mouse's actions sitting up on its hind legs or if it's

447
00:24:09,470 --> 00:24:11,000
坐在它的后腿上，或者如果它在挠耳和类似的东西
sitting up on its hind legs or if it's scratching its ear and stuff like that

448
00:24:11,000 --> 00:24:11,010
坐在它的后腿上，或者如果它在挠耳和类似的东西
scratching its ear and stuff like that those are very structured output on so

449
00:24:11,010 --> 00:24:14,090
这些都是非常结构化的输出，因此基本上是一种组合，
scratching its ear and stuff like that those are very structured output on so

450
00:24:14,090 --> 00:24:16,940
这些都是非常结构化的输出，因此基本上是一种组合，
those are very structured output on so basically one kind of a combination and

451
00:24:16,940 --> 00:24:16,950
这些都是非常结构化的输出，因此基本上是一种组合，
basically one kind of a combination and that's kind of a whole main idea of this

452
00:24:16,950 --> 00:24:19,730
这是本文的主要主题，也是我觉得越来越冷的一种感觉
basically one kind of a combination and that's kind of a whole main idea of this

453
00:24:19,730 --> 00:24:22,340
这是本文的主要主题，也是我觉得越来越冷的一种感觉
that's kind of a whole main idea of this paper and kind of cold I think growing

454
00:24:22,340 --> 00:24:22,350
这是本文的主要主题，也是我觉得越来越冷的一种感觉
paper and kind of cold I think growing field is essentially can we combine

455
00:24:22,350 --> 00:24:24,650
我们基本上可以将这些领域结合起来以构建更强大的建模工具
paper and kind of cold I think growing field is essentially can we combine

456
00:24:24,650 --> 00:24:27,110
我们基本上可以将这些领域结合起来以构建更强大的建模工具
field is essentially can we combine these to build stronger modeling tools

457
00:24:27,110 --> 00:24:27,120
我们基本上可以将这些领域结合起来以构建更强大的建模工具
these to build stronger modeling tools that can really get the best of both

458
00:24:27,120 --> 00:24:29,240
真正可以兼得两全其美的本质是它，为此，我们
these to build stronger modeling tools that can really get the best of both

459
00:24:29,240 --> 00:24:33,770
真正可以兼得两全其美的本质是它，为此，我们
that can really get the best of both worlds is essentially it so for this we

460
00:24:33,770 --> 00:24:33,780
真正可以兼得两全其美的本质是它，为此，我们
worlds is essentially it so for this we won't be looking at might we be looking

461
00:24:33,780 --> 00:24:35,690
不会看，也许我们会看一些更沉闷的东西
worlds is essentially it so for this we won't be looking at might we be looking

462
00:24:35,690 --> 00:24:36,940
不会看，也许我们会看一些更沉闷的东西
won't be looking at might we be looking at something a little bit more dull

463
00:24:36,940 --> 00:24:36,950
不会看，也许我们会看一些更沉闷的东西
at something a little bit more dull which is a natural clustering frog so

464
00:24:36,950 --> 00:24:40,970
这是一个自然的聚集青蛙，所以这只是一个例子，这是一个真正的
at something a little bit more dull which is a natural clustering frog so

465
00:24:40,970 --> 00:24:43,430
这是一个自然的聚集青蛙，所以这只是一个例子，这是一个真正的
which is a natural clustering frog so these are just an example it's a really

466
00:24:43,430 --> 00:24:43,440
这是一个自然的聚集青蛙，所以这只是一个例子，这是一个真正的
these are just an example it's a really great toy problem on one we'll be

467
00:24:43,440 --> 00:24:45,050
我们将要看到的一个巨大的玩具问题是螺旋形的问题，也许在
these are just an example it's a really great toy problem on one we'll be

468
00:24:45,050 --> 00:24:47,870
我们将要看到的一个巨大的玩具问题是螺旋形的问题，也许在
great toy problem on one we'll be looking at is spiral problems maybe in a

469
00:24:47,870 --> 00:24:47,880
我们将要看到的一个巨大的玩具问题是螺旋形的问题，也许在
looking at is spiral problems maybe in a spiral and the reason for that is one

470
00:24:47,880 --> 00:24:51,320
螺旋上升，原因之一是它们都在两个以内，这很棒
looking at is spiral problems maybe in a spiral and the reason for that is one

471
00:24:51,320 --> 00:24:53,000
螺旋上升，原因之一是它们都在两个以内，这很棒
spiral and the reason for that is one it's great they're both within two

472
00:24:53,000 --> 00:24:53,010
螺旋上升，原因之一是它们都在两个以内，这很棒
it's great they're both within two also it's these clusters are very

473
00:24:53,010 --> 00:24:56,750
这些集群都是我们想要的非常离散的集群
it's great they're both within two also it's these clusters are very

474
00:24:56,750 --> 00:24:58,790
这些集群都是我们想要的非常离散的集群
also it's these clusters are very discrete clusters that we want to you

475
00:24:58,790 --> 00:24:58,800
这些集群都是我们想要的非常离散的集群
discrete clusters that we want to you know categorize though each one of these

476
00:24:58,800 --> 00:25:00,380
知道分类，尽管您想找到的每个分类都是不同的
discrete clusters that we want to you know categorize though each one of these

477
00:25:00,380 --> 00:25:01,730
知道分类，尽管您想找到的每个分类都是不同的
know categorize though each one of these you want to just find is a different

478
00:25:01,730 --> 00:25:01,740
知道分类，尽管您想找到的每个分类都是不同的
you want to just find is a different class however they are still there

479
00:25:01,740 --> 00:25:04,730
上课，但是他们仍然是非大学的，所以在那里
you want to just find is a different class however they are still there

480
00:25:04,730 --> 00:25:08,690
上课，但是他们仍然是非大学的，所以在那里
class however they are still there non-college so there and this is

481
00:25:08,690 --> 00:25:08,700
上课，但是他们仍然是非大学的，所以在那里
non-college so there and this is unsupervised learning problem so they

482
00:25:08,700 --> 00:25:10,220
无监督的学习问题，所以他们睡觉你没有任何标签，所以
non-college so there and this is unsupervised learning problem so they

483
00:25:10,220 --> 00:25:13,010
无监督的学习问题，所以他们睡觉你没有任何标签，所以
unsupervised learning problem so they sleep you don't have any labels so

484
00:25:13,010 --> 00:25:13,020
无监督的学习问题，所以他们睡觉你没有任何标签，所以
sleep you don't have any labels so before we get into the actual paper room

485
00:25:13,020 --> 00:25:15,530
在进入实际的纸室之前，请访问我们的老朋友高斯混合物
sleep you don't have any labels so before we get into the actual paper room

486
00:25:15,530 --> 00:25:18,500
在进入实际的纸室之前，请访问我们的老朋友高斯混合物
before we get into the actual paper room visit our old friend Gaussian mixture

487
00:25:18,500 --> 00:25:18,510
在进入实际的纸室之前，请访问我们的老朋友高斯混合物
visit our old friend Gaussian mixture models to go over so this is the

488
00:25:18,510 --> 00:25:23,180
模型，所以这是非贝叶斯公式，我发现了这一点，
visit our old friend Gaussian mixture models to go over so this is the

489
00:25:23,180 --> 00:25:26,060
模型，所以这是非贝叶斯公式，我发现了这一点，
models to go over so this is the non-bayesian formulation I find this and

490
00:25:26,060 --> 00:25:26,070
模型，所以这是非贝叶斯公式，我发现了这一点，
non-bayesian formulation I find this and Bishop just to review if you're like me

491
00:25:26,070 --> 00:25:29,360
主教只是想回顾一下您是否像我一样，并怀念我们倾向于的金鱼
non-bayesian formulation I find this and Bishop just to review if you're like me

492
00:25:29,360 --> 00:25:31,670
主教只是想回顾一下您是否像我一样，并怀念我们倾向于的金鱼
Bishop just to review if you're like me and have a memory of a goldfish we tend

493
00:25:31,670 --> 00:25:31,680
主教只是想回顾一下您是否像我一样，并怀念我们倾向于的金鱼
and have a memory of a goldfish we tend to forget this stuff however the idea of

494
00:25:31,680 --> 00:25:35,300
忘记这些东西，但是生态混合模型的想法是，我们有一个
and have a memory of a goldfish we tend to forget this stuff however the idea of

495
00:25:35,300 --> 00:25:37,810
忘记这些东西，但是生态混合模型的想法是，我们有一个
to forget this stuff however the idea of Ecology mixture model is that we have a

496
00:25:37,810 --> 00:25:37,820
忘记这些东西，但是生态混合模型的想法是，我们有一个
Ecology mixture model is that we have a latent variable Z which is binary

497
00:25:37,820 --> 00:25:40,310
潜在变量Z是二进制变量，表示哪个类别的
Ecology mixture model is that we have a latent variable Z which is binary

498
00:25:40,310 --> 00:25:43,430
潜在变量Z是二进制变量，表示哪个类别的
latent variable Z which is binary variable which represents which class of

499
00:25:43,430 --> 00:25:43,440
潜在变量Z是二进制变量，表示哪个类别的
variable which represents which class of which cause mixture we're pulling from

500
00:25:43,440 --> 00:25:45,140
导致我们从中混合的原因，对于每种原因，我们都要确保
variable which represents which class of which cause mixture we're pulling from

501
00:25:45,140 --> 00:25:47,300
导致我们从中混合的原因，对于每种原因，我们都要确保
which cause mixture we're pulling from and we have for each causing make sure

502
00:25:47,300 --> 00:25:47,310
导致我们从中混合的原因，对于每种原因，我们都要确保
and we have for each causing make sure we have respective mean and it also

503
00:25:47,310 --> 00:25:49,130
我们有各自的平均值，也有精度，我们可以增加复杂度a
and we have for each causing make sure we have respective mean and it also

504
00:25:49,130 --> 00:25:52,160
我们有各自的平均值，也有精度，我们可以增加复杂度a
we have respective mean and it also precision we can increase complexity a

505
00:25:52,160 --> 00:25:52,170
我们有各自的平均值，也有精度，我们可以增加复杂度a
precision we can increase complexity a little bit and make it kind of more

506
00:25:52,170 --> 00:25:53,750
并通过引入一些使它变得更多的贝叶斯相关性
precision we can increase complexity a little bit and make it kind of more

507
00:25:53,750 --> 00:25:55,640
并通过引入一些使它变得更多的贝叶斯相关性
little bit and make it kind of more Bayesian correlation by introducing some

508
00:25:55,640 --> 00:25:55,650
并通过引入一些使它变得更多的贝叶斯相关性
Bayesian correlation by introducing some priors onto our precision and all

509
00:25:55,650 --> 00:25:57,230
先验我们的精确度和所有确定性，这不是
Bayesian correlation by introducing some priors onto our precision and all

510
00:25:57,230 --> 00:26:00,140
先验我们的精确度和所有确定性，这不是
priors onto our precision and all certainty which is T nope here these are

511
00:26:00,140 --> 00:26:00,150
先验我们的精确度和所有确定性，这不是
certainty which is T nope here these are our high performers that we're

512
00:26:00,150 --> 00:26:01,130
我们要介绍的高绩效人才，所以这仅仅是一些
certainty which is T nope here these are our high performers that we're

513
00:26:01,130 --> 00:26:04,400
我们要介绍的高绩效人才，所以这仅仅是一些
our high performers that we're introducing so this is just some

514
00:26:04,400 --> 00:26:04,410
我们要介绍的高绩效人才，所以这仅仅是一些
introducing so this is just some reminders again if you want to know more

515
00:26:04,410 --> 00:26:06,800
再次提醒您，如果您想了解更多评分，请刷新您的记忆
introducing so this is just some reminders again if you want to know more

516
00:26:06,800 --> 00:26:12,080
再次提醒您，如果您想了解更多评分，请刷新您的记忆
reminders again if you want to know more much rating so just refresh your memory

517
00:26:12,080 --> 00:26:12,090
再次提醒您，如果您想了解更多评分，请刷新您的记忆
much rating so just refresh your memory so again our joint distribution it's

518
00:26:12,090 --> 00:26:14,630
再次，我们的联合分布将是
much rating so just refresh your memory so again our joint distribution it's

519
00:26:14,630 --> 00:26:18,130
再次，我们的联合分布将是
so again our joint distribution it's going to be a the multiplication of

520
00:26:18,130 --> 00:26:18,140
再次，我们的联合分布将是
going to be a the multiplication of essentially like including our priors or

521
00:26:18,140 --> 00:26:20,840
本质上就像包括我们的先验一样，可能性采取以下形式：
going to be a the multiplication of essentially like including our priors or

522
00:26:20,840 --> 00:26:22,370
本质上就像包括我们的先验一样，可能性采取以下形式：
essentially like including our priors or not the likelihood takes the form of

523
00:26:22,370 --> 00:26:22,380
本质上就像包括我们的先验一样，可能性采取以下形式：
not the likelihood takes the form of course our cause in C is binary

524
00:26:22,380 --> 00:26:27,410
当然，我们在C中的原因是二进制的
not the likelihood takes the form of course our cause in C is binary

525
00:26:27,410 --> 00:26:28,360
是的，只是混合系数，我们会通过它快速完成-我
not the likelihood takes the form of course our cause in C is binary

526
00:26:28,360 --> 00:26:28,370
是的，只是混合系数，我们会通过它快速完成-我


527
00:26:28,370 --> 00:26:32,630
是的，只是混合系数，我们会通过它快速完成-我
yeah just mixing coefficients we're just gonna go kind of fast through this - I

528
00:26:32,630 --> 00:26:32,640
是的，只是混合系数，我们会通过它快速完成-我
gonna go kind of fast through this - I have greens on afterwards

529
00:26:32,640 --> 00:26:33,920
后来果岭开了，但这里只用了什么东西，所以
gonna go kind of fast through this - I have greens on afterwards

530
00:26:33,920 --> 00:26:36,200
后来果岭开了，但这里只用了什么东西，所以
have greens on afterwards yet only used a anything here alright so

531
00:26:36,200 --> 00:26:36,210
后来果岭开了，但这里只用了什么东西，所以
yet only used a anything here alright so just to refresh your memory for actually

532
00:26:36,210 --> 00:26:39,140
只是为了刷新您的记忆，以便进行此问题的调整
yet only used a anything here alright so just to refresh your memory for actually

533
00:26:39,140 --> 00:26:42,440
只是为了刷新您的记忆，以便进行此问题的调整
just to refresh your memory for actually on conducting for tuning this problem

534
00:26:42,440 --> 00:26:42,450
只是为了刷新您的记忆，以便进行此问题的调整
on conducting for tuning this problem are legit

535
00:26:42,450 --> 00:26:42,960
在法国是合法的，今天是什么样子
on conducting for tuning this problem are legit

536
00:26:42,960 --> 00:26:44,970
在法国是合法的，今天是什么样子
are legit in France and whatnot it's day like

537
00:26:44,970 --> 00:26:44,980
在法国是合法的，今天是什么样子
in France and whatnot it's day like someone to enum algorithms with this

538
00:26:44,980 --> 00:26:47,120
有人用这个贝叶斯算法来枚举他们尚未接受的算法
in France and whatnot it's day like someone to enum algorithms with this

539
00:26:47,120 --> 00:26:49,260
有人用这个贝叶斯算法来枚举他们尚未接受的算法
someone to enum algorithms with this Bayesian that they've yet to take kind

540
00:26:49,260 --> 00:26:49,270
有人用这个贝叶斯算法来枚举他们尚未接受的算法
Bayesian that they've yet to take kind of a variational approach which involves

541
00:26:49,270 --> 00:26:50,909
涉及使下界最大化的变分方法，我们都知道
Bayesian that they've yet to take kind of a variational approach which involves

542
00:26:50,909 --> 00:26:52,529
涉及使下界最大化的变分方法，我们都知道
of a variational approach which involves maximizing lower bound we all know that

543
00:26:52,529 --> 00:26:52,539
涉及使下界最大化的变分方法，我们都知道
maximizing lower bound we all know that and it's an alternative estimate we came

544
00:26:52,539 --> 00:26:55,169
这是另一种估计，我们来回之间是必要的
maximizing lower bound we all know that and it's an alternative estimate we came

545
00:26:55,169 --> 00:26:57,419
这是另一种估计，我们来回之间是必要的
and it's an alternative estimate we came Kong back and forth between essential

546
00:26:57,419 --> 00:26:57,429
这是另一种估计，我们来回之间是必要的
Kong back and forth between essential updating responsibilities computing the

547
00:26:57,429 --> 00:26:59,250
更新职责，计算与那些相关的统计数据
Kong back and forth between essential updating responsibilities computing the

548
00:26:59,250 --> 00:27:01,490
更新职责，计算与那些相关的统计数据
updating responsibilities computing the relevant statistics related to those

549
00:27:01,490 --> 00:27:01,500
更新职责，计算与那些相关的统计数据
relevant statistics related to those responsibilities and also updating the

550
00:27:01,500 --> 00:27:03,779
责任并更新您必须跳过的超参数空间
relevant statistics related to those responsibilities and also updating the

551
00:27:03,779 --> 00:27:05,730
责任并更新您必须跳过的超参数空间
responsibilities and also updating the hyper parameters space you have to jump

552
00:27:05,730 --> 00:27:05,740
责任并更新您必须跳过的超参数空间
hyper parameters space you have to jump back and forth between these two then

553
00:27:05,740 --> 00:27:07,260
在这两者之间来回交流，然后将实际解收敛于
hyper parameters space you have to jump back and forth between these two then

554
00:27:07,260 --> 00:27:10,169
在这两者之间来回交流，然后将实际解收敛于
back and forth between these two then converge the actual solution in

555
00:27:10,169 --> 00:27:10,179
在这两者之间来回交流，然后将实际解收敛于
converge the actual solution in particular mission we don't know now the

556
00:27:10,179 --> 00:27:12,090
我们现在不知道的特定任务这个感兴趣的问题是
converge the actual solution in particular mission we don't know now the

557
00:27:12,090 --> 00:27:14,159
我们现在不知道的特定任务这个感兴趣的问题是
particular mission we don't know now the problem with this problem of interest is

558
00:27:14,159 --> 00:27:14,169
我们现在不知道的特定任务这个感兴趣的问题是
problem with this problem of interest is basically we can't actually describe

559
00:27:14,169 --> 00:27:17,250
基本上，我们实际上不能非常有效地描述这些区域，就像
problem with this problem of interest is basically we can't actually describe

560
00:27:17,250 --> 00:27:20,549
基本上，我们实际上不能非常有效地描述这些区域，就像
basically we can't actually describe these regions very efficiently and like

561
00:27:20,549 --> 00:27:20,559
基本上，我们实际上不能非常有效地描述这些区域，就像
these regions very efficiently and like a hint said that before we chose us prom

562
00:27:20,559 --> 00:27:22,890
提示说，在我们选择舞会之前，特别是因为这些确实是
these regions very efficiently and like a hint said that before we chose us prom

563
00:27:22,890 --> 00:27:24,750
提示说，在我们选择舞会之前，特别是因为这些确实是
a hint said that before we chose us prom specifically because these are indeed

564
00:27:24,750 --> 00:27:24,760
提示说，在我们选择舞会之前，特别是因为这些确实是
specifically because these are indeed there they don't really fit college so

565
00:27:24,760 --> 00:27:27,210
他们根本不适合大学，所以即使我们能够
specifically because these are indeed there they don't really fit college so

566
00:27:27,210 --> 00:27:28,590
他们根本不适合大学，所以即使我们能够
there they don't really fit college so essentially even though we're able to

567
00:27:28,590 --> 00:27:28,600
他们根本不适合大学，所以即使我们能够
essentially even though we're able to fit the data through mixture we don't

568
00:27:28,600 --> 00:27:31,470
通过混合拟合数据，我们实际上并没有得到五个离散类
essentially even though we're able to fit the data through mixture we don't

569
00:27:31,470 --> 00:27:33,480
通过混合拟合数据，我们实际上并没有得到五个离散类
fit the data through mixture we don't really get the five discrete classes

570
00:27:33,480 --> 00:27:33,490
通过混合拟合数据，我们实际上并没有得到五个离散类
really get the five discrete classes that we actually originally wanted so

571
00:27:33,490 --> 00:27:37,919
我们原本想要的，所以让我们完整地看一看
really get the five discrete classes that we actually originally wanted so

572
00:27:37,919 --> 00:27:38,909
我们原本想要的，所以让我们完整地看一看
that we actually originally wanted so let's look at something completely

573
00:27:38,909 --> 00:27:38,919
我们原本想要的，所以让我们完整地看一看
let's look at something completely different now let's say all right so

574
00:27:38,919 --> 00:27:40,950
现在不一样了，我们说这是结构化的结果，所以现在
let's look at something completely different now let's say all right so

575
00:27:40,950 --> 00:27:43,140
现在不一样了，我们说这是结构化的结果，所以现在
different now let's say all right so this was the structured result so now

576
00:27:43,140 --> 00:27:43,150
现在不一样了，我们说这是结构化的结果，所以现在
this was the structured result so now let's go to entirely flexible is all an

577
00:27:43,150 --> 00:27:46,620
让我们去完全灵活，这里的所有想法就是现在而不是
this was the structured result so now let's go to entirely flexible is all an

578
00:27:46,620 --> 00:27:48,299
让我们去完全灵活，这里的所有想法就是现在而不是
let's go to entirely flexible is all an idea here is that now instead of

579
00:27:48,299 --> 00:27:48,309
让我们去完全灵活，这里的所有想法就是现在而不是
idea here is that now instead of essentially having you know this mixture

580
00:27:48,309 --> 00:27:49,919
从本质上讲，您知道这种混合监护人将基本上是
idea here is that now instead of essentially having you know this mixture

581
00:27:49,919 --> 00:27:51,270
从本质上讲，您知道这种混合监护人将基本上是
essentially having you know this mixture guardians were going to basically be

582
00:27:51,270 --> 00:27:51,280
从本质上讲，您知道这种混合监护人将基本上是
guardians were going to basically be using a narrow network since you predict

583
00:27:51,280 --> 00:27:55,760
使用狭窄的网络，因为您可以预测均值和过程
guardians were going to basically be using a narrow network since you predict

584
00:27:55,760 --> 00:28:01,020
使用狭窄的网络，因为您可以预测均值和过程
using a narrow network since you predict to predict a mean and also a procedure

585
00:28:01,020 --> 00:28:01,620
所以现在这是我们的可能性，您会看到我们的实际均值以及
using a narrow network since you predict to predict a mean and also a procedure

586
00:28:01,620 --> 00:28:01,630
所以现在这是我们的可能性，您会看到我们的实际均值以及


587
00:28:01,630 --> 00:28:06,570
所以现在这是我们的可能性，您会看到我们的实际均值以及
so this is now our likelihood and you see that our our actual mean and also

588
00:28:06,570 --> 00:28:06,580
所以现在这是我们的可能性，您会看到我们的实际均值以及
see that our our actual mean and also our precision is now so wait biases of

589
00:28:06,580 --> 00:28:09,210
我们的精度现在是神经网络的等待偏差，现在这实际上是
see that our our actual mean and also our precision is now so wait biases of

590
00:28:09,210 --> 00:28:11,760
我们的精度现在是神经网络的等待偏差，现在这实际上是
our precision is now so wait biases of the neural network now this is actually

591
00:28:11,760 --> 00:28:11,770
我们的精度现在是神经网络的等待偏差，现在这实际上是
the neural network now this is actually a function that's basically being

592
00:28:11,770 --> 00:28:13,080
现在基本上在这里产生的功能当然是问题
the neural network now this is actually a function that's basically being

593
00:28:13,080 --> 00:28:17,159
现在基本上在这里产生的功能当然是问题
a function that's basically being produced here now of course the issue

594
00:28:17,159 --> 00:28:17,169
现在基本上在这里产生的功能当然是问题
produced here now of course the issue with this is obvious

595
00:28:17,169 --> 00:28:18,480
很明显，我们已经失去了所有的分类
produced here now of course the issue with this is obvious

596
00:28:18,480 --> 00:28:21,029
很明显，我们已经失去了所有的分类
with this is obvious we've lost all the sort of categorizing

597
00:28:21,029 --> 00:28:21,039
很明显，我们已经失去了所有的分类
we've lost all the sort of categorizing is essentially it sure we can fit this

598
00:28:21,039 --> 00:28:23,340
从本质上讲，我们可以很好地适应这一点，从而获得非常好的密度
we've lost all the sort of categorizing is essentially it sure we can fit this

599
00:28:23,340 --> 00:28:25,770
从本质上讲，我们可以很好地适应这一点，从而获得非常好的密度
is essentially it sure we can fit this very nicely we get very nice densities

600
00:28:25,770 --> 00:28:25,780
从本质上讲，我们可以很好地适应这一点，从而获得非常好的密度
very nicely we get very nice densities where the actual data is but in the way

601
00:28:25,780 --> 00:28:28,560
实际数据在哪里，但以对不同实际数据进行分类的方式
very nicely we get very nice densities where the actual data is but in the way

602
00:28:28,560 --> 00:28:30,180
实际数据在哪里，但以对不同实际数据进行分类的方式
where the actual data is but in the way of classifying the different actual

603
00:28:30,180 --> 00:28:30,190
实际数据在哪里，但以对不同实际数据进行分类的方式
of classifying the different actual clusters Bravo

604
00:28:30,190 --> 00:28:33,289
聚集Bravo好吧，现在关于要发表的论文
of classifying the different actual clusters Bravo

605
00:28:33,289 --> 00:28:37,710
聚集Bravo好吧，现在关于要发表的论文
clusters Bravo alright so now about which papers to

606
00:28:37,710 --> 00:28:37,720
聚集Bravo好吧，现在关于要发表的论文
alright so now about which papers to this later paper back in 2012 and I'm

607
00:28:37,720 --> 00:28:43,020
这是2012年的这篇论文，我在谈论一种方法，
alright so now about which papers to this later paper back in 2012 and I'm

608
00:28:43,020 --> 00:28:45,299
这是2012年的这篇论文，我在谈论一种方法，
this later paper back in 2012 and I'm talking about a method which is kind of

609
00:28:45,299 --> 00:28:45,309
这是2012年的这篇论文，我在谈论一种方法，
talking about a method which is kind of general approach car rat the mixture

610
00:28:45,309 --> 00:28:47,520
通用方法大鼠混合模型和核心思想本质上是
talking about a method which is kind of general approach car rat the mixture

611
00:28:47,520 --> 00:28:51,630
通用方法大鼠混合模型和核心思想本质上是
general approach car rat the mixture models and the core idea is essentially

612
00:28:51,630 --> 00:28:51,640
通用方法大鼠混合模型和核心思想本质上是
models and the core idea is essentially in its name so we're going to take a

613
00:28:51,640 --> 00:28:54,390
以它的名字命名，所以我们将采用混合模型，在左侧
models and the core idea is essentially in its name so we're going to take a

614
00:28:54,390 --> 00:28:56,760
以它的名字命名，所以我们将采用混合模型，在左侧
in its name so we're going to take a mixture model so on the left and

615
00:28:56,760 --> 00:28:56,770
以它的名字命名，所以我们将采用混合模型，在左侧
mixture model so on the left and basically wrap it and some sort of

616
00:28:56,770 --> 00:28:58,500
基本上包装它和某种功能，基本上可以转换
mixture model so on the left and basically wrap it and some sort of

617
00:28:58,500 --> 00:29:01,320
基本上包装它和某种功能，基本上可以转换
basically wrap it and some sort of function that transforms basically the

618
00:29:01,320 --> 00:29:01,330
基本上包装它和某种功能，基本上可以转换
function that transforms basically the the latent variable was returned

619
00:29:01,330 --> 00:29:02,970
将针对混合模型确定的潜在变量返回到
function that transforms basically the the latent variable was returned

620
00:29:02,970 --> 00:29:05,010
将针对混合模型确定的潜在变量返回到
the latent variable was returned determined for the mixture model into a

621
00:29:05,010 --> 00:29:05,020
将针对混合模型确定的潜在变量返回到
determined for the mixture model into a non Gaussian and spacing on garden

622
00:29:05,020 --> 00:29:07,169
非高斯和间隔动物的本质，所以这个想法是
determined for the mixture model into a non Gaussian and spacing on garden

623
00:29:07,169 --> 00:29:10,320
非高斯和间隔动物的本质，所以这个想法是
non Gaussian and spacing on garden animals essentially so the idea is that

624
00:29:10,320 --> 00:29:10,330
非高斯和间隔动物的本质，所以这个想法是
animals essentially so the idea is that instead of using them as the direct

625
00:29:10,330 --> 00:29:13,049
而不是将它们用作通过某种方式映射它的直接输出
animals essentially so the idea is that instead of using them as the direct

626
00:29:13,049 --> 00:29:14,940
而不是将它们用作通过某种方式映射它的直接输出
instead of using them as the direct output along map it through some sort of

627
00:29:14,940 --> 00:29:14,950
而不是将它们用作通过某种方式映射它的直接输出
output along map it through some sort of function do they get a much more complex

628
00:29:14,950 --> 00:29:16,950
函数是否可以获得更复杂的输出，但仍将保留
output along map it through some sort of function do they get a much more complex

629
00:29:16,950 --> 00:29:20,159
函数是否可以获得更复杂的输出，但仍将保留
function do they get a much more complex output yet will also retain the

630
00:29:20,159 --> 00:29:20,169
函数是否可以获得更复杂的输出，但仍将保留
output yet will also retain the structured representation

631
00:29:20,169 --> 00:29:24,030
结构化表示
output yet will also retain the structured representation

632
00:29:24,030 --> 00:29:24,520
所以这就是我们在这里要看的东西，所以基本上所有东西都有
output yet will also retain the structured representation

633
00:29:24,520 --> 00:29:24,530
所以这就是我们在这里要看的东西，所以基本上所有东西都有


634
00:29:24,530 --> 00:29:29,530
所以这就是我们在这里要看的东西，所以基本上所有东西都有
so here's what we're looking at on here so basically everything most of it has

635
00:29:29,530 --> 00:29:29,540
所以这就是我们在这里要看的东西，所以基本上所有东西都有
so basically everything most of it has remained the same I'll talk about this

636
00:29:29,540 --> 00:29:31,930
保持不变，我将继续讨论并分解更多细节，但前提是
so basically everything most of it has remained the same I'll talk about this

637
00:29:31,930 --> 00:29:34,120
保持不变，我将继续讨论并分解更多细节，但前提是
remained the same I'll talk about this and break down more detail but only if

638
00:29:34,120 --> 00:29:34,130
保持不变，我将继续讨论并分解更多细节，但前提是
and break down more detail but only if now at this arbitrary function over here

639
00:29:34,130 --> 00:29:36,460
现在在这里的任意功能上，为此，我们将要
and break down more detail but only if now at this arbitrary function over here

640
00:29:36,460 --> 00:29:39,640
现在在这里的任意功能上，为此，我们将要
now at this arbitrary function over here and for this and the paper we're gonna

641
00:29:39,640 --> 00:29:39,650
现在在这里的任意功能上，为此，我们将要
and for this and the paper we're gonna be following it it's gonna be a Gaussian

642
00:29:39,650 --> 00:29:41,500
跟随它，这将是一个高斯过程，所以里根在左边
and for this and the paper we're gonna be following it it's gonna be a Gaussian

643
00:29:41,500 --> 00:29:45,160
跟随它，这将是一个高斯过程，所以里根在左边
be following it it's gonna be a Gaussian process so Reagan is down on the left

644
00:29:45,160 --> 00:29:45,170
跟随它，这将是一个高斯过程，所以里根在左边
process so Reagan is down on the left this is actually precisely the Bayesian

645
00:29:45,170 --> 00:29:47,230
这实际上正是我们拥有的高斯混合模型上的贝叶斯模型
process so Reagan is down on the left this is actually precisely the Bayesian

646
00:29:47,230 --> 00:29:49,870
这实际上正是我们拥有的高斯混合模型上的贝叶斯模型
this is actually precisely the Bayesian on Gaussian mixture model that we had

647
00:29:49,870 --> 00:29:49,880
这实际上正是我们拥有的高斯混合模型上的贝叶斯模型
on Gaussian mixture model that we had before

648
00:29:49,880 --> 00:29:50,530
之前，实际上除了钥匙
on Gaussian mixture model that we had before

649
00:29:50,530 --> 00:29:53,800
之前，实际上除了钥匙
before exactly actually except the key

650
00:29:53,800 --> 00:29:53,810
之前，实际上除了钥匙
exactly actually except the key difference is that now the outputs are

651
00:29:53,810 --> 00:29:55,570
区别在于，现在的输出不是实际的观测值，不是
exactly actually except the key difference is that now the outputs are

652
00:29:55,570 --> 00:29:57,130
区别在于，现在的输出不是实际的观测值，不是
difference is that now the outputs are not the actual observations they're not

653
00:29:57,130 --> 00:29:57,140
区别在于，现在的输出不是实际的观测值，不是
not the actual observations they're not a set of latent variables so these don't

654
00:29:57,140 --> 00:29:59,020
一组潜在变量，因此它们实际上并没有真正的含义
not the actual observations they're not a set of latent variables so these don't

655
00:29:59,020 --> 00:30:01,480
一组潜在变量，因此它们实际上并没有真正的含义
a set of latent variables so these don't actually have really true meaning

656
00:30:01,480 --> 00:30:01,490
一组潜在变量，因此它们实际上并没有真正的含义
actually have really true meaning they're not what we're seeing isn't it's

657
00:30:01,490 --> 00:30:02,890
他们不是我们所看到的，不是我们也想要的实际数据
actually have really true meaning they're not what we're seeing isn't it's

658
00:30:02,890 --> 00:30:05,410
他们不是我们所看到的，不是我们也想要的实际数据
they're not what we're seeing isn't it's not what our actual data I also want to

659
00:30:05,410 --> 00:30:05,420
他们不是我们所看到的，不是我们也想要的实际数据
not what our actual data I also want to note here that I personally I predefined

660
00:30:05,420 --> 00:30:08,050
请注意，我个人预定义了一组混合成分k
not what our actual data I also want to note here that I personally I predefined

661
00:30:08,050 --> 00:30:12,010
请注意，我个人预定义了一组混合成分k
note here that I personally I predefined a set of mixture components k however

662
00:30:12,010 --> 00:30:12,020
请注意，我个人预定义了一组混合成分k
a set of mixture components k however you can indeed have a infinite set which

663
00:30:12,020 --> 00:30:14,710
您确实可以有一个无限的集合，这就是他们在论文中通过
a set of mixture components k however you can indeed have a infinite set which

664
00:30:14,710 --> 00:30:16,690
您确实可以有一个无限的集合，这就是他们在论文中通过
you can indeed have a infinite set which is what they do in the paper through a

665
00:30:16,690 --> 00:30:16,700
您确实可以有一个无限的集合，这就是他们在论文中通过
is what they do in the paper through a Derrick wave process and give sampling

666
00:30:16,700 --> 00:30:18,670
井架波过程并提供采样
is what they do in the paper through a Derrick wave process and give sampling

667
00:30:18,670 --> 00:30:21,070
井架波过程并提供采样
Derrick wave process and give sampling of that

668
00:30:21,070 --> 00:30:23,169
现在在右边基本上这将是我们的高斯过程
Derrick wave process and give sampling of that

669
00:30:23,169 --> 00:30:23,179
现在在右边基本上这将是我们的高斯过程


670
00:30:23,179 --> 00:30:29,200
现在在右边基本上这将是我们的高斯过程
now on the right side basically this is now going to be our Gaussian process

671
00:30:29,200 --> 00:30:29,210
现在在右边基本上这将是我们的高斯过程
now going to be our Gaussian process here so basically it's going to be

672
00:30:29,210 --> 00:30:31,029
在这里，基本上将这些潜在变量映射到一个
now going to be our Gaussian process here so basically it's going to be

673
00:30:31,029 --> 00:30:33,249
在这里，基本上将这些潜在变量映射到一个
here so basically it's going to be mapping these latent variables here to a

674
00:30:33,249 --> 00:30:33,259
在这里，基本上将这些潜在变量映射到一个
mapping these latent variables here to a non ecology manifold is the idea and I

675
00:30:33,259 --> 00:30:38,109
非生态流形是这个主意，我留在这里，这是一个高斯
mapping these latent variables here to a non ecology manifold is the idea and I

676
00:30:38,109 --> 00:30:40,209
非生态流形是这个主意，我留在这里，这是一个高斯
non ecology manifold is the idea and I stay here that this is a Gaussian

677
00:30:40,209 --> 00:30:40,219
非生态流形是这个主意，我留在这里，这是一个高斯
stay here that this is a Gaussian process however on this is not actually

678
00:30:40,219 --> 00:30:43,749
流程，但实际上并不包含在内，因此您可以将此想法扩展到
stay here that this is a Gaussian process however on this is not actually

679
00:30:43,749 --> 00:30:46,659
流程，但实际上并不包含在内，因此您可以将此想法扩展到
process however on this is not actually inclusive so you can extend this idea to

680
00:30:46,659 --> 00:30:46,669
流程，但实际上并不包含在内，因此您可以将此想法扩展到
inclusive so you can extend this idea to others or a methods however you want

681
00:30:46,669 --> 00:30:48,729
其他或方法，但是您实际上想要一个想要的地图
inclusive so you can extend this idea to others or a methods however you want

682
00:30:48,729 --> 00:30:49,869
其他或方法，但是您实际上想要一个想要的地图
others or a methods however you want actually one of the map how you wanted

683
00:30:49,869 --> 00:30:49,879
其他或方法，但是您实际上想要一个想要的地图
actually one of the map how you wanted to find this function um it's just what

684
00:30:49,879 --> 00:30:52,629
找到这个功能，这就是我们启动的功能，我们正在做这个特殊的
actually one of the map how you wanted to find this function um it's just what

685
00:30:52,629 --> 00:30:53,769
找到这个功能，这就是我们启动的功能，我们正在做这个特殊的
to find this function um it's just what we launched we're doing this particular

686
00:30:53,769 --> 00:30:53,779
找到这个功能，这就是我们启动的功能，我们正在做这个特殊的
we launched we're doing this particular paper um I do know here that they're

687
00:30:53,779 --> 00:30:57,190
嗯，我在这里确实知道他们基本上是这样，所以我们在这里
we launched we're doing this particular paper um I do know here that they're

688
00:30:57,190 --> 00:30:59,680
嗯，我在这里确实知道他们基本上是这样，所以我们在这里
paper um I do know here that they're basically so this right here we have

689
00:30:59,680 --> 00:30:59,690
嗯，我在这里确实知道他们基本上是这样，所以我们在这里
basically so this right here we have inputs our latent variables on that the

690
00:30:59,690 --> 00:31:02,200
输入我们的潜在变量，以毫米为单位，这恰好是
basically so this right here we have inputs our latent variables on that the

691
00:31:02,200 --> 00:31:06,159
输入我们的潜在变量，以毫米为单位，这恰好是
inputs our latent variables on that the in mm process and this is precisely a

692
00:31:06,159 --> 00:31:06,169
输入我们的潜在变量，以毫米为单位，这恰好是
in mm process and this is precisely a Gaussian process lake imperative model

693
00:31:06,169 --> 00:31:08,709
如果我们忽略此封闭部分，则实际上是高斯过程湖势在必行模型
in mm process and this is precisely a Gaussian process lake imperative model

694
00:31:08,709 --> 00:31:11,709
如果我们忽略此封闭部分，则实际上是高斯过程湖势在必行模型
Gaussian process lake imperative model in fact if we ignore this closed section

695
00:31:11,709 --> 00:31:11,719
如果我们忽略此封闭部分，则实际上是高斯过程湖势在必行模型
in fact if we ignore this closed section out here and we just take these guys as

696
00:31:11,719 --> 00:31:14,529
在这里，我们只是把这些家伙当成基本固定的，这实在是一个艰巨的任务
in fact if we ignore this closed section out here and we just take these guys as

697
00:31:14,529 --> 00:31:18,330
在这里，我们只是把这些家伙当成基本固定的，这实在是一个艰巨的任务
out here and we just take these guys as basically fixed it's precisely a gauntly

698
00:31:18,330 --> 00:31:18,340
在这里，我们只是把这些家伙当成基本固定的，这实在是一个艰巨的任务
basically fixed it's precisely a gauntly so in essence you can view this as a

699
00:31:18,340 --> 00:31:21,729
因此，从本质上讲，您可以将其视为GPL的通用版本，因此，如果
basically fixed it's precisely a gauntly so in essence you can view this as a

700
00:31:21,729 --> 00:31:26,769
因此，从本质上讲，您可以将其视为GPL的通用版本，因此，如果
so in essence you can view this as a more generalized version of GPL so if

701
00:31:26,769 --> 00:31:26,779
因此，从本质上讲，您可以将其视为GPL的通用版本，因此，如果
more generalized version of GPL so if you like me and you're not too well

702
00:31:26,779 --> 00:31:28,779
你喜欢我，首先在薄纱和潜伏变量方面不太好
more generalized version of GPL so if you like me and you're not too well

703
00:31:28,779 --> 00:31:30,940
你喜欢我，首先在薄纱和潜伏变量方面不太好
you like me and you're not too well first on gauzy and upon latent variable

704
00:31:30,940 --> 00:31:30,950
你喜欢我，首先在薄纱和潜伏变量方面不太好
first on gauzy and upon latent variable models we're gonna go over it so the

705
00:31:30,950 --> 00:31:33,129
我们将要讨论的模型，所以这个想法的关键原则是
first on gauzy and upon latent variable models we're gonna go over it so the

706
00:31:33,129 --> 00:31:35,139
我们将要讨论的模型，所以这个想法的关键原则是
models we're gonna go over it so the idea the the key principle is that

707
00:31:35,139 --> 00:31:35,149
我们将要讨论的模型，所以这个想法的关键原则是
idea the the key principle is that instead of having circle represent your

708
00:31:35,149 --> 00:31:38,619
而不是让圆圈通过德国高斯表示您的可能性，并且
idea the the key principle is that instead of having circle represent your

709
00:31:38,619 --> 00:31:41,039
而不是让圆圈通过德国高斯表示您的可能性，并且
instead of having circle represent your likelihood through a German Gaussian and

710
00:31:41,039 --> 00:31:41,049
而不是让圆圈通过德国高斯表示您的可能性，并且
likelihood through a German Gaussian and your actual covariance matrix is going

711
00:31:41,049 --> 00:31:44,379
您实际的协方差矩阵将通过内核函数定义
likelihood through a German Gaussian and your actual covariance matrix is going

712
00:31:44,379 --> 00:31:46,690
您实际的协方差矩阵将通过内核函数定义
your actual covariance matrix is going to be defined through a kernel function

713
00:31:46,690 --> 00:31:46,700
您实际的协方差矩阵将通过内核函数定义
to be defined through a kernel function down here now the key thing that makes

714
00:31:46,700 --> 00:31:49,239
现在在这里，使创新成为典范的关键是
to be defined through a kernel function down here now the key thing that makes

715
00:31:49,239 --> 00:31:51,279
现在在这里，使创新成为典范的关键是
down here now the key thing that makes this innovation very models is that this

716
00:31:51,279 --> 00:31:51,289
现在在这里，使创新成为典范的关键是
this innovation very models is that this kernel function is governed through

717
00:31:51,289 --> 00:31:52,659
内核函数是通过潜在变量控制的，因此这些变量是
this innovation very models is that this kernel function is governed through

718
00:31:52,659 --> 00:31:54,820
内核函数是通过潜在变量控制的，因此这些变量是
kernel function is governed through latent variables so these variables are

719
00:31:54,820 --> 00:31:54,830
内核函数是通过潜在变量控制的，因此这些变量是
latent variables so these variables are related to your actually do get related

720
00:31:54,830 --> 00:31:57,489
与您的实际关系确实相关，但是存在主要变量
latent variables so these variables are related to your actually do get related

721
00:31:57,489 --> 00:31:59,999
与您的实际关系确实相关，但是存在主要变量
related to your actually do get related but there's been leading variables

722
00:31:59,999 --> 00:32:00,009
与您的实际关系确实相关，但是存在主要变量
but there's been leading variables basically it now of course we need to

723
00:32:00,009 --> 00:32:05,289
基本上现在，我们当然需要优化这些潜在变量，所以我们
but there's been leading variables basically it now of course we need to

724
00:32:05,289 --> 00:32:07,060
基本上现在，我们当然需要优化这些潜在变量，所以我们
basically it now of course we need to optimize these latent variables so we

725
00:32:07,060 --> 00:32:07,070
基本上现在，我们当然需要优化这些潜在变量，所以我们
optimize these latent variables so we needed to tune this model so you can get

726
00:32:07,070 --> 00:32:08,710
需要调整此模型，以便您基本上可以完成此操作，从而获得所需的结果
optimize these latent variables so we needed to tune this model so you can get

727
00:32:08,710 --> 00:32:11,019
需要调整此模型，以便您基本上可以完成此操作，从而获得所需的结果
needed to tune this model so you can get desired result on that is done basically

728
00:32:11,019 --> 00:32:11,029
需要调整此模型，以便您基本上可以完成此操作，从而获得所需的结果
desired result on that is done basically if ingredient based operations

729
00:32:11,029 --> 00:32:12,430
如果基于成分的操作优化是的，那么我很快
desired result on that is done basically if ingredient based operations

730
00:32:12,430 --> 00:32:16,690
如果基于成分的操作优化是的，那么我很快
if ingredient based operations optimization and yeah so I just quickly

731
00:32:16,690 --> 00:32:16,700
如果基于成分的操作优化是的，那么我很快
optimization and yeah so I just quickly list some gradients here you can see

732
00:32:16,700 --> 00:32:18,789
在这里列出一些渐变，您可以看到基本上我们需要一个成本函数
optimization and yeah so I just quickly list some gradients here you can see

733
00:32:18,789 --> 00:32:21,340
在这里列出一些渐变，您可以看到基本上我们需要一个成本函数
list some gradients here you can see that basically we want a cost function

734
00:32:21,340 --> 00:32:21,350
在这里列出一些渐变，您可以看到基本上我们需要一个成本函数
that basically we want a cost function or you know what I like over here like a

735
00:32:21,350 --> 00:32:22,930
或者你知道我喜欢这里的东西，就像观察笔记
that basically we want a cost function or you know what I like over here like a

736
00:32:22,930 --> 00:32:24,220
或者你知道我喜欢这里的东西，就像观察笔记
or you know what I like over here like a note of observation is getting laid

737
00:32:24,220 --> 00:32:24,230
或者你知道我喜欢这里的东西，就像观察笔记
note of observation is getting laid variables and also the data is gonna

738
00:32:24,230 --> 00:32:26,080
变量以及数据将代表我们的参数以及GPM和
note of observation is getting laid variables and also the data is gonna

739
00:32:26,080 --> 00:32:29,940
变量以及数据将代表我们的参数以及GPM和
variables and also the data is gonna represent our parameters and the GPM and

740
00:32:29,940 --> 00:32:29,950
变量以及数据将代表我们的参数以及GPM和
represent our parameters and the GPM and essentially this using chain rule you

741
00:32:29,950 --> 00:32:32,259
基本上，这是使用链式规则，您可以看到，基本上，
represent our parameters and the GPM and essentially this using chain rule you

742
00:32:32,259 --> 00:32:34,029
基本上，这是使用链式规则，您可以看到，基本上，
essentially this using chain rule you can see that basically this combined

743
00:32:34,029 --> 00:32:34,039
基本上，这是使用链式规则，您可以看到，基本上，
can see that basically this combined with this will give you the derivative

744
00:32:34,039 --> 00:32:36,220
这样做会给您成本函数的导数，因此您的
can see that basically this combined with this will give you the derivative

745
00:32:36,220 --> 00:32:39,700
这样做会给您成本函数的导数，因此您的
with this will give you the derivative of the of your cost function so your

746
00:32:39,700 --> 00:32:39,710
这样做会给您成本函数的导数，因此您的
of the of your cost function so your wall of your likelihood with respect to

747
00:32:39,710 --> 00:32:42,279
关于您的实际潜在变量的可能性墙被消耗了
of the of your cost function so your wall of your likelihood with respect to

748
00:32:42,279 --> 00:32:46,989
关于您的实际潜在变量的可能性墙被消耗了
wall of your likelihood with respect to your actual latent variable be consumed

749
00:32:46,989 --> 00:32:48,520
好了，现在进入实际文件，以便我们将其分解
wall of your likelihood with respect to your actual latent variable be consumed

750
00:32:48,520 --> 00:32:48,530
好了，现在进入实际文件，以便我们将其分解


751
00:32:48,530 --> 00:32:52,760
好了，现在进入实际文件，以便我们将其分解
alright so now moving into the actual paper now so we're gonna break this down

752
00:32:52,760 --> 00:32:52,770
好了，现在进入实际文件，以便我们将其分解
paper now so we're gonna break this down and look into three parts of this actual

753
00:32:52,770 --> 00:32:54,920
并研究一下我想谈论的说唱混合模型的这一实际部分
paper now so we're gonna break this down and look into three parts of this actual

754
00:32:54,920 --> 00:32:57,230
并研究一下我想谈论的说唱混合模型的这一实际部分
and look into three parts of this actual of this rap mixture model I want to talk

755
00:32:57,230 --> 00:32:57,240
并研究一下我想谈论的说唱混合模型的这一实际部分
of this rap mixture model I want to talk about a generation this is a generative

756
00:32:57,240 --> 00:32:59,000
关于一代，这是一个生成模型，我不谈论训练
of this rap mixture model I want to talk about a generation this is a generative

757
00:32:59,000 --> 00:33:01,220
关于一代，这是一个生成模型，我不谈论训练
about a generation this is a generative model I don't talk about the training of

758
00:33:01,220 --> 00:33:01,230
关于一代，这是一个生成模型，我不谈论训练
model I don't talk about the training of it they don't talk about on briefly

759
00:33:01,230 --> 00:33:03,230
他们没有在简短的预测中谈论它，所以它是热能ppl
model I don't talk about the training of it they don't talk about on briefly

760
00:33:03,230 --> 00:33:06,320
他们没有在简短的预测中谈论它，所以它是热能ppl
it they don't talk about on briefly prediction so it's thermal energy ppl

761
00:33:06,320 --> 00:33:06,330
他们没有在简短的预测中谈论它，所以它是热能ppl
prediction so it's thermal energy ppl Fiona song

762
00:33:06,330 --> 00:33:07,310
菲奥娜（Fiona）歌曲本质上这是一个生成模型
prediction so it's thermal energy ppl Fiona song

763
00:33:07,310 --> 00:33:09,140
菲奥娜（Fiona）歌曲本质上这是一个生成模型
Fiona song essentially this is a generative model

764
00:33:09,140 --> 00:33:09,150
菲奥娜（Fiona）歌曲本质上这是一个生成模型
essentially this is a generative model so we can generate realizations from

765
00:33:09,150 --> 00:33:11,900
因此我们可以从此PGM基本生成器生成实现，而不是
essentially this is a generative model so we can generate realizations from

766
00:33:11,900 --> 00:33:16,010
因此我们可以从此PGM基本生成器生成实现，而不是
so we can generate realizations from this PGM basic generator instead of

767
00:33:16,010 --> 00:33:16,020
因此我们可以从此PGM基本生成器生成实现，而不是
this PGM basic generator instead of latent variables and feed it through our

768
00:33:16,020 --> 00:33:17,570
潜在变量，并通过我们的高斯过程将其馈送到非高斯
this PGM basic generator instead of latent variables and feed it through our

769
00:33:17,570 --> 00:33:20,020
潜在变量，并通过我们的高斯过程将其馈送到非高斯
latent variables and feed it through our Gaussian process on to non Gaussian

770
00:33:20,020 --> 00:33:20,030
潜在变量，并通过我们的高斯过程将其馈送到非高斯
Gaussian process on to non Gaussian manifolds idea so the idea is I surmise

771
00:33:20,030 --> 00:33:25,490
流形的想法，所以我想这是三个步骤，尽管每个步骤
Gaussian process on to non Gaussian manifolds idea so the idea is I surmise

772
00:33:25,490 --> 00:33:26,990
流形的想法，所以我想这是三个步骤，尽管每个步骤
manifolds idea so the idea is I surmise it's in three steps though for each

773
00:33:26,990 --> 00:33:27,000
流形的想法，所以我想这是三个步骤，尽管每个步骤
it's in three steps though for each component for volume to I remember going

774
00:33:27,000 --> 00:33:30,200
我记得在这里回到我们的PGM，所以第一步
it's in three steps though for each component for volume to I remember going

775
00:33:30,200 --> 00:33:34,100
我记得在这里回到我们的PGM，所以第一步
component for volume to I remember going back to our PGM here so the first step

776
00:33:34,100 --> 00:33:34,110
我记得在这里回到我们的PGM，所以第一步
back to our PGM here so the first step is that we want to draw precision and it

777
00:33:34,110 --> 00:33:36,290
是我们要绘制精度，这也意味着从
back to our PGM here so the first step is that we want to draw precision and it

778
00:33:36,290 --> 00:33:38,480
是我们要绘制精度，这也意味着从
is that we want to draw precision and it also mean for each component right from

779
00:33:38,480 --> 00:33:38,490
是我们要绘制精度，这也意味着从
also mean for each component right from our priors who's here

780
00:33:38,490 --> 00:33:41,420
我们的先驱们总是在这里，尽管我们总是在定义
also mean for each component right from our priors who's here

781
00:33:41,420 --> 00:33:43,400
我们的先驱们总是在这里，尽管我们总是在定义
our priors who's here somewhere as we always define though

782
00:33:43,400 --> 00:33:43,410
我们的先驱们总是在这里，尽管我们总是在定义
somewhere as we always define though there's a Wishart distribution and the

783
00:33:43,410 --> 00:33:45,170
这里有一个Wishart分布以及这里的社会病理学和分布
somewhere as we always define though there's a Wishart distribution and the

784
00:33:45,170 --> 00:33:47,590
这里有一个Wishart分布以及这里的社会病理学和分布
there's a Wishart distribution and the social pathology and distribution here

785
00:33:47,590 --> 00:33:47,600
这里有一个Wishart分布以及这里的社会病理学和分布
social pathology and distribution here we can then draw a function so this is

786
00:33:47,600 --> 00:33:51,260
然后我们可以绘制一个函数，所以这基本上是如果您先于
social pathology and distribution here we can then draw a function so this is

787
00:33:51,260 --> 00:33:53,390
然后我们可以绘制一个函数，所以这基本上是如果您先于
we can then draw a function so this is basically if you have priors over your

788
00:33:53,390 --> 00:33:53,400
然后我们可以绘制一个函数，所以这基本上是如果您先于
basically if you have priors over your actual parameters and you're calling

789
00:33:53,400 --> 00:33:55,670
实际的参数，你打电话给我，我应该画那些
basically if you have priors over your actual parameters and you're calling

790
00:33:55,670 --> 00:33:58,250
实际的参数，你打电话给我，我应该画那些
actual parameters and you're calling processed me I should draw those

791
00:33:58,250 --> 00:33:58,260
实际的参数，你打电话给我，我应该画那些
processed me I should draw those parameters for your GP and that foreign

792
00:33:58,260 --> 00:34:00,980
您的GP和那位外籍女士的参数很长
processed me I should draw those parameters for your GP and that foreign

793
00:34:00,980 --> 00:34:02,600
您的GP和那位外籍女士的参数很长
parameters for your GP and that foreign lady here function that's a long map

794
00:34:02,600 --> 00:34:02,610
您的GP和那位外籍女士的参数很长
lady here function that's a long map user space and for for each desired

795
00:34:02,610 --> 00:34:08,450
用户空间，然后针对每个所需的观察，您就可以
lady here function that's a long map user space and for for each desired

796
00:34:08,450 --> 00:34:11,090
用户空间，然后针对每个所需的观察，您就可以
user space and for for each desired observation that you want you can then

797
00:34:11,090 --> 00:34:11,100
用户空间，然后针对每个所需的观察，您就可以
observation that you want you can then draw a assignment so you just choose

798
00:34:11,100 --> 00:34:14,510
绘制作业，所以您只需选择想要的班级，然后从该绘制中
observation that you want you can then draw a assignment so you just choose

799
00:34:14,510 --> 00:34:16,490
绘制作业，所以您只需选择想要的班级，然后从该绘制中
draw a assignment so you just choose which class you want and from that draw

800
00:34:16,490 --> 00:34:16,500
绘制作业，所以您只需选择想要的班级，然后从该绘制中
which class you want and from that draw a set of latent variables from your T

801
00:34:16,500 --> 00:34:18,770
一组来自您的T GM的潜在变量，这是由它们的原因引起的，而您
which class you want and from that draw a set of latent variables from your T

802
00:34:18,770 --> 00:34:21,500
一组来自您的T GM的潜在变量，这是由它们的原因引起的，而您
a set of latent variables from your T GM's this is from their cause in and you

803
00:34:21,500 --> 00:34:21,510
一组来自您的T GM的潜在变量，这是由它们的原因引起的，而您
GM's this is from their cause in and you seek those X's through your dogs and

804
00:34:21,510 --> 00:34:23,600
通过狗和可能的发电机寻找那些X
GM's this is from their cause in and you seek those X's through your dogs and

805
00:34:23,600 --> 00:34:26,399
通过狗和可能的发电机寻找那些X
seek those X's through your dogs and possible generator why

806
00:34:26,399 --> 00:34:26,409
通过狗和可能的发电机寻找那些X
possible generator why now that's nice but we still have to

807
00:34:26,409 --> 00:34:29,740
现在很好，但是我们仍然要担心我们如何实际得到这个
possible generator why now that's nice but we still have to

808
00:34:29,740 --> 00:34:31,270
现在很好，但是我们仍然要担心我们如何实际得到这个
now that's nice but we still have to worry about how do we actually get this

809
00:34:31,270 --> 00:34:31,280
现在很好，但是我们仍然要担心我们如何实际得到这个
worry about how do we actually get this model to mark how do we trade it so we

810
00:34:31,280 --> 00:34:35,409
模型来标记我们如何进行交易，因此我们拥有两个系统，它们比
worry about how do we actually get this model to mark how do we trade it so we

811
00:34:35,409 --> 00:34:37,540
模型来标记我们如何进行交易，因此我们拥有两个系统，它们比
model to mark how do we trade it so we have two systems on or over further than

812
00:34:37,540 --> 00:34:37,550
模型来标记我们如何进行交易，因此我们拥有两个系统，它们比
have two systems on or over further than two systems in this you have the PGM and

813
00:34:37,550 --> 00:34:39,399
在这两个系统中，您拥有PGM和GP，我们将成为
have two systems on or over further than two systems in this you have the PGM and

814
00:34:39,399 --> 00:34:41,860
在这两个系统中，您拥有PGM和GP，我们将成为
two systems in this you have the PGM and also the GP and we're going to be

815
00:34:41,860 --> 00:34:41,870
在这两个系统中，您拥有PGM和GP，我们将成为
also the GP and we're going to be optimizing those simultaneously and

816
00:34:41,870 --> 00:34:44,830
同时优化这些，基本上要最大化
also the GP and we're going to be optimizing those simultaneously and

817
00:34:44,830 --> 00:34:47,680
同时优化这些，基本上要最大化
optimizing those simultaneously and basically what you want to maximize are

818
00:34:47,680 --> 00:34:47,690
同时优化这些，基本上要最大化
basically what you want to maximize are displayed here like there's a billion

819
00:34:47,690 --> 00:34:49,240
在这里显示，就像有十亿个变量，所以这是不同的
basically what you want to maximize are displayed here like there's a billion

820
00:34:49,240 --> 00:34:51,659
在这里显示，就像有十亿个变量，所以这是不同的
displayed here like there's a billion variables so this is different

821
00:34:51,659 --> 00:34:51,669
在这里显示，就像有十亿个变量，所以这是不同的
variables so this is different originally than our GP procedure but

822
00:34:51,669 --> 00:34:54,430
最初比我们的GP程序要好，但是如果我们扩展它，我们会看到
variables so this is different originally than our GP procedure but

823
00:34:54,430 --> 00:34:56,260
最初比我们的GP程序要好，但是如果我们扩展它，我们会看到
originally than our GP procedure but however if we expand it out we see that

824
00:34:56,260 --> 00:34:56,270
最初比我们的GP程序要好，但是如果我们扩展它，我们会看到
however if we expand it out we see that actually his and this is a kind of core

825
00:34:56,270 --> 00:34:59,530
实际上是他的，这是一种核心思想，从本质上讲，我们拥有
however if we expand it out we see that actually his and this is a kind of core

826
00:34:59,530 --> 00:35:02,740
实际上是他的，这是一种核心思想，从本质上讲，我们拥有
actually his and this is a kind of core idea here is that essentially we have we

827
00:35:02,740 --> 00:35:02,750
实际上是他的，这是一种核心思想，从本质上讲，我们拥有
idea here is that essentially we have we break it apart yes you have a loop

828
00:35:02,750 --> 00:35:05,170
分解它是的，您有一个来自我们高斯的电循环
idea here is that essentially we have we break it apart yes you have a loop

829
00:35:05,170 --> 00:35:07,030
分解它是的，您有一个来自我们高斯的电循环
break it apart yes you have a loop electrically that was from our Gaussian

830
00:35:07,030 --> 00:35:07,040
分解它是的，您有一个来自我们高斯的电循环
electrically that was from our Gaussian process but then we have essentially

831
00:35:07,040 --> 00:35:09,340
流程，但从本质上讲，您可以将其视为先验的
electrically that was from our Gaussian process but then we have essentially

832
00:35:09,340 --> 00:35:11,620
流程，但从本质上讲，您可以将其视为先验的
process but then we have essentially this you can consider it like a prior is

833
00:35:11,620 --> 00:35:11,630
流程，但从本质上讲，您可以将其视为先验的
this you can consider it like a prior is basically it so we have this complex

834
00:35:11,630 --> 00:35:13,150
基本上是这样，所以我们有一个复杂的先验被标记到我们的
this you can consider it like a prior is basically it so we have this complex

835
00:35:13,150 --> 00:35:16,020
基本上是这样，所以我们有一个复杂的先验被标记到我们的
basically it so we have this complex prior that's getting tagged on to our

836
00:35:16,020 --> 00:35:16,030
基本上是这样，所以我们有一个复杂的先验被标记到我们的
prior that's getting tagged on to our loss function which is then going to

837
00:35:16,030 --> 00:35:18,910
损失函数，然后将要改善其性能，这是
prior that's getting tagged on to our loss function which is then going to

838
00:35:18,910 --> 00:35:21,070
损失函数，然后将要改善其性能，这是
loss function which is then going to improve its performance and this is

839
00:35:21,070 --> 00:35:21,080
损失函数，然后将要改善其性能，这是
improve its performance and this is basically this idea right here is the

840
00:35:21,080 --> 00:35:24,100
基本上，这里的想法与实际使用的想法相同
improve its performance and this is basically this idea right here is the

841
00:35:24,100 --> 00:35:26,110
基本上，这里的想法与实际使用的想法相同
basically this idea right here is the same concept that is used actually also

842
00:35:26,110 --> 00:35:26,120
基本上，这里的想法与实际使用的想法相同
same concept that is used actually also in the 2000 sticking paper that I was

843
00:35:26,120 --> 00:35:28,390
在我本应该真正专注于2000年的粘纸上，但这是
same concept that is used actually also in the 2000 sticking paper that I was

844
00:35:28,390 --> 00:35:31,300
在我本应该真正专注于2000年的粘纸上，但这是
in the 2000 sticking paper that I was supposed to really focus on but it's the

845
00:35:31,300 --> 00:35:31,310
在我本应该真正专注于2000年的粘纸上，但这是
supposed to really focus on but it's the same with the same idea essentially

846
00:35:31,310 --> 00:35:32,980
相同的想法本质上是他们致力于更复杂的
supposed to really focus on but it's the same with the same idea essentially

847
00:35:32,980 --> 00:35:36,450
相同的想法本质上是他们致力于更复杂的
same with the same idea essentially they're tacking on a more complex more

848
00:35:36,450 --> 00:35:36,460
相同的想法本质上是他们致力于更复杂的
they're tacking on a more complex more descriptive prior on to their loss

849
00:35:36,460 --> 00:35:40,810
在描述其损失函数之前
they're tacking on a more complex more descriptive prior on to their loss

850
00:35:40,810 --> 00:35:41,680
在描述其损失函数之前
descriptive prior on to their loss function

851
00:35:41,680 --> 00:35:41,690
在描述其损失函数之前
function which basically allows them to do a lot

852
00:35:41,690 --> 00:35:43,930
基本上可以让他们做很多事
function which basically allows them to do a lot

853
00:35:43,930 --> 00:35:46,809
基本上可以让他们做很多事
which basically allows them to do a lot who were stuff

854
00:35:46,809 --> 00:35:47,840
是的，因此可以在此基础上进行改进
which basically allows them to do a lot who were stuff

855
00:35:47,840 --> 00:35:47,850
是的，因此可以在此基础上进行改进


856
00:35:47,850 --> 00:35:53,680
是的，因此可以在此基础上进行改进
yes so to kind of evolve this on in this

857
00:35:53,680 --> 00:35:53,690
是的，因此可以在此基础上进行改进
so to kind of evolve this on in this paper they use a hybrid Monte Carlo or

858
00:35:53,690 --> 00:35:56,319
论文他们使用混合蒙特卡洛或哈密尔顿蒙特卡洛辩论
so to kind of evolve this on in this paper they use a hybrid Monte Carlo or

859
00:35:56,319 --> 00:35:58,779
论文他们使用混合蒙特卡洛或哈密尔顿蒙特卡洛辩论
paper they use a hybrid Monte Carlo or Hamiltonian Monte Carlo debate please

860
00:35:58,779 --> 00:35:58,789
论文他们使用混合蒙特卡洛或哈密尔顿蒙特卡洛辩论
Hamiltonian Monte Carlo debate please sample I say kind of move because I need

861
00:35:58,789 --> 00:36:03,190
样本我之所以说这样一种举动，是因为我需要来自背景方面
Hamiltonian Monte Carlo debate please sample I say kind of move because I need

862
00:36:03,190 --> 00:36:07,480
样本我之所以说这样一种举动，是因为我需要来自背景方面
sample I say kind of move because I need coming from a background in terms of

863
00:36:07,480 --> 00:36:07,490
样本我之所以说这样一种举动，是因为我需要来自背景方面
coming from a background in terms of research I think gradient but it's

864
00:36:07,490 --> 00:36:09,670
研究，我认为是梯度，但它是采样，所以一个采样一组
coming from a background in terms of research I think gradient but it's

865
00:36:09,670 --> 00:36:11,500
研究，我认为是梯度，但它是采样，所以一个采样一组
research I think gradient but it's sampling so one sample a set of

866
00:36:11,500 --> 00:36:11,510
研究，我认为是梯度，但它是采样，所以一个采样一组
sampling so one sample a set of particles from basically this posterior

867
00:36:11,510 --> 00:36:15,339
基本上来自这个后部的粒子，所以这个想法本质上是
sampling so one sample a set of particles from basically this posterior

868
00:36:15,339 --> 00:36:18,339
基本上来自这个后部的粒子，所以这个想法本质上是
particles from basically this posterior here so the idea there is essentially

869
00:36:18,339 --> 00:36:18,349
基本上来自这个后部的粒子，所以这个想法本质上是
here so the idea there is essentially we're going to have an additional set of

870
00:36:18,349 --> 00:36:20,289
如果您还记得HMC，我们将有另外一组潜在变量
here so the idea there is essentially we're going to have an additional set of

871
00:36:20,289 --> 00:36:24,760
如果您还记得HMC，我们将有另外一组潜在变量
we're going to have an additional set of latent variables if you recall HMC

872
00:36:24,760 --> 00:36:24,770
如果您还记得HMC，我们将有另外一组潜在变量
latent variables if you recall HMC basically we're then going to propagate

873
00:36:24,770 --> 00:36:26,500
基本上，我们接下来将使用哈密顿动力学来传播它们，以便
latent variables if you recall HMC basically we're then going to propagate

874
00:36:26,500 --> 00:36:29,230
基本上，我们接下来将使用哈密顿动力学来传播它们，以便
basically we're then going to propagate those using hamiltonian dynamics so to

875
00:36:29,230 --> 00:36:29,240
基本上，我们接下来将使用哈密顿动力学来传播它们，以便
those using hamiltonian dynamics so to do that you meet the gradient the

876
00:36:29,240 --> 00:36:32,170
你是否满足梯度，这里的梯度实际上就是
those using hamiltonian dynamics so to do that you meet the gradient the

877
00:36:32,170 --> 00:36:35,559
你是否满足梯度，这里的梯度实际上就是
do that you meet the gradient the gradient here is actually so if we take

878
00:36:35,559 --> 00:36:35,569
你是否满足梯度，这里的梯度实际上就是
gradient here is actually so if we take the log of the rights the logs put it

879
00:36:35,569 --> 00:36:37,930
日志所赋予的权利的日志，那么您就拥有了这些的总和
gradient here is actually so if we take the log of the rights the logs put it

880
00:36:37,930 --> 00:36:40,380
日志所赋予的权利的日志，那么您就拥有了这些的总和
the log of the rights the logs put it across then you have this sum of these

881
00:36:40,380 --> 00:36:40,390
日志所赋予的权利的日志，那么您就拥有了这些的总和
across then you have this sum of these so we call that the gradient here is

882
00:36:40,390 --> 00:36:43,510
所以我们称这里的梯度恰好来自我们的GP，这就是
across then you have this sum of these so we call that the gradient here is

883
00:36:43,510 --> 00:36:46,029
所以我们称这里的梯度恰好来自我们的GP，这就是
so we call that the gradient here is exactly comes from our GP so that's we

884
00:36:46,029 --> 00:36:46,039
所以我们称这里的梯度恰好来自我们的GP，这就是
exactly comes from our GP so that's we already have these here and then the

885
00:36:46,039 --> 00:36:48,430
在这里已经有这些了，然后我们的先验的导数是解析的
exactly comes from our GP so that's we already have these here and then the

886
00:36:48,430 --> 00:36:51,579
在这里已经有这些了，然后我们的先验的导数是解析的
already have these here and then the derivative of our prior is analytical

887
00:36:51,579 --> 00:36:51,589
在这里已经有这些了，然后我们的先验的导数是解析的
derivative of our prior is analytical because it's a PGM and we can control we

888
00:36:51,589 --> 00:36:54,099
因为它是一个PGM，我们可以控制，所以我们可以说
derivative of our prior is analytical because it's a PGM and we can control we

889
00:36:54,099 --> 00:36:54,840
因为它是一个PGM，我们可以控制，所以我们可以说
because it's a PGM and we can control we can say that

890
00:36:54,840 --> 00:36:54,850
因为它是一个PGM，我们可以控制，所以我们可以说
can say that nice distributions here that allows us

891
00:36:54,850 --> 00:36:57,360
这里不错的分布，让我们您知道这吸引人
can say that nice distributions here that allows us

892
00:36:57,360 --> 00:36:59,490
这里不错的分布，让我们您知道这吸引人
nice distributions here that allows us you know find this attractable

893
00:36:59,490 --> 00:36:59,500
这里不错的分布，让我们您知道这吸引人
you know find this attractable actual long solution

894
00:36:59,500 --> 00:37:04,410
实际的长期解决方案
you know find this attractable actual long solution

895
00:37:04,410 --> 00:37:04,539
所以是的，一旦用HMC采样了粒子，就以B为基数，所以
you know find this attractable actual long solution

896
00:37:04,539 --> 00:37:04,549
所以是的，一旦用HMC采样了粒子，就以B为基数，所以


897
00:37:04,549 --> 00:37:08,949
所以是的，一旦用HMC采样了粒子，就以B为基数，所以
so yeah so base B once once the particles are sampled with HMC so

898
00:37:08,949 --> 00:37:08,959
所以是的，一旦用HMC采样了粒子，就以B为基数，所以
particles are sampled with HMC so essentially we have a set then propagate

899
00:37:08,959 --> 00:37:11,410
本质上我们有一个集合，然后通过他的集合量传播一点到
particles are sampled with HMC so essentially we have a set then propagate

900
00:37:11,410 --> 00:37:13,569
本质上我们有一个集合，然后通过他的集合量传播一点到
essentially we have a set then propagate a little bit through his set amounts to

901
00:37:13,569 --> 00:37:13,579
本质上我们有一个集合，然后通过他的集合量传播一点到
a little bit through his set amounts to that so like 25 or whatever we then

902
00:37:13,579 --> 00:37:16,269
大概是25或其他，然后我们更新PCM，基本上就是这个新集合
a little bit through his set amounts to that so like 25 or whatever we then

903
00:37:16,269 --> 00:37:18,400
大概是25或其他，然后我们更新PCM，基本上就是这个新集合
that so like 25 or whatever we then update the PCM so basically this new set

904
00:37:18,400 --> 00:37:18,410
大概是25或其他，然后我们更新PCM，基本上就是这个新集合
update the PCM so basically this new set of particles within which are latent

905
00:37:18,410 --> 00:37:20,799
内有潜在变量的粒子的观测值
update the PCM so basically this new set of particles within which are latent

906
00:37:20,799 --> 00:37:23,650
内有潜在变量的粒子的观测值
of particles within which are latent variables act as observations for the

907
00:37:23,650 --> 00:37:23,660
内有潜在变量的粒子的观测值
variables act as observations for the PGM and in a sense she then we take over

908
00:37:23,660 --> 00:37:26,829
PGM，从某种意义上说，她然后我们接管了，我们将
variables act as observations for the PGM and in a sense she then we take over

909
00:37:26,829 --> 00:37:29,979
PGM，从某种意义上说，她然后我们接管了，我们将
PGM and in a sense she then we take over and we do the standard mixture of

910
00:37:29,979 --> 00:37:29,989
PGM，从某种意义上说，她然后我们接管了，我们将
and we do the standard mixture of garbage in optimization process you know

911
00:37:29,989 --> 00:37:33,009
在优化过程中出现垃圾，您知道变式方法，或者
and we do the standard mixture of garbage in optimization process you know

912
00:37:33,009 --> 00:37:34,809
在优化过程中出现垃圾，您知道变式方法，或者
garbage in optimization process you know the variational approach or if you're

913
00:37:34,809 --> 00:37:34,819
在优化过程中出现垃圾，您知道变式方法，或者
the variational approach or if you're not so in the Bayesian and DM approach

914
00:37:34,819 --> 00:37:36,880
在最佳峰的贝叶斯和DM方法中不是这样，然后
the variational approach or if you're not so in the Bayesian and DM approach

915
00:37:36,880 --> 00:37:39,130
在最佳峰的贝叶斯和DM方法中不是这样，然后
not so in the Bayesian and DM approach at an optimized peak and then you go

916
00:37:39,130 --> 00:37:39,140
在最佳峰的贝叶斯和DM方法中不是这样，然后
at an optimized peak and then you go back you return to the document process

917
00:37:39,140 --> 00:37:41,410
返回到您优化的文档流程，基本上重复一次
at an optimized peak and then you go back you return to the document process

918
00:37:41,410 --> 00:37:45,429
返回到您优化的文档流程，基本上重复一次
back you return to the document process you optimize and basically on you repeat

919
00:37:45,429 --> 00:37:45,439
返回到您优化的文档流程，基本上重复一次
you optimize and basically on you repeat you jump back and forth so in summary

920
00:37:45,439 --> 00:37:49,410
您来回跳动，因此总的来说，基本上我们有一套培训
you optimize and basically on you repeat you jump back and forth so in summary

921
00:37:49,410 --> 00:37:51,969
您来回跳动，因此总的来说，基本上我们有一套培训
you jump back and forth so in summary essentially we have a set of training

922
00:37:51,969 --> 00:37:51,979
您来回跳动，因此总的来说，基本上我们有一套培训
essentially we have a set of training observations Y we have an initial set of

923
00:37:51,979 --> 00:37:55,539
观察Y我们有一个初始的潜在变量集被打包
essentially we have a set of training observations Y we have an initial set of

924
00:37:55,539 --> 00:37:57,789
观察Y我们有一个初始的潜在变量集被打包
observations Y we have an initial set of latent variable is packed however

925
00:37:57,789 --> 00:37:57,799
观察Y我们有一个初始的潜在变量集被打包
latent variable is packed however looking for each training parameters

926
00:37:57,799 --> 00:37:59,559
在这里寻找每个训练参数，所以theta再次是我们的高斯
latent variable is packed however looking for each training parameters

927
00:37:59,559 --> 00:38:02,049
在这里寻找每个训练参数，所以theta再次是我们的高斯
looking for each training parameters here so theta again is our Gaussian

928
00:38:02,049 --> 00:38:02,059
在这里寻找每个训练参数，所以theta再次是我们的高斯
here so theta again is our Gaussian process parameters so length scales or

929
00:38:02,059 --> 00:38:06,219
工艺参数，长度范围或其他一些噪声项，以及
here so theta again is our Gaussian process parameters so length scales or

930
00:38:06,219 --> 00:38:08,289
工艺参数，长度范围或其他一些噪声项，以及
process parameters so length scales or whatever some additional noise terms and

931
00:38:08,289 --> 00:38:08,299
工艺参数，长度范围或其他一些噪声项，以及
whatever some additional noise terms and then these are all part of our actual

932
00:38:08,299 --> 00:38:10,150
那么这些都是我们实际PDF的一部分，因此第一步是
whatever some additional noise terms and then these are all part of our actual

933
00:38:10,150 --> 00:38:13,359
那么这些都是我们实际PDF的一部分，因此第一步是
then these are all part of our actual PDF so the first step is that we're

934
00:38:13,359 --> 00:38:13,369
那么这些都是我们实际PDF的一部分，因此第一步是
PDF so the first step is that we're going to calculate the gradient of our

935
00:38:13,369 --> 00:38:15,130
要计算我们的潜力的梯度，那么我们的行为很少
PDF so the first step is that we're going to calculate the gradient of our

936
00:38:15,130 --> 00:38:17,829
要计算我们的潜力的梯度，那么我们的行为很少
going to calculate the gradient of our potential here we're then little conduct

937
00:38:17,829 --> 00:38:17,839
要计算我们的潜力的梯度，那么我们的行为很少
potential here we're then little conduct agency so essentially we're going to

938
00:38:17,839 --> 00:38:19,599
代理机构，因此从本质上讲，我们将采用每一个微粒，否则我将搬家
potential here we're then little conduct agency so essentially we're going to

939
00:38:19,599 --> 00:38:21,249
代理机构，因此从本质上讲，我们将采用每一个微粒，否则我将搬家
agency so essentially we're going to take every single particle or I'll move

940
00:38:21,249 --> 00:38:21,259
代理机构，因此从本质上讲，我们将采用每一个微粒，否则我将搬家
take every single particle or I'll move it a little bit a little bit a little

941
00:38:21,259 --> 00:38:22,569
往后方一点点，然后那个
take every single particle or I'll move it a little bit a little bit a little

942
00:38:22,569 --> 00:38:25,449
往后方一点点，然后那个
it a little bit a little bit a little bit toward the posterior and then that

943
00:38:25,449 --> 00:38:25,459
往后方一点点，然后那个
bit toward the posterior and then that sample right there after stead amount of

944
00:38:25,459 --> 00:38:27,219
经过固定的步骤之后，就可以在那里进行采样，然后将其作为一组新的
bit toward the posterior and then that sample right there after stead amount of

945
00:38:27,219 --> 00:38:29,140
经过固定的步骤之后，就可以在那里进行采样，然后将其作为一组新的
sample right there after stead amount of steps will then act as a new set of

946
00:38:29,140 --> 00:38:29,150
经过固定的步骤之后，就可以在那里进行采样，然后将其作为一组新的
steps will then act as a new set of waiting observations for the

947
00:38:29,150 --> 00:38:30,789
从这里等待概率图形模型的观察
steps will then act as a new set of waiting observations for the

948
00:38:30,789 --> 00:38:33,339
从这里等待概率图形模型的观察
waiting observations for the probabilistic graphical models from here

949
00:38:33,339 --> 00:38:33,349
从这里等待概率图形模型的观察
probabilistic graphical models from here we then conduct the inference on the PGM

950
00:38:33,349 --> 00:38:36,130
然后，我们在迭代之间的PGM上进行推断
probabilistic graphical models from here we then conduct the inference on the PGM

951
00:38:36,130 --> 00:38:37,839
然后，我们在迭代之间的PGM上进行推断
we then conduct the inference on the PGM we iterate back and forth between

952
00:38:37,839 --> 00:38:37,849
然后，我们在迭代之间的PGM上进行推断
we iterate back and forth between computing the responsibilities and

953
00:38:37,849 --> 00:38:39,519
计算职责和实际参数超参数
we iterate back and forth between computing the responsibilities and

954
00:38:39,519 --> 00:38:43,140
计算职责和实际参数超参数
computing the responsibilities and actual parameters the hyper parameters

955
00:38:43,140 --> 00:38:43,150
计算职责和实际参数超参数
actual parameters the hyper parameters and we update them and then down here I

956
00:38:43,150 --> 00:38:45,420
我们对其进行了更新，然后在这里我没有提及，但实际上
actual parameters the hyper parameters and we update them and then down here I

957
00:38:45,420 --> 00:38:47,490
我们对其进行了更新，然后在这里我没有提及，但实际上
and we update them and then down here I did not mention this but essentially the

958
00:38:47,490 --> 00:38:47,500
我们对其进行了更新，然后在这里我没有提及，但实际上
did not mention this but essentially the the parameters and the Guardian process

959
00:38:47,500 --> 00:38:50,430
参数和监护程序也通过代理进行更新，因此
did not mention this but essentially the the parameters and the Guardian process

960
00:38:50,430 --> 00:38:52,860
参数和监护程序也通过代理进行更新，因此
the parameters and the Guardian process are also updated through agency also so

961
00:38:52,860 --> 00:38:52,870
参数和监护程序也通过代理进行更新，因此
are also updated through agency also so basically they sample length scales and

962
00:38:52,870 --> 00:38:55,170
基本上他们会采样长度尺度和噪声项，然后慢慢传播
are also updated through agency also so basically they sample length scales and

963
00:38:55,170 --> 00:38:57,390
基本上他们会采样长度尺度和噪声项，然后慢慢传播
basically they sample length scales and noise terms and slowly propagate those

964
00:38:57,390 --> 00:38:57,400
基本上他们会采样长度尺度和噪声项，然后慢慢传播
noise terms and slowly propagate those as well and basically this entire

965
00:38:57,400 --> 00:38:59,040
以及基本上整个过程，然后一遍又一遍地循环
noise terms and slowly propagate those as well and basically this entire

966
00:38:59,040 --> 00:39:00,930
以及基本上整个过程，然后一遍又一遍地循环
as well and basically this entire process and then it looped over and over

967
00:39:00,930 --> 00:39:00,940
以及基本上整个过程，然后一遍又一遍地循环
process and then it looped over and over and over until you team convergent or

968
00:39:00,940 --> 00:39:03,000
直到您的团队趋同或达到您的时代
process and then it looped over and over and over until you team convergent or

969
00:39:03,000 --> 00:39:06,710
直到您的团队趋同或达到您的时代
and over until you team convergent or your epoch has been reached

970
00:39:06,710 --> 00:39:06,720
直到您的团队趋同或达到您的时代
your epoch has been reached alright yes this is a quick on

971
00:39:06,720 --> 00:39:09,000
好的，这是关于预测的快速讨论
your epoch has been reached alright yes this is a quick on

972
00:39:09,000 --> 00:39:12,990
好的，这是关于预测的快速讨论
alright yes this is a quick on discussion regarding the predictive

973
00:39:12,990 --> 00:39:13,000
好的，这是关于预测的快速讨论
discussion regarding the predictive distribution so this is a little bit

974
00:39:13,000 --> 00:39:14,880
分配，所以这有点涉及本质上
discussion regarding the predictive distribution so this is a little bit

975
00:39:14,880 --> 00:39:18,350
分配，所以这有点涉及本质上
distribution so this is a little bit it's a little bit involved essentially

976
00:39:18,350 --> 00:39:18,360
分配，所以这有点涉及本质上
it's a little bit involved essentially we have to do a Monte Carlo

977
00:39:18,360 --> 00:39:21,530
不幸的是，我们必须最后进行一次蒙特卡洛近似
it's a little bit involved essentially we have to do a Monte Carlo

978
00:39:21,530 --> 00:39:24,900
不幸的是，我们必须最后进行一次蒙特卡洛近似
we have to do a Monte Carlo approximation unfortunately last and

979
00:39:24,900 --> 00:39:24,910
不幸的是，我们必须最后进行一次蒙特卡洛近似
approximation unfortunately last and unfortunately but yeah and the main

980
00:39:24,910 --> 00:39:27,000
不幸的是，是的，其背后的主要原因是因为我们
approximation unfortunately last and unfortunately but yeah and the main

981
00:39:27,000 --> 00:39:28,470
不幸的是，是的，其背后的主要原因是因为我们
unfortunately but yeah and the main reason behind that is because we're

982
00:39:28,470 --> 00:39:28,480
不幸的是，是的，其背后的主要原因是因为我们
reason behind that is because we're using monstro it's actually sampled

983
00:39:28,480 --> 00:39:30,450
使用monstro，实际上可以轻松地对变量进行采样并对其进行优化，但是
reason behind that is because we're using monstro it's actually sampled

984
00:39:30,450 --> 00:39:33,720
使用monstro，实际上可以轻松地对变量进行采样并对其进行优化，但是
using monstro it's actually sampled easily in variables and optimize it but

985
00:39:33,720 --> 00:39:33,730
使用monstro，实际上可以轻松地对变量进行采样并对其进行优化，但是
easily in variables and optimize it but I will say here that on so breaking

986
00:39:33,730 --> 00:39:36,780
我在这里要说的是，如此分散实际的预测分布
easily in variables and optimize it but I will say here that on so breaking

987
00:39:36,780 --> 00:39:38,990
我在这里要说的是，如此分散实际的预测分布
I will say here that on so breaking apart actual predictive distribution

988
00:39:38,990 --> 00:39:39,000
我在这里要说的是，如此分散实际的预测分布
apart actual predictive distribution where Y stars weren't guaranteed

989
00:39:39,000 --> 00:39:41,130
不能保证对Y星感兴趣的观测和
apart actual predictive distribution where Y stars weren't guaranteed

990
00:39:41,130 --> 00:39:42,900
不能保证对Y星感兴趣的观测和
where Y stars weren't guaranteed observation that were interested in and

991
00:39:42,900 --> 00:39:42,910
不能保证对Y星感兴趣的观测和
observation that were interested in and X star is going to be so if we kind of

992
00:39:42,910 --> 00:39:50,250
X星将是这样，如果我们将其拆分并分离，我们可以看到
observation that were interested in and X star is going to be so if we kind of

993
00:39:50,250 --> 00:39:54,030
X星将是这样，如果我们将其拆分并分离，我们可以看到
X star is going to be so if we kind of split this up and separate it we can see

994
00:39:54,030 --> 00:39:54,040
X星将是这样，如果我们将其拆分并分离，我们可以看到
split this up and separate it we can see that this guy here this is actually done

995
00:39:54,040 --> 00:39:56,610
这个家伙实际上是通过代理完成的，所以这是完成了三个
split this up and separate it we can see that this guy here this is actually done

996
00:39:56,610 --> 00:39:59,760
这个家伙实际上是通过代理完成的，所以这是完成了三个
that this guy here this is actually done through agency so this is it done three

997
00:39:59,760 --> 00:39:59,770
这个家伙实际上是通过代理完成的，所以这是完成了三个
through agency so this is it done three agencies this is also so this is

998
00:39:59,770 --> 00:40:01,320
代理商也是这样，这基本上是通过抽样完成的
through agency so this is it done three agencies this is also so this is

999
00:40:01,320 --> 00:40:03,690
代理商也是这样，这基本上是通过抽样完成的
agencies this is also so this is basically done by sampling we

1000
00:40:03,690 --> 00:40:03,700
代理商也是这样，这基本上是通过抽样完成的
basically done by sampling we marginalized yeah so we compute this by

1001
00:40:03,700 --> 00:40:06,660
是边缘化的，所以我们本质上是通过玩一堆新游戏来计算
basically done by sampling we marginalized yeah so we compute this by

1002
00:40:06,660 --> 00:40:09,210
是边缘化的，所以我们本质上是通过玩一堆新游戏来计算
marginalized yeah so we compute this by essentially and playing a bunch of new

1003
00:40:09,210 --> 00:40:09,220
是边缘化的，所以我们本质上是通过玩一堆新游戏来计算
essentially and playing a bunch of new flaking variables from our PGM and

1004
00:40:09,220 --> 00:40:11,640
从我们的PGM中提取变量并通过网络将其转发给
essentially and playing a bunch of new flaking variables from our PGM and

1005
00:40:11,640 --> 00:40:13,320
从我们的PGM中提取变量并通过网络将其转发给
flaking variables from our PGM and feeding them forward through the network

1006
00:40:13,320 --> 00:40:13,330
从我们的PGM中提取变量并通过网络将其转发给
feeding them forward through the network and this right here is actually the GP

1007
00:40:13,330 --> 00:40:17,460
这实际上是GP预测分布
feeding them forward through the network and this right here is actually the GP

1008
00:40:17,460 --> 00:40:18,960
这实际上是GP预测分布
and this right here is actually the GP predictive distribution which there's

1009
00:40:18,960 --> 00:40:18,970
这实际上是GP预测分布
predictive distribution which there's actually playing analytical for because

1010
00:40:18,970 --> 00:40:21,480
实际上是出于分析目的，因为这只是离奇
predictive distribution which there's actually playing analytical for because

1011
00:40:21,480 --> 00:40:24,750
实际上是出于分析目的，因为这只是离奇
actually playing analytical for because it's just bizarre

1012
00:40:24,750 --> 00:40:26,150
好的
actually playing analytical for because it's just bizarre

1013
00:40:26,150 --> 00:40:26,160
好的


1014
00:40:26,160 --> 00:40:28,940
好的
all right

1015
00:40:28,940 --> 00:40:29,770
还在生气，我不知道是哪个
all right

1016
00:40:29,770 --> 00:40:29,780
还在生气，我不知道是哪个


1017
00:40:29,780 --> 00:40:36,190
还在生气，我不知道是哪个
still angry work I don't know which

1018
00:40:36,190 --> 00:40:38,109
我没有网路
still angry work I don't know which

1019
00:40:38,109 --> 00:40:38,119
我没有网路


1020
00:40:38,119 --> 00:40:41,559
我没有网路
I have no internet

1021
00:40:41,559 --> 00:40:47,430
好吧，反正我会在这里说明一下
I have no internet

1022
00:40:47,430 --> 00:40:47,440
好吧，反正我会在这里说明一下


1023
00:40:47,440 --> 00:40:53,410
好吧，反正我会在这里说明一下
okay all right well anyway I'll just I'll just kind of illustrate this here

1024
00:40:53,410 --> 00:40:53,420
好吧，反正我会在这里说明一下
I'll just kind of illustrate this here so essentially this if you look on the

1025
00:40:53,420 --> 00:40:56,290
所以基本上，如果你看幻灯片，这基本上是一部电影
I'll just kind of illustrate this here so essentially this if you look on the

1026
00:40:56,290 --> 00:40:58,540
所以基本上，如果你看幻灯片，这基本上是一部电影
so essentially this if you look on the slides basically this is a movie that

1027
00:40:58,540 --> 00:40:58,550
所以基本上，如果你看幻灯片，这基本上是一部电影
slides basically this is a movie that illustrates this whole process so the

1028
00:40:58,550 --> 00:41:00,640
说明了整个过程，所以想法是，在右侧，我们有一个
slides basically this is a movie that illustrates this whole process so the

1029
00:41:00,640 --> 00:41:03,940
说明了整个过程，所以想法是，在右侧，我们有一个
illustrates this whole process so the idea is that on on the right we have a

1030
00:41:03,940 --> 00:41:03,950
说明了整个过程，所以想法是，在右侧，我们有一个
idea is that on on the right we have a set of observations and a spiral

1031
00:41:03,950 --> 00:41:05,910
一组观察结果和一个螺旋线，基本上这些都是我们通过GP得出的
idea is that on on the right we have a set of observations and a spiral

1032
00:41:05,910 --> 00:41:09,610
一组观察结果和一个螺旋线，基本上这些都是我们通过GP得出的
set of observations and a spiral basically these we through the GP on

1033
00:41:09,610 --> 00:41:09,620
一组观察结果和一个螺旋线，基本上这些都是我们通过GP得出的
basically these we through the GP on these are translated to variables that

1034
00:41:09,620 --> 00:41:12,820
这些被转换为变量，然后我们通过HMC PGM传播这些变量
basically these we through the GP on these are translated to variables that

1035
00:41:12,820 --> 00:41:16,630
这些被转换为变量，然后我们通过HMC PGM传播这些变量
these are translated to variables that we then propagate through HMC the PGM

1036
00:41:16,630 --> 00:41:16,640
这些被转换为变量，然后我们通过HMC PGM传播这些变量
we then propagate through HMC the PGM then tries to map instead of mixtures

1037
00:41:16,640 --> 00:41:18,250
然后尝试在其上映射而不是混合，然后在此处，然后
we then propagate through HMC the PGM then tries to map instead of mixtures

1038
00:41:18,250 --> 00:41:21,340
然后尝试在其上映射而不是混合，然后在此处，然后
then tries to map instead of mixtures onto that and then over here we then

1039
00:41:21,340 --> 00:41:21,350
然后尝试在其上映射而不是混合，然后在此处，然后
onto that and then over here we then basically sample a bunch from these and

1040
00:41:21,350 --> 00:41:23,290
基本上从这些中取样一堆，然后通过
onto that and then over here we then basically sample a bunch from these and

1041
00:41:23,290 --> 00:41:24,820
基本上从这些中取样一堆，然后通过
basically sample a bunch from these and then this represents the standpoint by

1042
00:41:24,820 --> 00:41:24,830
基本上从这些中取样一堆，然后通过
then this represents the standpoint by the colors and there's also shows in the

1043
00:41:24,830 --> 00:41:27,610
颜色，并且在纸上还显示了如何
then this represents the standpoint by the colors and there's also shows in the

1044
00:41:27,610 --> 00:41:30,190
颜色，并且在纸上还显示了如何
the colors and there's also shows in the paper of how

1045
00:41:30,190 --> 00:41:42,609
还有我们的早餐有任何问题
the colors and there's also shows in the paper of how

1046
00:41:42,609 --> 00:41:42,619
还有我们的早餐有任何问题


1047
00:41:42,619 --> 00:41:48,550
还有我们的早餐有任何问题
and also our breakfast any question

1048
00:41:48,550 --> 00:41:49,710
[掌声]
and also our breakfast any question

1049
00:41:49,710 --> 00:41:49,720
[掌声]


1050
00:41:49,720 --> 00:41:52,800
[掌声]
[Applause]

1051
00:41:52,800 --> 00:42:51,940
大家下午好，我会谈论最近的论文
[Applause]

1052
00:42:51,940 --> 00:42:51,950
大家下午好，我会谈论最近的论文


1053
00:42:51,950 --> 00:42:56,319
大家下午好，我会谈论最近的论文
good afternoon everyone I'll be talking about the paper that has been recently

1054
00:42:56,319 --> 00:42:56,329
大家下午好，我会谈论最近的论文
about the paper that has been recently published in 2017 that is a learning in

1055
00:42:56,329 --> 00:42:59,020
于2017年发布，该书旨在学习异构数据的网络结构
about the paper that has been recently published in 2017 that is a learning in

1056
00:42:59,020 --> 00:43:00,460
于2017年发布，该书旨在学习异构数据的网络结构
published in 2017 that is a learning in network structure of heterogeneous data

1057
00:43:00,460 --> 00:43:00,470
于2017年发布，该书旨在学习异构数据的网络结构
network structure of heterogeneous data by your pairwise exponential macro

1058
00:43:00,470 --> 00:43:02,530
通过您的成对指数宏随机字段，在此我们可以观察到
network structure of heterogeneous data by your pairwise exponential macro

1059
00:43:02,530 --> 00:43:04,809
通过您的成对指数宏随机字段，在此我们可以观察到
by your pairwise exponential macro random field and in this we can observe

1060
00:43:04,809 --> 00:43:04,819
通过您的成对指数宏随机字段，在此我们可以观察到
random field and in this we can observe there are three main important keywords

1061
00:43:04,819 --> 00:43:07,030
有三个主要的重要关键词之一是学习网络
random field and in this we can observe there are three main important keywords

1062
00:43:07,030 --> 00:43:09,520
有三个主要的重要关键词之一是学习网络
there are three main important keywords one is the learning the network

1063
00:43:09,520 --> 00:43:09,530
有三个主要的重要关键词之一是学习网络
one is the learning the network structure second one is a word data

1064
00:43:09,530 --> 00:43:11,859
结构第二个是单词数据，它本质上是异构的，
one is the learning the network structure second one is a word data

1065
00:43:11,859 --> 00:43:14,319
结构第二个是单词数据，它本质上是异构的，
structure second one is a word data it's a heterogeneous in nature and the

1066
00:43:14,319 --> 00:43:14,329
结构第二个是单词数据，它本质上是异构的，
it's a heterogeneous in nature and the third one is what model we are going to

1067
00:43:14,329 --> 00:43:16,230
第三个是我们要与指数马尔可夫配对的模型
it's a heterogeneous in nature and the third one is what model we are going to

1068
00:43:16,230 --> 00:43:18,970
第三个是我们要与指数马尔可夫配对的模型
third one is what model we are going to want to pair with exponential Markov

1069
00:43:18,970 --> 00:43:18,980
第三个是我们要与指数马尔可夫配对的模型
want to pair with exponential Markov random field and this is the outline of

1070
00:43:18,980 --> 00:43:21,760
随机字段，这是我这件事的概述，我的意思是先跟我谈谈
want to pair with exponential Markov random field and this is the outline of

1071
00:43:21,760 --> 00:43:25,150
随机字段，这是我这件事的概述，我的意思是先跟我谈谈
random field and this is the outline of my this thing I mean talk to me first

1072
00:43:25,150 --> 00:43:25,160
随机字段，这是我这件事的概述，我的意思是先跟我谈谈
my this thing I mean talk to me first I'll be giving an introduction of water

1073
00:43:25,160 --> 00:43:26,440
接下来，我将介绍水测试，但其动机是
my this thing I mean talk to me first I'll be giving an introduction of water

1074
00:43:26,440 --> 00:43:28,690
接下来，我将介绍水测试，但其动机是
I'll be giving an introduction of water test next but the motivation of its of

1075
00:43:28,690 --> 00:43:28,700
接下来，我将介绍水测试，但其动机是
test next but the motivation of its of the work and then later the column

1076
00:43:28,700 --> 00:43:32,589
工作，然后是列定义，然后我会讲非常
test next but the motivation of its of the work and then later the column

1077
00:43:32,589 --> 00:43:35,500
工作，然后是列定义，然后我会讲非常
the work and then later the column definition and then I'll be talking very

1078
00:43:35,500 --> 00:43:35,510
工作，然后是列定义，然后我会讲非常
definition and then I'll be talking very in detail about pmrs and later since

1079
00:43:35,510 --> 00:43:40,240
有关pmrs的详细信息，以后再讲，因为有一个术语是分区
definition and then I'll be talking very in detail about pmrs and later since

1080
00:43:40,240 --> 00:43:43,900
有关pmrs的详细信息，以后再讲，因为有一个术语是分区
in detail about pmrs and later since there is one term that is the partition

1081
00:43:43,900 --> 00:43:43,910
有关pmrs的详细信息，以后再讲，因为有一个术语是分区
there is one term that is the partition function which is not tractable so

1082
00:43:43,910 --> 00:43:45,870
函数是难处理的，因此在计算上我们去
there is one term that is the partition function which is not tractable so

1083
00:43:45,870 --> 00:43:47,530
函数是难处理的，因此在计算上我们去
function which is not tractable so computationally so we go for

1084
00:43:47,530 --> 00:43:47,540
函数是难处理的，因此在计算上我们去
computationally so we go for approximated or maximum like here

1085
00:43:47,540 --> 00:43:49,000
近似或最大值，例如此处，而不是精确的最大值
computationally so we go for approximated or maximum like here

1086
00:43:49,000 --> 00:43:50,319
近似或最大值，例如此处，而不是精确的最大值
approximated or maximum like here instead of going for exact maximum

1087
00:43:50,319 --> 00:43:50,329
近似或最大值，例如此处，而不是精确的最大值
instead of going for exact maximum likelihood and then later I'll be

1088
00:43:50,329 --> 00:43:52,240
可能性，然后稍后我将讨论优化技术
instead of going for exact maximum likelihood and then later I'll be

1089
00:43:52,240 --> 00:43:55,030
可能性，然后稍后我将讨论优化技术
likelihood and then later I'll be discussing about optimization technique

1090
00:43:55,030 --> 00:43:55,040
可能性，然后稍后我将讨论优化技术
discussing about optimization technique called or a DMM that is alternating

1091
00:43:55,040 --> 00:43:56,799
被称为或DMM的交替方向或功率复用的方法
discussing about optimization technique called or a DMM that is alternating

1092
00:43:56,799 --> 00:43:58,630
被称为或DMM的交替方向或功率复用的方法
called or a DMM that is alternating direction or method of power multiplex

1093
00:43:58,630 --> 00:43:58,640
被称为或DMM的交替方向或功率复用的方法
direction or method of power multiplex and then I will show a bleep result of

1094
00:43:58,640 --> 00:44:01,059
然后我将显示获得的结果的失败结果，然后得出结论
direction or method of power multiplex and then I will show a bleep result of

1095
00:44:01,059 --> 00:44:03,690
然后我将显示获得的结果的失败结果，然后得出结论
and then I will show a bleep result of what is obtained and then the conclusion

1096
00:44:03,690 --> 00:44:03,700
然后我将显示获得的结果的失败结果，然后得出结论
what is obtained and then the conclusion so what does and Markov random feel like

1097
00:44:03,700 --> 00:44:08,109
所以，马尔可夫随机觉得宏随机场的重要性是
what is obtained and then the conclusion so what does and Markov random feel like

1098
00:44:08,109 --> 00:44:09,700
所以，马尔可夫随机觉得宏随机场的重要性是
so what does and Markov random feel like its importance of macro random field is

1099
00:44:09,700 --> 00:44:09,710
所以，马尔可夫随机觉得宏随机场的重要性是
its importance of macro random field is like its importance is fundamental tool

1100
00:44:09,710 --> 00:44:11,349
就像它的重要性是机器学习中许多应用程序的基本工具
its importance of macro random field is like its importance is fundamental tool

1101
00:44:11,349 --> 00:44:14,530
就像它的重要性是机器学习中许多应用程序的基本工具
like its importance is fundamental tool to many applications in machine learning

1102
00:44:14,530 --> 00:44:14,540
就像它的重要性是机器学习中许多应用程序的基本工具
to many applications in machine learning and also it is necessary for the samara

1103
00:44:14,540 --> 00:44:18,690
并且所有这些都需要轮回的异质性
to many applications in machine learning and also it is necessary for the samara

1104
00:44:18,690 --> 00:44:21,010
并且所有这些都需要轮回的异质性
and also it is necessary for the samara from all this a matter for heterogeneous

1105
00:44:21,010 --> 00:44:21,020
并且所有这些都需要轮回的异质性
from all this a matter for heterogeneous entities so if for example you have a

1106
00:44:21,020 --> 00:44:23,260
实体，例如，如果您有一个医疗数据库和性质，那么这就是
from all this a matter for heterogeneous entities so if for example you have a

1107
00:44:23,260 --> 00:44:27,520
实体，例如，如果您有一个医疗数据库和性质，那么这就是
entities so if for example you have a medical database and nature so that is

1108
00:44:27,520 --> 00:44:27,530
实体，例如，如果您有一个医疗数据库和性质，那么这就是
medical database and nature so that is it has between the categorical and

1109
00:44:27,530 --> 00:44:30,099
它介于类别变量和连续变量之间，因此例如
medical database and nature so that is it has between the categorical and

1110
00:44:30,099 --> 00:44:32,079
它介于类别变量和连续变量之间，因此例如
it has between the categorical and continuous variables so for example the

1111
00:44:32,079 --> 00:44:32,089
它介于类别变量和连续变量之间，因此例如
continuous variables so for example the age gender the medical history of the

1112
00:44:32,089 --> 00:44:34,500
年龄性别患者的病史和其他有趣的领域
continuous variables so for example the age gender the medical history of the

1113
00:44:34,500 --> 00:44:40,150
年龄性别患者的病史和其他有趣的领域
age gender the medical history of the patient and the other interesting area

1114
00:44:40,150 --> 00:44:40,160
年龄性别患者的病史和其他有趣的领域
patient and the other interesting area where it can be used for analyzing the

1115
00:44:40,160 --> 00:44:44,680
可用于分析蛋白质相互作用的地方
patient and the other interesting area where it can be used for analyzing the

1116
00:44:44,680 --> 00:44:47,799
可用于分析蛋白质相互作用的地方
where it can be used for analyzing the protein interaction

1117
00:44:47,799 --> 00:44:48,160
有一个主要的主要领域可以实现这一目标，那就是
where it can be used for analyzing the protein interaction

1118
00:44:48,160 --> 00:44:48,170
有一个主要的主要领域可以实现这一目标，那就是


1119
00:44:48,170 --> 00:44:54,040
有一个主要的主要领域可以实现这一目标，那就是
there is one major major field which implements this and that is in

1120
00:44:54,040 --> 00:44:54,050
有一个主要的主要领域可以实现这一目标，那就是
implements this and that is in computational biology which is the being

1121
00:44:54,050 --> 00:44:57,550
计算生物学这是无能为力的
implements this and that is in computational biology which is the being

1122
00:44:57,550 --> 00:44:58,660
计算生物学这是无能为力的
computational biology which is the being unable to task for this is to

1123
00:44:58,660 --> 00:44:58,670
计算生物学这是无能为力的
unable to task for this is to infrastructure and what is happening we

1124
00:44:58,670 --> 00:45:02,200
基础设施以及正在发生的事情
unable to task for this is to infrastructure and what is happening we

1125
00:45:02,200 --> 00:45:05,110
基础设施以及正在发生的事情
infrastructure and what is happening we now people and people who sees the

1126
00:45:05,110 --> 00:45:05,120
基础设施以及正在发生的事情
now people and people who sees the Gaussian graphical models but in

1127
00:45:05,120 --> 00:45:09,030
高斯图形模型，但在今天有了这种新技术
now people and people who sees the Gaussian graphical models but in

1128
00:45:09,030 --> 00:45:12,550
高斯图形模型，但在今天有了这种新技术
Gaussian graphical models but in nowadays with new technologies of this

1129
00:45:12,550 --> 00:45:12,560
高斯图形模型，但在今天有了这种新技术
nowadays with new technologies of this DNA sequencing we can which produces the

1130
00:45:12,560 --> 00:45:16,600
我们可以通过DNA测序来激活带有或不带有氮的数据
nowadays with new technologies of this DNA sequencing we can which produces the

1131
00:45:16,600 --> 00:45:18,700
我们可以通过DNA测序来激活带有或不带有氮的数据
DNA sequencing we can which produces the data with or with nitrogen is activation

1132
00:45:18,700 --> 00:45:18,710
我们可以通过DNA测序来激活带有或不带有氮的数据
data with or with nitrogen is activation and this growth gaussian graphical

1133
00:45:18,710 --> 00:45:21,670
而且这种增长的高斯图形模型将无法提取
data with or with nitrogen is activation and this growth gaussian graphical

1134
00:45:21,670 --> 00:45:25,590
而且这种增长的高斯图形模型将无法提取
and this growth gaussian graphical models will not be able to extract

1135
00:45:25,590 --> 00:45:25,600
而且这种增长的高斯图形模型将无法提取
models will not be able to extract generate the structure for this

1136
00:45:25,600 --> 00:45:27,540
产生这个异质结构域的结构，因此
models will not be able to extract generate the structure for this

1137
00:45:27,540 --> 00:45:31,080
产生这个异质结构域的结构，因此
generate the structure for this heterogenous domain so because of this

1138
00:45:31,080 --> 00:45:31,090
产生这个异质结构域的结构，因此
heterogenous domain so because of this we are going to outline the entire now

1139
00:45:31,090 --> 00:45:34,570
我们现在将在运动问题中概述整个问题
heterogenous domain so because of this we are going to outline the entire now

1140
00:45:34,570 --> 00:45:36,790
我们现在将在运动问题中概述整个问题
we are going to outline the entire now in the sport questions we are going to

1141
00:45:36,790 --> 00:45:36,800
我们现在将在运动问题中概述整个问题
in the sport questions we are going to see what there's a PMRF and then second

1142
00:45:36,800 --> 00:45:39,700
看看有一个PMRF，然后我们将近似
in the sport questions we are going to see what there's a PMRF and then second

1143
00:45:39,700 --> 00:45:41,280
看看有一个PMRF，然后我们将近似
see what there's a PMRF and then second we are going to of approximate the

1144
00:45:41,280 --> 00:45:41,290
看看有一个PMRF，然后我们将近似
we are going to of approximate the [Applause]

1145
00:45:41,290 --> 00:45:42,480
[鼓掌]公式最大近似值
we are going to of approximate the [Applause]

1146
00:45:42,480 --> 00:45:44,740
[鼓掌]公式最大近似值
[Applause] formula to approximate in maximum

1147
00:45:44,740 --> 00:45:44,750
[鼓掌]公式最大近似值
formula to approximate in maximum likelihood problem and then develop

1148
00:45:44,750 --> 00:45:47,860
可能性问题，然后开发Avant，然后再进行分区功能
formula to approximate in maximum likelihood problem and then develop

1149
00:45:47,860 --> 00:45:50,890
可能性问题，然后开发Avant，然后再进行分区功能
likelihood problem and then develop Avant and then on the partition function

1150
00:45:50,890 --> 00:45:50,900
可能性问题，然后开发Avant，然后再进行分区功能
Avant and then on the partition function in the later a scalable or a DML

1151
00:45:50,900 --> 00:45:53,320
在后来的封闭式可扩展或DML优化算法中
Avant and then on the partition function in the later a scalable or a DML

1152
00:45:53,320 --> 00:45:56,260
在后来的封闭式可扩展或DML优化算法中
in the later a scalable or a DML optimization algorithm with the closed

1153
00:45:56,260 --> 00:45:56,270
在后来的封闭式可扩展或DML优化算法中
optimization algorithm with the closed form update and then you'll also know

1154
00:45:56,270 --> 00:45:58,780
表格更新，然后您还将知道，如果我们的估计量是浮士德式的
optimization algorithm with the closed form update and then you'll also know

1155
00:45:58,780 --> 00:46:01,920
表格更新，然后您还将知道，如果我们的估计量是浮士德式的
form update and then you'll also know that if then our estimator is a Faustian

1156
00:46:01,920 --> 00:46:01,930
表格更新，然后您还将知道，如果我们的估计量是浮士德式的
that if then our estimator is a Faustian so what is PMS going to diffuse of EMR

1157
00:46:01,930 --> 00:46:06,910
那么PMS将如何传播EMR，所以我们有一些定义
that if then our estimator is a Faustian so what is PMS going to diffuse of EMR

1158
00:46:06,910 --> 00:46:10,090
那么PMS将如何传播EMR，所以我们有一些定义
so what is PMS going to diffuse of EMR so there are some definitions that we

1159
00:46:10,090 --> 00:46:10,100
那么PMS将如何传播EMR，所以我们有一些定义
so there are some definitions that we are going to consider first we'll

1160
00:46:10,100 --> 00:46:11,620
首先要考虑的是，我们将数据视为
so there are some definitions that we are going to consider first we'll

1161
00:46:11,620 --> 00:46:13,900
首先要考虑的是，我们将数据视为
are going to consider first we'll consider that data is like an

1162
00:46:13,900 --> 00:46:13,910
首先要考虑的是，我们将数据视为
consider that data is like an independent multiband observation and

1163
00:46:13,910 --> 00:46:15,580
独立的多频带观测，然后这些样本从
consider that data is like an independent multiband observation and

1164
00:46:15,580 --> 00:46:18,550
独立的多频带观测，然后这些样本从
independent multiband observation and then later these samples are iid from an

1165
00:46:18,550 --> 00:46:18,560
独立的多频带观测，然后这些样本从
then later these samples are iid from an exponential family of institution it's P

1166
00:46:18,560 --> 00:46:22,000
指数家族的机构是P的X逗号theta，然后是
then later these samples are iid from an exponential family of institution it's P

1167
00:46:22,000 --> 00:46:24,040
指数家族的机构是P的X逗号theta，然后是
exponential family of institution it's P of X comma theta and then later with

1168
00:46:24,040 --> 00:46:24,050
指数家族的机构是P的X逗号theta，然后是
of X comma theta and then later with represented by P no graphical model with

1169
00:46:24,050 --> 00:46:26,230
用没有自然参数theta和的P无图形模型表示
of X comma theta and then later with represented by P no graphical model with

1170
00:46:26,230 --> 00:46:29,650
用没有自然参数theta和的P无图形模型表示
represented by P no graphical model with the natural parameter theta and and we

1171
00:46:29,650 --> 00:46:29,660
用没有自然参数theta和的P无图形模型表示
the natural parameter theta and and we use these samples to estimate the

1172
00:46:29,660 --> 00:46:31,900
使用这些样本来估算下标分布，这是
the natural parameter theta and and we use these samples to estimate the

1173
00:46:31,900 --> 00:46:33,670
使用这些样本来估算下标分布，这是
use these samples to estimate the underling distribution and this is the

1174
00:46:33,670 --> 00:46:33,680
使用这些样本来估算下标分布，这是
underling distribution and this is the in general like we have London PGM where

1175
00:46:33,680 --> 00:46:37,600
总的来说，就像我们有伦敦PGM，其中V是我的Nora顶点，E是我的优势
underling distribution and this is the in general like we have London PGM where

1176
00:46:37,600 --> 00:46:40,060
总的来说，就像我们有伦敦PGM，其中V是我的Nora顶点，E是我的优势
in general like we have London PGM where V is my Nora vertices and E is my edge

1177
00:46:40,060 --> 00:46:40,070
总的来说，就像我们有伦敦PGM，其中V是我的Nora顶点，E是我的优势
V is my Nora vertices and E is my edge and the length of this is P and also the

1178
00:46:40,070 --> 00:46:43,390
它的长度是P，并且结构也以此编码
V is my Nora vertices and E is my edge and the length of this is P and also the

1179
00:46:43,390 --> 00:46:44,710
它的长度是P，并且结构也以此编码
and the length of this is P and also the structure is encoded with this

1180
00:46:44,710 --> 00:46:44,720
它的长度是P，并且结构也以此编码
structure is encoded with this exponential family parameter theta so

1181
00:46:44,720 --> 00:46:51,300
指数族参数theta，因此PMRF pms是多元变量的子类
structure is encoded with this exponential family parameter theta so

1182
00:46:51,300 --> 00:46:54,220
指数族参数theta，因此PMRF pms是多元变量的子类
exponential family parameter theta so PMRF pms is a subclass of multivariate

1183
00:46:54,220 --> 00:46:54,230
指数族参数theta，因此PMRF pms是多元变量的子类
PMRF pms is a subclass of multivariate exponent

1184
00:46:54,230 --> 00:46:55,190
可以解释的指数或指数族
PMRF pms is a subclass of multivariate exponent

1185
00:46:55,190 --> 00:46:57,030
可以解释的指数或指数族
or exponential family that can explain explicitly relieve the marker structure

1186
00:46:57,030 --> 00:46:59,270
显式缓解跨异构变量的标记结构，这里
or exponential family that can explain explicitly relieve the marker structure

1187
00:46:59,270 --> 00:47:01,910
显式缓解跨异构变量的标记结构，这里
explicitly relieve the marker structure across heterogeneous variables and here

1188
00:47:01,910 --> 00:47:01,920
显式缓解跨异构变量的标记结构，这里
across heterogeneous variables and here this these are the few notations that we

1189
00:47:01,920 --> 00:47:03,829
这些是我们将在这片轻落的片子中遵循的几个符号
across heterogeneous variables and here this these are the few notations that we

1190
00:47:03,829 --> 00:47:06,950
这些是我们将在这片轻落的片子中遵循的几个符号
this these are the few notations that we will follow in this light falling slice

1191
00:47:06,950 --> 00:47:06,960
这些是我们将在这片轻落的片子中遵循的几个符号
will follow in this light falling slice the inner product is given by this

1192
00:47:06,960 --> 00:47:08,720
内积是由B的预告片给出的，还有明显的upma
will follow in this light falling slice the inner product is given by this

1193
00:47:08,720 --> 00:47:11,960
内积是由B的预告片给出的，还有明显的upma
the inner product is given by this trailer of a B and also the obvious upma

1194
00:47:11,960 --> 00:47:11,970
内积是由B的预告片给出的，还有明显的upma
trailer of a B and also the obvious upma contaminate the set of very effectors in

1195
00:47:11,970 --> 00:47:14,000
以这种形式污染非常效应器集，所以让我们考虑
trailer of a B and also the obvious upma contaminate the set of very effectors in

1196
00:47:14,000 --> 00:47:17,870
以这种形式污染非常效应器集，所以让我们考虑
contaminate the set of very effectors in this form okay so let's consider a

1197
00:47:17,870 --> 00:47:17,880
以这种形式污染非常效应器集，所以让我们考虑
this form okay so let's consider a random vector with X X 1 to X B and then

1198
00:47:17,880 --> 00:47:21,799
XX 1到XB的随机向量，然后是复古属且在
this form okay so let's consider a random vector with X X 1 to X B and then

1199
00:47:21,799 --> 00:47:23,420
XX 1到XB的随机向量，然后是复古属且在
random vector with X X 1 to X B and then later which are retro genus and within

1200
00:47:23,420 --> 00:47:23,430
XX 1到XB的随机向量，然后是复古属且在
later which are retro genus and within this domain or extras a chronicle

1201
00:47:23,430 --> 00:47:25,579
这个域或多余的只是变量的编年史产品，那是什么
later which are retro genus and within this domain or extras a chronicle

1202
00:47:25,579 --> 00:47:28,660
这个域或多余的只是变量的编年史产品，那是什么
this domain or extras a chronicle product of just variables so what is it

1203
00:47:28,660 --> 00:47:28,670
这个域或多余的只是变量的编年史产品，那是什么
product of just variables so what is it if you have a matrix a which is a 1 a 2

1204
00:47:28,670 --> 00:47:31,730
如果您有一个矩阵a，它是1 a 2 a 3 a 4和B，那么我们将每个矩阵相乘
product of just variables so what is it if you have a matrix a which is a 1 a 2

1205
00:47:31,730 --> 00:47:34,880
如果您有一个矩阵a，它是1 a 2 a 3 a 4和B，那么我们将每个矩阵相乘
if you have a matrix a which is a 1 a 2 a 3 a 4 and B so we multiply each

1206
00:47:34,880 --> 00:47:34,890
如果您有一个矩阵a，它是1 a 2 a 3 a 4和B，那么我们将每个矩阵相乘
a 3 a 4 and B so we multiply each element of this a1 through this matrix B

1207
00:47:34,890 --> 00:47:37,880
这个a1的元素通过这个矩阵B和这个PHP来实现，这就是
a 3 a 4 and B so we multiply each element of this a1 through this matrix B

1208
00:47:37,880 --> 00:47:40,390
这个a1的元素通过这个矩阵B和这个PHP来实现，这就是
element of this a1 through this matrix B and a to this PHP so that's the

1209
00:47:40,390 --> 00:47:40,400
这个a1的元素通过这个矩阵B和这个PHP来实现，这就是
and a to this PHP so that's the chronicle product here and then later or

1210
00:47:40,400 --> 00:47:43,190
在这里记述产品，然后再或假设我们有条件地分配
and a to this PHP so that's the chronicle product here and then later or

1211
00:47:43,190 --> 00:47:46,430
在这里记述产品，然后再或假设我们有条件地分配
chronicle product here and then later or suppose we the conditional distribution

1212
00:47:46,430 --> 00:47:46,440
在这里记述产品，然后再或假设我们有条件地分配
suppose we the conditional distribution of each variable is X are given all my

1213
00:47:46,440 --> 00:47:48,589
每个变量的X是给定我所有以前的PP减去1的变量
suppose we the conditional distribution of each variable is X are given all my

1214
00:47:48,589 --> 00:47:51,309
每个变量的X是给定我所有以前的PP减去1的变量
of each variable is X are given all my previous PP minus 1 variables are

1215
00:47:51,309 --> 00:47:51,319
每个变量的X是给定我所有以前的PP减去1的变量
previous PP minus 1 variables are unknown to be the exponential

1216
00:47:51,319 --> 00:47:53,480
未知的是该域中的指数分布是sy
previous PP minus 1 variables are unknown to be the exponential

1217
00:47:53,480 --> 00:47:57,890
未知的是该域中的指数分布是sy
unknown to be the exponential distribution in this domain is the sy

1218
00:47:57,890 --> 00:47:57,900
未知的是该域中的指数分布是sy
distribution in this domain is the sy are Thea ok so yeah and then later the

1219
00:47:57,900 --> 00:48:01,609
是Thea好的，是的，然后在此之后也指定了分布
distribution in this domain is the sy are Thea ok so yeah and then later the

1220
00:48:01,609 --> 00:48:03,440
是Thea好的，是的，然后在此之后也指定了分布
are Thea ok so yeah and then later the distribution is also specified with this

1221
00:48:03,440 --> 00:48:03,450
是Thea好的，是的，然后在此之后也指定了分布
distribution is also specified with this M R dimensional or potential with BR and

1222
00:48:03,450 --> 00:48:07,700
将BR和s BR转换为X Appa的MR尺寸或潜力，并基于我的比例
distribution is also specified with this M R dimensional or potential with BR and

1223
00:48:07,700 --> 00:48:11,180
将BR和s BR转换为X Appa的MR尺寸或潜力，并基于我的比例
M R dimensional or potential with BR and s BR into X Appa and my scale based

1224
00:48:11,180 --> 00:48:11,190
将BR和s BR转换为X Appa的MR尺寸或潜力，并基于我的比例
s BR into X Appa and my scale based parameters TR into extra part and then

1225
00:48:11,190 --> 00:48:13,309
参数TR变成多余的部分，然后我让K这就是这种方式
s BR into X Appa and my scale based parameters TR into extra part and then

1226
00:48:13,309 --> 00:48:16,220
参数TR变成多余的部分，然后我让K这就是这种方式
parameters TR into extra part and then my let the K this is the way this is the

1227
00:48:16,220 --> 00:48:16,230
参数TR变成多余的部分，然后我让K这就是这种方式
my let the K this is the way this is the main Joint Distribution for this the

1228
00:48:16,230 --> 00:48:18,319
此条件的主要联合分配条件是我的X对XP等于1
my let the K this is the way this is the main Joint Distribution for this the

1229
00:48:18,319 --> 00:48:22,280
此条件的主要联合分配条件是我的X对XP等于1
main Joint Distribution for this the condition is that my X is 1 to XP you

1230
00:48:22,280 --> 00:48:22,290
此条件的主要联合分配条件是我的X对XP等于1
condition is that my X is 1 to XP you should follow this joint distribution

1231
00:48:22,290 --> 00:48:25,240
应该遵循这个联合分布，其中theta是我的分区
condition is that my X is 1 to XP you should follow this joint distribution

1232
00:48:25,240 --> 00:48:29,180
应该遵循这个联合分布，其中theta是我的分区
should follow this joint distribution where a of theta is my partition

1233
00:48:29,180 --> 00:48:29,190
应该遵循这个联合分布，其中theta是我的分区
where a of theta is my partition function and theta is my the no

1234
00:48:29,190 --> 00:48:35,000
函数和theta是我的no参数，抱歉此X参数和
where a of theta is my partition function and theta is my the no

1235
00:48:35,000 --> 00:48:37,430
函数和theta是我的no参数，抱歉此X参数和
function and theta is my the no parameter sorry this X parameter and the

1236
00:48:37,430 --> 00:48:37,440
函数和theta是我的no参数，抱歉此X参数和
parameter sorry this X parameter and the sweetest monitor is my parameter so yeah

1237
00:48:37,440 --> 00:48:41,480
最甜蜜的监视器是我的参数，所以从theta 1到theta P，所以我们的马尔代塔是
parameter sorry this X parameter and the sweetest monitor is my parameter so yeah

1238
00:48:41,480 --> 00:48:45,380
最甜蜜的监视器是我的参数，所以从theta 1到theta P，所以我们的马尔代塔是
sweetest monitor is my parameter so yeah theta 1 to theta P so we're maldita is

1239
00:48:45,380 --> 00:48:45,390
最甜蜜的监视器是我的参数，所以从theta 1到theta P，所以我们的马尔代塔是
theta 1 to theta P so we're maldita is the node parameter and the big theta is

1240
00:48:45,390 --> 00:48:47,720
node参数和大theta是我的订单Kappa theta是我的H参数
theta 1 to theta P so we're maldita is the node parameter and the big theta is

1241
00:48:47,720 --> 00:48:50,000
node参数和大theta是我的订单Kappa theta是我的H参数
the node parameter and the big theta is my order Kappa theta is my H parameter

1242
00:48:50,000 --> 00:48:50,010
node参数和大theta是我的订单Kappa theta是我的H参数
my order Kappa theta is my H parameter and your Peter make a lock partition

1243
00:48:50,010 --> 00:48:52,280
和你的彼得做一个锁分区功能，这表达在
my order Kappa theta is my H parameter and your Peter make a lock partition

1244
00:48:52,280 --> 00:48:54,579
和你的彼得做一个锁分区功能，这表达在
and your Peter make a lock partition function which is expressed in this

1245
00:48:54,579 --> 00:48:54,589
和你的彼得做一个锁分区功能，这表达在
function which is expressed in this equation ok

1246
00:48:54,589 --> 00:48:56,930
等式好了，现在这是一个简短的摘要，例如
function which is expressed in this equation ok

1247
00:48:56,930 --> 00:49:00,260
等式好了，现在这是一个简短的摘要，例如
equation ok so now this is a small brief like like

1248
00:49:00,260 --> 00:49:00,270
等式好了，现在这是一个简短的摘要，例如
so now this is a small brief like like we're going to say we're going to define

1249
00:49:00,270 --> 00:49:03,110
我们要说的是要根据这个指数定义X的P
so now this is a small brief like like we're going to say we're going to define

1250
00:49:03,110 --> 00:49:05,570
我们要说的是要根据这个指数定义X的P
we're going to say we're going to define this P of X in terms of this exponential

1251
00:49:05,570 --> 00:49:05,580
我们要说的是要根据这个指数定义X的P
this P of X in terms of this exponential family expression so where B of X is

1252
00:49:05,580 --> 00:49:08,330
家庭表达，所以X的B就是足够的统计量
this P of X in terms of this exponential family expression so where B of X is

1253
00:49:08,330 --> 00:49:09,830
家庭表达，所以X的B就是足够的统计量
family expression so where B of X is nothing but when sufficient statistic

1254
00:49:09,830 --> 00:49:09,840
家庭表达，所以X的B就是足够的统计量
nothing but when sufficient statistic this is my base parameter and a of theta

1255
00:49:09,840 --> 00:49:12,710
这是我的基本参数，theta的a是我的分区函数，这个内部
nothing but when sufficient statistic this is my base parameter and a of theta

1256
00:49:12,710 --> 00:49:15,680
这是我的基本参数，theta的a是我的分区函数，这个内部
this is my base parameter and a of theta is my partition function and this inner

1257
00:49:15,680 --> 00:49:15,690
这是我的基本参数，theta的a是我的分区函数，这个内部
is my partition function and this inner product I define it in this fashion okay

1258
00:49:15,690 --> 00:49:19,700
我以这种方式定义产品好吗
is my partition function and this inner product I define it in this fashion okay

1259
00:49:19,700 --> 00:49:20,770
所以下一个重要的事情是在一个节点上发生了什么
is my partition function and this inner product I define it in this fashion okay

1260
00:49:20,770 --> 00:49:20,780
所以下一个重要的事情是在一个节点上发生了什么


1261
00:49:20,780 --> 00:49:27,440
所以下一个重要的事情是在一个节点上发生了什么
so the next important thing is what happens at one node so one a conditional

1262
00:49:27,440 --> 00:49:27,450
所以下一个重要的事情是在一个节点上发生了什么
happens at one node so one a conditional distribution what happens so a node

1263
00:49:27,450 --> 00:49:29,690
分布发生了什么，因此给定节点X的节点条件分布是
happens at one node so one a conditional distribution what happens so a node

1264
00:49:29,690 --> 00:49:33,100
分布发生了什么，因此给定节点X的节点条件分布是
distribution what happens so a node condition distribution given node X are

1265
00:49:33,100 --> 00:49:33,110
分布发生了什么，因此给定节点X的节点条件分布是
condition distribution given node X are given all my known condition on may all

1266
00:49:33,110 --> 00:49:36,380
鉴于我所有已知的条件，可能只有前面提到的，您的V
condition distribution given node X are given all my known condition on may all

1267
00:49:36,380 --> 00:49:38,600
鉴于我所有已知的条件，可能只有前面提到的，您的V
given all my known condition on may all only previous notes that V of you'll

1268
00:49:38,600 --> 00:49:38,610
鉴于我所有已知的条件，可能只有前面提到的，您的V
only previous notes that V of you'll know that it's an exponential

1269
00:49:38,610 --> 00:49:39,440
知道这是一个指数族
only previous notes that V of you'll know that it's an exponential

1270
00:49:39,440 --> 00:49:41,750
知道这是一个指数族
know that it's an exponential exponential family is given by this

1271
00:49:41,750 --> 00:49:41,760
知道这是一个指数族
exponential family is given by this expression and I don't have a of beta

1272
00:49:41,760 --> 00:49:43,280
表达式，我没有beta，因为我放弃了比例
exponential family is given by this expression and I don't have a of beta

1273
00:49:43,280 --> 00:49:44,690
表达式，我没有beta，因为我放弃了比例
expression and I don't have a of beta because I have given up proportional

1274
00:49:44,690 --> 00:49:44,700
表达式，我没有beta，因为我放弃了比例
because I have given up proportional sign here where my sufficient statistics

1275
00:49:44,700 --> 00:49:46,910
在这里签名，我足够的统计信息就是这些变量和这些变量
because I have given up proportional sign here where my sufficient statistics

1276
00:49:46,910 --> 00:49:50,870
在这里签名，我足够的统计信息就是这些变量和这些变量
sign here where my sufficient statistics is just our these variables and these

1277
00:49:50,870 --> 00:49:50,880
在这里签名，我足够的统计信息就是这些变量和这些变量
is just our these variables and these values and base parameter of these

1278
00:49:50,880 --> 00:49:52,730
值和这些值的基本参数还可以，因为我们
is just our these variables and these values and base parameter of these

1279
00:49:52,730 --> 00:49:56,930
值和这些值的基本参数还可以，因为我们
values and base parameter of these values okay the reason why because we

1280
00:49:56,930 --> 00:49:56,940
值和这些值的基本参数还可以，因为我们
values okay the reason why because we are both we are doing node by node or

1281
00:49:56,940 --> 00:49:59,270
因为我们定义的是
values okay the reason why because we are both we are doing node by node or

1282
00:49:59,270 --> 00:50:02,060
因为我们定义的是
are both we are doing node by node or basis because of that I defined that the

1283
00:50:02,060 --> 00:50:02,070
因为我们定义的是
basis because of that I defined that the road condition institution okay next the

1284
00:50:02,070 --> 00:50:05,270
道路状况机构，接下来PMRF模型可以是民众贡献
basis because of that I defined that the road condition institution okay next the

1285
00:50:05,270 --> 00:50:07,520
道路状况机构，接下来PMRF模型可以是民众贡献
road condition institution okay next the PMRF model can is the populace tribution

1286
00:50:07,520 --> 00:50:07,530
道路状况机构，接下来PMRF模型可以是民众贡献
PMRF model can is the populace tribution which which can ranging from a

1287
00:50:07,530 --> 00:50:09,170
可以是均质的，也可以是混合的，然后是
PMRF model can is the populace tribution which which can ranging from a

1288
00:50:09,170 --> 00:50:11,660
可以是均质的，也可以是混合的，然后是
which which can ranging from a homogeneous to or mixed one and then

1289
00:50:11,660 --> 00:50:11,670
可以是均质的，也可以是混合的，然后是
homogeneous to or mixed one and then later from a node conditional

1290
00:50:11,670 --> 00:50:13,520
稍后从前面方程中的节点条件分布中，我们可以
homogeneous to or mixed one and then later from a node conditional

1291
00:50:13,520 --> 00:50:15,290
稍后从前面方程中的节点条件分布中，我们可以
later from a node conditional distribution in previous equation we can

1292
00:50:15,290 --> 00:50:15,300
稍后从前面方程中的节点条件分布中，我们可以
distribution in previous equation we can that we can design up

1293
00:50:15,300 --> 00:50:18,080
我们可以通过节点距离来设计一个节点的PMR
distribution in previous equation we can that we can design up

1294
00:50:18,080 --> 00:50:20,630
我们可以通过节点距离来设计一个节点的PMR
that we can design up PMR for a node by node distance by

1295
00:50:20,630 --> 00:50:20,640
我们可以通过节点距离来设计一个节点的PMR
PMR for a node by node distance by choosing a decide of my base parameter

1296
00:50:20,640 --> 00:50:23,000
选择我的基本参数和我在VR中的正式身份的决定，然后查看
PMR for a node by node distance by choosing a decide of my base parameter

1297
00:50:23,000 --> 00:50:25,880
选择我的基本参数和我在VR中的正式身份的决定，然后查看
choosing a decide of my base parameter and my official status in the VR and see

1298
00:50:25,880 --> 00:50:25,890
选择我的基本参数和我在VR中的正式身份的决定，然后查看
and my official status in the VR and see oh yeah putting still BR and my based

1299
00:50:25,890 --> 00:50:30,050
哦，是的，继续放置BR和基于我的度量TR，请注意，这是一个联合
and my official status in the VR and see oh yeah putting still BR and my based

1300
00:50:30,050 --> 00:50:34,370
哦，是的，继续放置BR和基于我的度量TR，请注意，这是一个联合
oh yeah putting still BR and my based measure TR and note that this is a joint

1301
00:50:34,370 --> 00:50:34,380
哦，是的，继续放置BR和基于我的度量TR，请注意，这是一个联合
measure TR and note that this is a joint this is valid if I am able to obtain a

1302
00:50:34,380 --> 00:50:37,190
如果我能够获得θ的y值，但是我的Lθ是
measure TR and note that this is a joint this is valid if I am able to obtain a

1303
00:50:37,190 --> 00:50:40,520
如果我能够获得θ的y值，但是我的Lθ是
this is valid if I am able to obtain a value for y of theta but my L theta is

1304
00:50:40,520 --> 00:50:40,530
如果我能够获得θ的y值，但是我的Lθ是
value for y of theta but my L theta is computationally intractable so the

1305
00:50:40,530 --> 00:50:42,740
计算上难以处理，所以我们选择近似对数的原因
value for y of theta but my L theta is computationally intractable so the

1306
00:50:42,740 --> 00:50:45,680
计算上难以处理，所以我们选择近似对数的原因
computationally intractable so the reason why we go for approximate log

1307
00:50:45,680 --> 00:50:45,690
计算上难以处理，所以我们选择近似对数的原因
reason why we go for approximate log likelihood okay so for example I don't

1308
00:50:45,690 --> 00:50:49,790
可能还好，例如，我不举一个通用的例子
reason why we go for approximate log likelihood okay so for example I don't

1309
00:50:49,790 --> 00:50:51,260
可能还好，例如，我不举一个通用的例子
likelihood okay so for example I don't give an example of a universal

1310
00:50:51,260 --> 00:50:51,270
可能还好，例如，我不举一个通用的例子
give an example of a universal distribution where are my

1311
00:50:51,270 --> 00:50:54,189
将我的Sigma分配到哪里-如果我的
give an example of a universal distribution where are my

1312
00:50:54,189 --> 00:52:00,699
将我的Sigma分配到哪里-如果我的
distribution where are my Sigma into the - and what happens if my

1313
00:52:00,699 --> 00:52:00,709
将我的Sigma分配到哪里-如果我的
Sigma into the - and what happens if my lambda is in a structured graph so and

1314
00:52:00,709 --> 00:52:04,519
lambda在结构化图中，因此在此我们使用惩罚，因此
Sigma into the - and what happens if my lambda is in a structured graph so and

1315
00:52:04,519 --> 00:52:08,509
lambda在结构化图中，因此在此我们使用惩罚，因此
lambda is in a structured graph so and again in this we use a penalty so this

1316
00:52:08,509 --> 00:52:08,519
lambda在结构化图中，因此在此我们使用惩罚，因此
again in this we use a penalty so this one have taken it from the mouse we book

1317
00:52:08,519 --> 00:52:10,819
我们从书中摘录了第23章，我相信这是一本
again in this we use a penalty so this one have taken it from the mouse we book

1318
00:52:10,819 --> 00:52:13,370
我们从书中摘录了第23章，我相信这是一本
one have taken it from the mouse we book chapter 23 I believe so this is an

1319
00:52:13,370 --> 00:52:13,380
我们从书中摘录了第23章，我相信这是一本
chapter 23 I believe so this is an example so my lambda is very high so it

1320
00:52:13,380 --> 00:52:16,669
例子，所以我的lambda很高，所以它在本质上非常稀疏，为此我
chapter 23 I believe so this is an example so my lambda is very high so it

1321
00:52:16,669 --> 00:52:18,919
例子，所以我的lambda很高，所以它在本质上非常稀疏，为此我
example so my lambda is very high so it is very sparse in nature and for this my

1322
00:52:18,919 --> 00:52:18,929
例子，所以我的lambda很高，所以它在本质上非常稀疏，为此我
is very sparse in nature and for this my lambda is equal to 0 so it is very dense

1323
00:52:18,929 --> 00:52:20,689
lambda等于0，所以它在本质上非常密集，因此我的lambda给了我一个非常
is very sparse in nature and for this my lambda is equal to 0 so it is very dense

1324
00:52:20,689 --> 00:52:23,269
lambda等于0，所以它在本质上非常密集，因此我的lambda给了我一个非常
lambda is equal to 0 so it is very dense in nature so my lambda gives me a very

1325
00:52:23,269 --> 00:52:23,279
lambda等于0，所以它在本质上非常密集，因此我的lambda给了我一个非常
in nature so my lambda gives me a very big spectrum of my specificity okay so

1326
00:52:23,279 --> 00:52:28,969
我的特异性范围很大，所以下一个亲本是大概的
in nature so my lambda gives me a very big spectrum of my specificity okay so

1327
00:52:28,969 --> 00:52:30,829
我的特异性范围很大，所以下一个亲本是大概的
big spectrum of my specificity okay so next a parent thing is the approximate

1328
00:52:30,829 --> 00:52:30,839
我的特异性范围很大，所以下一个亲本是大概的
next a parent thing is the approximate maximum like you know make you so we go

1329
00:52:30,839 --> 00:52:36,319
像你知道的那样使你最大化，所以我们去赢利，因为theta值很高
next a parent thing is the approximate maximum like you know make you so we go

1330
00:52:36,319 --> 00:52:37,999
像你知道的那样使你最大化，所以我们去赢利，因为theta值很高
maximum like you know make you so we go for a profit because a of theta as high

1331
00:52:37,999 --> 00:52:38,009
像你知道的那样使你最大化，所以我们去赢利，因为theta值很高
for a profit because a of theta as high dimensional integral and it's typically

1332
00:52:38,009 --> 00:52:39,949
尺寸积分，它通常是棘手的，为了做到这一点，我们
for a profit because a of theta as high dimensional integral and it's typically

1333
00:52:39,949 --> 00:52:44,259
尺寸积分，它通常是棘手的，为了做到这一点，我们
dimensional integral and it's typically intractable and in order to do this we

1334
00:52:44,259 --> 00:52:44,269
尺寸积分，它通常是棘手的，为了做到这一点，我们
intractable and in order to do this we replace your theta with intractable or

1335
00:52:44,269 --> 00:52:47,479
用难以解决的或凸出的theta值代替您的theta或为我
intractable and in order to do this we replace your theta with intractable or

1336
00:52:47,479 --> 00:52:50,509
用难以解决的或凸出的theta值代替您的theta或为我
replace your theta with intractable or convex upper value of theta or for my

1337
00:52:50,509 --> 00:52:50,519
用难以解决的或凸出的theta值代替您的theta或为我
convex upper value of theta or for my problem for proceeding for me to obtain

1338
00:52:50,519 --> 00:52:54,979
让我着手获得theta的T Tauri的价值的问题，因此
convex upper value of theta or for my problem for proceeding for me to obtain

1339
00:52:54,979 --> 00:52:57,859
让我着手获得theta的T Tauri的价值的问题，因此
problem for proceeding for me to obtain our value for U of T Tauri of theta so

1340
00:52:57,859 --> 00:52:57,869
让我着手获得theta的T Tauri的价值的问题，因此
our value for U of T Tauri of theta so we need we need to recall all

1341
00:52:57,869 --> 00:53:00,450
我们需要回忆起所有的耐心，因为从我的意思是
our value for U of T Tauri of theta so we need we need to recall all

1342
00:53:00,450 --> 00:53:07,140
我们需要回忆起所有的耐心，因为从我的意思是
we need we need to recall all patience because from the I mean a

1343
00:53:07,140 --> 00:53:07,150
我们需要回忆起所有的耐心，因为从我的意思是
patience because from the I mean a different paper so in order to have a

1344
00:53:07,150 --> 00:53:11,010
不同的纸张，以便具有紧凑的符号
patience because from the I mean a different paper so in order to have a

1345
00:53:11,010 --> 00:53:12,030
不同的纸张，以便具有紧凑的符号
different paper so in order to have a compact notation

1346
00:53:12,030 --> 00:53:12,040
不同的纸张，以便具有紧凑的符号
compact notation I just recall everything again so theta

1347
00:53:12,040 --> 00:53:14,040
我只是再次回忆起一切，所以theta是我的自然参数，成为您的
compact notation I just recall everything again so theta

1348
00:53:14,040 --> 00:53:15,810
我只是再次回忆起一切，所以theta是我的自然参数，成为您的
I just recall everything again so theta is my natural parameter and be your

1349
00:53:15,810 --> 00:53:15,820
我只是再次回忆起一切，所以theta是我的自然参数，成为您的
is my natural parameter and be your purchase my sufficient statistics and

1350
00:53:15,820 --> 00:53:18,320
购买我足够的统计信息，它在此域中，也包括我的内部
is my natural parameter and be your purchase my sufficient statistics and

1351
00:53:18,320 --> 00:53:21,240
购买我足够的统计信息，它在此域中，也包括我的内部
purchase my sufficient statistics and it's in this domain and also my inner

1352
00:53:21,240 --> 00:53:21,250
购买我足够的统计信息，它在此域中，也包括我的内部
it's in this domain and also my inner product is expressed in this fashion

1353
00:53:21,250 --> 00:53:22,680
产品以这种方式表达，我们都记得几张幻灯片
it's in this domain and also my inner product is expressed in this fashion

1354
00:53:22,680 --> 00:53:26,070
产品以这种方式表达，我们都记得几张幻灯片
product is expressed in this fashion which we all remember few slides back

1355
00:53:26,070 --> 00:53:26,080
产品以这种方式表达，我们都记得几张幻灯片
which we all remember few slides back and also here the new thing is we're

1356
00:53:26,080 --> 00:53:28,140
这也是我们要在其中定义均值参数的新事物
which we all remember few slides back and also here the new thing is we're

1357
00:53:28,140 --> 00:53:31,230
这也是我们要在其中定义均值参数的新事物
and also here the new thing is we're going to define the mean parameters in

1358
00:53:31,230 --> 00:53:31,240
这也是我们要在其中定义均值参数的新事物
going to define the mean parameters in this fashion and this is for my for my

1359
00:53:31,240 --> 00:53:35,670
这种时尚，这是我的优势，主要的是我的优势，我的优势
going to define the mean parameters in this fashion and this is for my for my

1360
00:53:35,670 --> 00:53:38,160
这种时尚，这是我的优势，主要的是我的优势，我的优势
this fashion and this is for my for my edge so main one is for my edge and my

1361
00:53:38,160 --> 00:53:38,170
这种时尚，这是我的优势，主要的是我的优势，我的优势
edge so main one is for my edge and my expectation of the VR of X is nothing

1362
00:53:38,170 --> 00:53:40,109
对X的VR的期望不过是我的mu R，对于
edge so main one is for my edge and my expectation of the VR of X is nothing

1363
00:53:40,109 --> 00:53:43,050
对X的VR的期望不过是我的mu R，对于
expectation of the VR of X is nothing but my mu R and for the similarly for

1364
00:53:43,050 --> 00:53:43,060
对X的VR的期望不过是我的mu R，对于
but my mu R and for the similarly for the S parameter and also one more

1365
00:53:43,060 --> 00:53:45,660
S参数，还有一个更重要的事情是您将
but my mu R and for the similarly for the S parameter and also one more

1366
00:53:45,660 --> 00:53:46,920
S参数，还有一个更重要的事情是您将
the S parameter and also one more important thing is you are going to

1367
00:53:46,920 --> 00:53:46,930
S参数，还有一个更重要的事情是您将
important thing is you are going to express it and the Google map the for

1368
00:53:46,930 --> 00:53:52,230
表示它，然后Google将该节点的X参数与X映射为
important thing is you are going to express it and the Google map the for

1369
00:53:52,230 --> 00:53:55,079
表示它，然后Google将该节点的X参数与X映射为
express it and the Google map the for the node and the X parameter with the in

1370
00:53:55,079 --> 00:53:55,089
表示它，然后Google将该节点的X参数与X映射为
the node and the X parameter with the in this matrix okay the reason I mentioned

1371
00:53:55,089 --> 00:54:00,839
这个矩阵好吧，我之所以提到它，是因为在本书和
the node and the X parameter with the in this matrix okay the reason I mentioned

1372
00:54:00,839 --> 00:54:02,190
这个矩阵好吧，我之所以提到它，是因为在本书和
this matrix okay the reason I mentioned it because in this book and the

1373
00:54:02,190 --> 00:54:02,200
这个矩阵好吧，我之所以提到它，是因为在本书和
it because in this book and the surrealist paper

1374
00:54:02,200 --> 00:54:02,880
超现实主义的纸乔丹纸，他为
it because in this book and the surrealist paper

1375
00:54:02,880 --> 00:54:06,480
超现实主义的纸乔丹纸，他为
surrealist paper Jordan paper he gives an expression for

1376
00:54:06,480 --> 00:54:06,490
超现实主义的纸乔丹纸，他为
Jordan paper he gives an expression for the upper bound the lock partition

1377
00:54:06,490 --> 00:54:08,760
theta的锁分区功能的上限如下
Jordan paper he gives an expression for the upper bound the lock partition

1378
00:54:08,760 --> 00:54:09,960
theta的锁分区功能的上限如下
the upper bound the lock partition function of theta has the following

1379
00:54:09,960 --> 00:54:09,970
theta的锁分区功能的上限如下
function of theta has the following upper bound and here the same notations

1380
00:54:09,970 --> 00:54:13,050
上限和相同的符号，此处使用的是不同的报告
function of theta has the following upper bound and here the same notations

1381
00:54:13,050 --> 00:54:15,329
上限和相同的符号，此处使用的是不同的报告
upper bound and here the same notations what a different report is used here in

1382
00:54:15,329 --> 00:54:15,339
上限和相同的符号，此处使用的是不同的报告
what a different report is used here in this paper and this is just a brief

1383
00:54:15,339 --> 00:54:19,109
这篇论文，这只是对他如何获得此的简要说明
what a different report is used here in this paper and this is just a brief

1384
00:54:19,109 --> 00:54:21,480
这篇论文，这只是对他如何获得此的简要说明
this paper and this is just a brief explanation of how he has obtained this

1385
00:54:21,480 --> 00:54:21,490
这篇论文，这只是对他如何获得此的简要说明
explanation of how he has obtained this one so in particularly we obtain the

1386
00:54:21,490 --> 00:54:23,250
因此，特别是我们获得了
explanation of how he has obtained this one so in particularly we obtain the

1387
00:54:23,250 --> 00:54:25,109
因此，特别是我们获得了
one so in particularly we obtain the upper bound relationship between the

1388
00:54:25,109 --> 00:54:25,119
因此，特别是我们获得了
upper bound relationship between the entropy H of X and the entropy of the

1389
00:54:25,119 --> 00:54:26,670
X的熵H和由此得到的结点势的熵
upper bound relationship between the entropy H of X and the entropy of the

1390
00:54:26,670 --> 00:54:29,609
X的熵H和由此得到的结点势的熵
entropy H of X and the entropy of the node potential given by this in addition

1391
00:54:29,609 --> 00:54:29,619
X的熵H和由此得到的结点势的熵
node potential given by this in addition to the different choices of L R where R

1392
00:54:29,619 --> 00:54:32,010
到LR的不同选择，因为我在Pino中有R
node potential given by this in addition to the different choices of L R where R

1393
00:54:32,010 --> 00:54:34,380
到LR的不同选择，因为我在Pino中有R
to the different choices of L R where R because I have in my Pino does this

1394
00:54:34,380 --> 00:54:34,390
到LR的不同选择，因为我在Pino中有R
because I have in my Pino does this thing so it's goes from R 1 to P 4 or

1395
00:54:34,390 --> 00:54:37,230
所以它是从R 1到P 4或异构域，所以我有这个
because I have in my Pino does this thing so it's goes from R 1 to P 4 or

1396
00:54:37,230 --> 00:54:40,070
所以它是从R 1到P 4或异构域，所以我有这个
thing so it's goes from R 1 to P 4 or heterogeneous domains so I have this

1397
00:54:40,070 --> 00:54:40,080
所以它是从R 1到P 4或异构域，所以我有这个
heterogeneous domains so I have this expression for a of theta now is by

1398
00:54:40,080 --> 00:54:44,490
现在表达the theta是通过奉献这个双重的你
heterogeneous domains so I have this expression for a of theta now is by

1399
00:54:44,490 --> 00:54:46,230
现在表达the theta是通过奉献这个双重的你
expression for a of theta now is by taking the dedication of this dual you

1400
00:54:46,230 --> 00:54:46,240
现在表达the theta是通过奉献这个双重的你
taking the dedication of this dual you can convert this high dimension problem

1401
00:54:46,240 --> 00:54:47,520
可以根据上述定理转换这个高维问题，即
taking the dedication of this dual you can convert this high dimension problem

1402
00:54:47,520 --> 00:54:49,829
可以根据上述定理转换这个高维问题，即
can convert this high dimension problem from the above theorem and that is

1403
00:54:49,829 --> 00:54:49,839
可以根据上述定理转换这个高维问题，即
from the above theorem and that is orderable mention equation to the

1404
00:54:49,839 --> 00:54:51,240
可调用提及形式或可处理形式的有序提及方程，以便
from the above theorem and that is orderable mention equation to the

1405
00:54:51,240 --> 00:54:54,420
可调用提及形式或可处理形式的有序提及方程，以便
orderable mention equation to the calling or tractable form so that the

1406
00:54:54,420 --> 00:54:54,430
可调用提及形式或可处理形式的有序提及方程，以便
calling or tractable form so that the same expression we can write in this

1407
00:54:54,430 --> 00:54:57,150
我们可以在其中写出相同的表达式，其中F表示为2
calling or tractable form so that the same expression we can write in this

1408
00:54:57,150 --> 00:54:59,400
我们可以在其中写出相同的表达式，其中F表示为2
same expression we can write in this where F of 2 is expressed in the

1409
00:54:59,400 --> 00:54:59,410
我们可以在其中写出相同的表达式，其中F表示为2
where F of 2 is expressed in the equation here later we are going to plug

1410
00:54:59,410 --> 00:55:03,690
等式在这里，我们将插入theta到主
where F of 2 is expressed in the equation here later we are going to plug

1411
00:55:03,690 --> 00:55:05,550
等式在这里，我们将插入theta到主
equation here later we are going to plug in this a of theta into the main

1412
00:55:05,550 --> 00:55:05,560
等式在这里，我们将插入theta到主
in this a of theta into the main equation here

1413
00:55:05,560 --> 00:55:08,280
等式在这里
in this a of theta into the main equation here

1414
00:55:08,280 --> 00:55:08,880
进入这里的主要方程式，然后对其进行简化，我们得到
in this a of theta into the main equation here

1415
00:55:08,880 --> 00:55:08,890
进入这里的主要方程式，然后对其进行简化，我们得到


1416
00:55:08,890 --> 00:55:14,350
进入这里的主要方程式，然后对其进行简化，我们得到
into the main equation here and then later simplifying it we obtain this

1417
00:55:14,350 --> 00:55:14,360
进入这里的主要方程式，然后对其进行简化，我们得到
later simplifying it we obtain this optimization problem available to

1418
00:55:14,360 --> 00:55:16,210
优化问题可用于最小化此问题，这是我的问题
later simplifying it we obtain this optimization problem available to

1419
00:55:16,210 --> 00:55:17,980
优化问题可用于最小化此问题，这是我的问题
optimization problem available to minimize this and where this is my

1420
00:55:17,980 --> 00:55:17,990
优化问题可用于最小化此问题，这是我的问题
minimize this and where this is my different matrix we have a theta belongs

1421
00:55:17,990 --> 00:55:20,200
我们有一个theta属于不同的矩阵，这个表达式什么都不是
minimize this and where this is my different matrix we have a theta belongs

1422
00:55:20,200 --> 00:55:23,440
我们有一个theta属于不同的矩阵，这个表达式什么都不是
different matrix we have a theta belongs to and this this expression is nothing

1423
00:55:23,440 --> 00:55:23,450
我们有一个theta属于不同的矩阵，这个表达式什么都不是
to and this this expression is nothing but the expression that we had observed

1424
00:55:23,450 --> 00:55:25,390
但是我们昨天在科迪·贝克（Cody Baker）解释时所观察到的表情
to and this this expression is nothing but the expression that we had observed

1425
00:55:25,390 --> 00:55:30,190
但是我们昨天在科迪·贝克（Cody Baker）解释时所观察到的表情
but the expression that we had observed when Cody Baker explained that yesterday

1426
00:55:30,190 --> 00:55:30,200
但是我们昨天在科迪·贝克（Cody Baker）解释时所观察到的表情
when Cody Baker explained that yesterday yesterday afternoon so when he explained

1427
00:55:30,200 --> 00:55:32,340
昨天下午，所以当他向这个小组解释图形时，昨天
when Cody Baker explained that yesterday yesterday afternoon so when he explained

1428
00:55:32,340 --> 00:55:36,790
昨天下午，所以当他向这个小组解释图形时，昨天
yesterday afternoon so when he explained this group graphical so yesterday so

1429
00:55:36,790 --> 00:55:36,800
昨天下午，所以当他向这个小组解释图形时，昨天
this group graphical so yesterday so this is something similar to that so to

1430
00:55:36,800 --> 00:55:39,610
这与之类似，因此要使其分组，所以我们要做的是
this group graphical so yesterday so this is something similar to that so to

1431
00:55:39,610 --> 00:55:43,480
这与之类似，因此要使其分组，所以我们要做的是
this is something similar to that so to make it group so what we do is we for a

1432
00:55:43,480 --> 00:55:43,490
这与之类似，因此要使其分组，所以我们要做的是
make it group so what we do is we for a zero-mean graph a Gaussian amara with

1433
00:55:43,490 --> 00:55:45,550
零均值图具有附加约束的高斯阿玛拉
make it group so what we do is we for a zero-mean graph a Gaussian amara with

1434
00:55:45,550 --> 00:55:48,850
零均值图具有附加约束的高斯阿玛拉
zero-mean graph a Gaussian amara with additional constraint that is

1435
00:55:48,850 --> 00:55:50,400
有条件地独立，那么我们要做的是研究为0，在这种情况下
zero-mean graph a Gaussian amara with additional constraint that is

1436
00:55:50,400 --> 00:55:50,410
有条件地独立，那么我们要做的是研究为0，在这种情况下


1437
00:55:50,410 --> 00:55:57,880
有条件地独立，那么我们要做的是研究为0，在这种情况下
conditionally independent then what we do is we study to 0 and in that case

1438
00:55:57,880 --> 00:55:57,890
有条件地独立，那么我们要做的是研究为0，在这种情况下
do is we study to 0 and in that case profit is equal to the graphical Rezo

1439
00:55:57,890 --> 00:55:59,500
利润等于图形Rezo，但
do is we study to 0 and in that case profit is equal to the graphical Rezo

1440
00:55:59,500 --> 00:56:01,360
利润等于图形Rezo，但
profit is equal to the graphical Rezo but there's one difference in the

1441
00:56:01,360 --> 00:56:01,370
利润等于图形Rezo，但
but there's one difference in the optimization procedure what he or what

1442
00:56:01,370 --> 00:56:03,520
优化过程他或他遵循的内容以及遵循的内容
but there's one difference in the optimization procedure what he or what

1443
00:56:03,520 --> 00:56:04,990
优化过程他或他遵循的内容以及遵循的内容
optimization procedure what he or what he has followed and what is followed

1444
00:56:04,990 --> 00:56:05,000
优化过程他或他遵循的内容以及遵循的内容
he has followed and what is followed here in that the graphical ticket

1445
00:56:05,000 --> 00:56:08,470
这是因为图形凭单相对于
he has followed and what is followed here in that the graphical ticket

1446
00:56:08,470 --> 00:56:10,630
这是因为图形凭单相对于
here in that the graphical ticket optimizes you with respect to the

1447
00:56:10,630 --> 00:56:10,640
这是因为图形凭单相对于
optimizes you with respect to the empirical covariance matrix but in our

1448
00:56:10,640 --> 00:56:12,940
经验协方差矩阵，但是在我们的情况下或我们要做的是
optimizes you with respect to the empirical covariance matrix but in our

1449
00:56:12,940 --> 00:56:15,010
经验协方差矩阵，但是在我们的情况下或我们要做的是
empirical covariance matrix but in our case or what we do is we optimize with

1450
00:56:15,010 --> 00:56:15,020
经验协方差矩阵，但是在我们的情况下或我们要做的是
case or what we do is we optimize with respect to using the sample average of

1451
00:56:15,020 --> 00:56:17,260
关于使用EMR的足够统计量的样本平均值
case or what we do is we optimize with respect to using the sample average of

1452
00:56:17,260 --> 00:56:19,600
关于使用EMR的足够统计量的样本平均值
respect to using the sample average of the sufficient statistics of the EMRs

1453
00:56:19,600 --> 00:56:19,610
关于使用EMR的足够统计量的样本平均值
the sufficient statistics of the EMRs those things we are talking about the

1454
00:56:19,610 --> 00:56:21,720
我们正在谈论的有关优化过程的那些事情
the sufficient statistics of the EMRs those things we are talking about the

1455
00:56:21,720 --> 00:56:26,040
我们正在谈论的有关优化过程的那些事情
those things we are talking about the optimization procedure we are going to

1456
00:56:26,040 --> 00:56:26,050
我们正在谈论的有关优化过程的那些事情
optimization procedure we are going to this alternating direction or method of

1457
00:56:26,050 --> 00:56:29,290
这个交替的方向或乘数的方法，我只是给你一个简短的
optimization procedure we are going to this alternating direction or method of

1458
00:56:29,290 --> 00:56:32,970
这个交替的方向或乘数的方法，我只是给你一个简短的
this alternating direction or method of multipliers and I just give you a brief

1459
00:56:32,970 --> 00:56:32,980
这个交替的方向或乘数的方法，我只是给你一个简短的
multipliers and I just give you a brief explanation of what DMMs and then and

1460
00:56:32,980 --> 00:56:37,150
解释什么数字万用表，然后再解释一下
multipliers and I just give you a brief explanation of what DMMs and then and

1461
00:56:37,150 --> 00:56:41,530
解释什么数字万用表，然后再解释一下
explanation of what DMMs and then and then explain again like how the being

1462
00:56:41,530 --> 00:56:41,540
解释什么数字万用表，然后再解释一下
then explain again like how the being implemented so this is just a small

1463
00:56:41,540 --> 00:56:44,440
实现，所以这只是一个小小的解释和算法，
then explain again like how the being implemented so this is just a small

1464
00:56:44,440 --> 00:56:48,220
实现，所以这只是一个小小的解释和算法，
implemented so this is just a small explanation and algorithm which also

1465
00:56:48,220 --> 00:56:48,230
实现，所以这只是一个小小的解释和算法，
explanation and algorithm which also complex optimization problem by breaking

1466
00:56:48,230 --> 00:56:50,020
通过分解成较小的部分可以解决复杂的优化问题
explanation and algorithm which also complex optimization problem by breaking

1467
00:56:50,020 --> 00:56:52,990
通过分解成较小的部分可以解决复杂的优化问题
complex optimization problem by breaking into smaller pieces each other which can

1468
00:56:52,990 --> 00:56:53,000
通过分解成较小的部分可以解决复杂的优化问题
into smaller pieces each other which can easily then be handled example it is

1469
00:56:53,000 --> 00:56:55,870
容易然后被处理的示例，这被认为是客观的
into smaller pieces each other which can easily then be handled example it is

1470
00:56:55,870 --> 00:56:57,520
容易然后被处理的示例，这被认为是客观的
easily then be handled example it is considered this would be objective

1471
00:56:57,520 --> 00:56:57,530
容易然后被处理的示例，这被认为是客观的
considered this would be objective function we have to minimize this

1472
00:56:57,530 --> 00:56:59,350
函数我们必须最小化X的目标函数f加上Z的G
considered this would be objective function we have to minimize this

1473
00:56:59,350 --> 00:57:01,030
函数我们必须最小化X的目标函数f加上Z的G
function we have to minimize this objective function f of X plus G of Z

1474
00:57:01,030 --> 00:57:01,040
函数我们必须最小化X的目标函数f加上Z的G
objective function f of X plus G of Z and we have to design variables

1475
00:57:01,040 --> 00:57:02,890
我们必须设计变量X和Z
objective function f of X plus G of Z and we have to design variables

1476
00:57:02,890 --> 00:57:05,170
我们必须设计变量X和Z
and we have to design variables X and Z which is subjected to a

1477
00:57:05,170 --> 00:57:05,180
我们必须设计变量X和Z
X and Z which is subjected to a constraint that is our 8 plus B Z equals

1478
00:57:05,180 --> 00:57:07,960
我们的8加BZ等于T的约束，现在我们定义一个参数a
X and Z which is subjected to a constraint that is our 8 plus B Z equals

1479
00:57:07,960 --> 00:57:10,750
我们的8加BZ等于T的约束，现在我们定义一个参数a
constraint that is our 8 plus B Z equals T and now we define an argument a

1480
00:57:10,750 --> 00:57:10,760
我们的8加BZ等于T的约束，现在我们定义一个参数a
T and now we define an argument a Lagrangian with the three parameter Rho

1481
00:57:10,760 --> 00:57:12,730
拉格朗日的三个参数Rho或刚好大于零，我们说
T and now we define an argument a Lagrangian with the three parameter Rho

1482
00:57:12,730 --> 00:57:15,430
拉格朗日的三个参数Rho或刚好大于零，我们说
Lagrangian with the three parameter Rho or just greater than zero and we say

1483
00:57:15,430 --> 00:57:15,440
拉格朗日的三个参数Rho或刚好大于零，我们说
or just greater than zero and we say that is nothing but the objective

1484
00:57:15,440 --> 00:57:19,240
那不过是目标函数加上这个的uu转置而已
or just greater than zero and we say that is nothing but the objective

1485
00:57:19,240 --> 00:57:22,440
那不过是目标函数加上这个的uu转置而已
that is nothing but the objective function plus u u transpose of this

1486
00:57:22,440 --> 00:57:22,450
那不过是目标函数加上这个的uu转置而已
function plus u u transpose of this constraint here plus my LP parameter to

1487
00:57:22,450 --> 00:57:25,540
这里的约束加上我的LP参数到规范，我们为X更新了
function plus u u transpose of this constraint here plus my LP parameter to

1488
00:57:25,540 --> 00:57:32,890
这里的约束加上我的LP参数到规范，我们为X更新了
constraint here plus my LP parameter to the norm and what we do we update X for

1489
00:57:32,890 --> 00:57:32,900
这里的约束加上我的LP参数到规范，我们为X更新了
the norm and what we do we update X for updating X we take the value of Z of the

1490
00:57:32,900 --> 00:57:35,350
更新X时，我们将获取先前剪辑的Z值，而您将获取先前剪辑的Z值
the norm and what we do we update X for updating X we take the value of Z of the

1491
00:57:35,350 --> 00:57:36,880
更新X时，我们将获取先前剪辑的Z值，而您将获取先前剪辑的Z值
updating X we take the value of Z of the previous clip and you of the previous

1492
00:57:36,880 --> 00:57:36,890
更新X时，我们将获取先前剪辑的Z值，而您将获取先前剪辑的Z值
previous clip and you of the previous clip and then later or we update Z when

1493
00:57:36,890 --> 00:57:40,870
剪辑，然后稍后进行更新，或者当我们更新Z时我们更新Z我们取更新后的值
previous clip and you of the previous clip and then later or we update Z when

1494
00:57:40,870 --> 00:57:43,990
剪辑，然后稍后进行更新，或者当我们更新Z时我们更新Z我们取更新后的值
clip and then later or we update Z when we updating Z we take the updated value

1495
00:57:43,990 --> 00:57:44,000
剪辑，然后稍后进行更新，或者当我们更新Z时我们更新Z我们取更新后的值
we updating Z we take the updated value of x and then we update we update the D

1496
00:57:44,000 --> 00:57:48,460
的x，然后我们更新，我们更新了D，但我们没有开发更新
we updating Z we take the updated value of x and then we update we update the D

1497
00:57:48,460 --> 00:57:50,260
的x，然后我们更新，我们更新了D，但我们没有开发更新
of x and then we update we update the D but we we do not have the update develop

1498
00:57:50,260 --> 00:57:50,270
的x，然后我们更新，我们更新了D，但我们没有开发更新
but we we do not have the update develop view so we are using the previous

1499
00:57:50,270 --> 00:57:51,850
视图，所以我们在这里使用以前的更新值，然后我们得到
but we we do not have the update develop view so we are using the previous

1500
00:57:51,850 --> 00:57:53,860
视图，所以我们在这里使用以前的更新值，然后我们得到
view so we are using the previous updated value here and later we get the

1501
00:57:53,860 --> 00:57:53,870
视图，所以我们在这里使用以前的更新值，然后我们得到
updated value here and later we get the closed form or solution with with with

1502
00:57:53,870 --> 00:57:57,130
在此处带有此表达式的封闭形式或解决方案，这就是原因
updated value here and later we get the closed form or solution with with with

1503
00:57:57,130 --> 00:57:59,650
在此处带有此表达式的封闭形式或解决方案，这就是原因
closed form or solution with with with this expression here and that is reason

1504
00:57:59,650 --> 00:57:59,660
在此处带有此表达式的封闭形式或解决方案，这就是原因
this expression here and that is reason why it is known as alternating direction

1505
00:57:59,660 --> 00:58:01,660
为什么将其称为交变方向，因为我们为X做它，然后为
this expression here and that is reason why it is known as alternating direction

1506
00:58:01,660 --> 00:58:04,660
为什么将其称为交变方向，因为我们为X做它，然后为
why it is known as alternating direction because we do it for X then we do it for

1507
00:58:04,660 --> 00:58:04,670
为什么将其称为交变方向，因为我们为X做它，然后为
because we do it for X then we do it for Z and then we do it again at last for

1508
00:58:04,670 --> 00:58:06,640
Z，然后我们再次针对英国的封闭式解决方案再次进行操作，我是说，
because we do it for X then we do it for Z and then we do it again at last for

1509
00:58:06,640 --> 00:58:10,180
Z，然后我们再次针对英国的封闭式解决方案再次进行操作，我是说，
Z and then we do it again at last for closed form solution for UK I mean so we

1510
00:58:10,180 --> 00:58:10,190
Z，然后我们再次针对英国的封闭式解决方案再次进行操作，我是说，
closed form solution for UK I mean so we do it until the stop criterion is

1511
00:58:10,190 --> 00:58:12,790
这样做直到提到停止标准为止，所以通常这样
closed form solution for UK I mean so we do it until the stop criterion is

1512
00:58:12,790 --> 00:58:15,370
这样做直到提到停止标准为止，所以通常这样
do it until the stop criterion is mentioned so this is in general so

1513
00:58:15,370 --> 00:58:15,380
这样做直到提到停止标准为止，所以通常这样
mentioned so this is in general so basically we have to update these three

1514
00:58:15,380 --> 00:58:17,200
基本上，我们必须更新这三个参数才能解决此问题
mentioned so this is in general so basically we have to update these three

1515
00:58:17,200 --> 00:58:19,900
基本上，我们必须更新这三个参数才能解决此问题
basically we have to update these three parameters coming back to this problem

1516
00:58:19,900 --> 00:58:19,910
基本上，我们必须更新这三个参数才能解决此问题
parameters coming back to this problem here we dated again saying that we have

1517
00:58:19,910 --> 00:58:23,380
在这里，我们再次约会，说我们必须将其最小化，然后您再次说
parameters coming back to this problem here we dated again saying that we have

1518
00:58:23,380 --> 00:58:25,780
在这里，我们再次约会，说我们必须将其最小化，然后您再次说
here we dated again saying that we have to minimize this and again you say that

1519
00:58:25,780 --> 00:58:25,790
在这里，我们再次约会，说我们必须将其最小化，然后您再次说
to minimize this and again you say that we have to update three things theta big

1520
00:58:25,790 --> 00:58:28,320
我们必须更新theta big的三件事，而您则是同一件事，但对于
to minimize this and again you say that we have to update three things theta big

1521
00:58:28,320 --> 00:58:31,300
我们必须更新theta big的三件事，而您则是同一件事，但对于
we have to update three things theta big and you it is the same thing but for

1522
00:58:31,300 --> 00:58:31,310
我们必须更新theta big的三件事，而您则是同一件事，但对于
and you it is the same thing but for this problem we prom late top-40 to

1523
00:58:31,310 --> 00:58:34,540
这个问题我们会向前40名舞会进行更新，这是eta的公式
and you it is the same thing but for this problem we prom late top-40 to

1524
00:58:34,540 --> 00:58:37,030
这个问题我们会向前40名舞会进行更新，这是eta的公式
this problem we prom late top-40 to update this is the formulation where eta

1525
00:58:37,030 --> 00:58:37,040
这个问题我们会向前40名舞会进行更新，这是eta的公式
update this is the formulation where eta is nothing but Rho by n and this is

1526
00:58:37,040 --> 00:58:39,340
只是Rho乘n而已，而Q就是我的分解，
update this is the formulation where eta is nothing but Rho by n and this is

1527
00:58:39,340 --> 00:58:43,000
只是Rho乘n而已，而Q就是我的分解，
is nothing but Rho by n and this is nothing but Q this my decomposition and

1528
00:58:43,000 --> 00:58:43,010
只是Rho乘n而已，而Q就是我的分解，
nothing but Q this my decomposition and later for Z update again this is the

1529
00:58:43,010 --> 00:58:45,670
稍后再次进行Z更新，这是我们已经看到的表达式
nothing but Q this my decomposition and later for Z update again this is the

1530
00:58:45,670 --> 00:58:47,470
稍后再次进行Z更新，这是我们已经看到的表达式
later for Z update again this is the expression which we have already seen

1531
00:58:47,470 --> 00:58:47,480
稍后再次进行Z更新，这是我们已经看到的表达式
expression which we have already seen and also this is from a you updated cell

1532
00:58:47,480 --> 00:58:49,960
而且这是从您更新的手机解决方案中获得的，因此我可以
expression which we have already seen and also this is from a you updated cell

1533
00:58:49,960 --> 00:58:52,660
而且这是从您更新的手机解决方案中获得的，因此我可以
and also this is from a you updated cell phone solution so I'll be able to get an

1534
00:58:52,660 --> 00:58:52,670
而且这是从您更新的手机解决方案中获得的，因此我可以
phone solution so I'll be able to get an optimum value okay I mean it is used for

1535
00:58:52,670 --> 00:58:59,370
最佳值好吧，我的意思是它用于可视化晶圆以检查
phone solution so I'll be able to get an optimum value okay I mean it is used for

1536
00:58:59,370 --> 00:59:02,770
最佳值好吧，我的意思是它用于可视化晶圆以检查
optimum value okay I mean it is used for to visualize the wafer to inspect the

1537
00:59:02,770 --> 00:59:02,780
最佳值好吧，我的意思是它用于可视化晶圆以检查
to visualize the wafer to inspect the performance of classification and in

1538
00:59:02,780 --> 00:59:05,410
性能的分类，在此我们有两个x轴和y轴
to visualize the wafer to inspect the performance of classification and in

1539
00:59:05,410 --> 00:59:07,570
性能的分类，在此我们有两个x轴和y轴
performance of classification and in this we have two x axis and y axis which

1540
00:59:07,570 --> 00:59:07,580
性能的分类，在此我们有两个x轴和y轴
this we have two x axis and y axis which is to positive and false positive and

1541
00:59:07,580 --> 00:59:10,609
是肯定的还是假的，我的读书俱乐部就在我角落的一部分
this we have two x axis and y axis which is to positive and false positive and

1542
00:59:10,609 --> 00:59:14,599
是肯定的还是假的，我的读书俱乐部就在我角落的一部分
is to positive and false positive and my book club is part of my corner then

1543
00:59:14,599 --> 00:59:14,609
是肯定的还是假的，我的读书俱乐部就在我角落的一部分
my book club is part of my corner then the system is accurate its operating the

1544
00:59:14,609 --> 00:59:17,150
该系统是准确的其操作场地，并且由于该区域下方
my book club is part of my corner then the system is accurate its operating the

1545
00:59:17,150 --> 00:59:19,969
该系统是准确的其操作场地，并且由于该区域下方
the system is accurate its operating the venue and since the area under this

1546
00:59:19,969 --> 00:59:19,979
该系统是准确的其操作场地，并且由于该区域下方
venue and since the area under this curve gives me the appreciation okay I

1547
00:59:19,979 --> 00:59:25,309
曲线给了我欣赏，好吧，我做了一个小玩具问题，因为我做了
venue and since the area under this curve gives me the appreciation okay I

1548
00:59:25,309 --> 00:59:28,039
曲线给了我欣赏，好吧，我做了一个小玩具问题，因为我做了
curve gives me the appreciation okay I took a small toy problem because I did

1549
00:59:28,039 --> 00:59:28,049
曲线给了我欣赏，好吧，我做了一个小玩具问题，因为我做了
took a small toy problem because I did not get the data set what the paper has

1550
00:59:28,049 --> 00:59:29,660
无法获得本文执行的数据集，因此在此论坛中
took a small toy problem because I did not get the data set what the paper has

1551
00:59:29,660 --> 00:59:32,359
无法获得本文执行的数据集，因此在此论坛中
not get the data set what the paper has implemented so in this in this forum

1552
00:59:32,359 --> 00:59:32,369
无法获得本文执行的数据集，因此在此论坛中
implemented so in this in this forum I've taken eight Bernoulli eight gamma

1553
00:59:32,369 --> 00:59:34,729
我取了八伯努利八伽马八高斯，做了蒸馏。
implemented so in this in this forum I've taken eight Bernoulli eight gamma

1554
00:59:34,729 --> 00:59:36,739
我取了八伯努利八伽马八高斯，做了蒸馏。
I've taken eight Bernoulli eight gamma eight Gaussian and made a distillate

1555
00:59:36,739 --> 00:59:36,749
我取了八伯努利八伽马八高斯，做了蒸馏。
eight Gaussian and made a distillate with K is equal to 3 and there are two

1556
00:59:36,749 --> 00:59:38,870
当K等于3时，有两种情况，一种具有权力，另一种是
eight Gaussian and made a distillate with K is equal to 3 and there are two

1557
00:59:38,870 --> 00:59:41,509
当K等于3时，有两种情况，一种具有权力，另一种是
with K is equal to 3 and there are two cases one has power he other is the

1558
00:59:41,509 --> 00:59:41,519
当K等于3时，有两种情况，一种具有权力，另一种是
cases one has power he other is the dense case was fast case taken or the

1559
00:59:41,519 --> 00:59:44,359
密集案例是快速案例，或者存在的潜力的10％，并且
cases one has power he other is the dense case was fast case taken or the

1560
00:59:44,359 --> 00:59:46,940
密集案例是快速案例，或者存在的潜力的10％，并且
dense case was fast case taken or the 10% of the potential that exists and the

1561
00:59:46,940 --> 00:59:46,950
密集案例是快速案例，或者存在的潜力的10％，并且
10% of the potential that exists and the for dense case have taken the 50% of the

1562
00:59:46,950 --> 00:59:49,069
对于稠密的情况，采取了50％的潜在边存在，然后这些是
10% of the potential that exists and the for dense case have taken the 50% of the

1563
00:59:49,069 --> 00:59:52,160
对于稠密的情况，采取了50％的潜在边存在，然后这些是
for dense case have taken the 50% of the potential edge exists and then these are

1564
00:59:52,160 --> 00:59:52,170
对于稠密的情况，采取了50％的潜在边存在，然后这些是
potential edge exists and then these are the results that have obtained this is

1565
00:59:52,170 --> 00:59:53,989
得到的结果是关于高度结构化和这个世界的
potential edge exists and then these are the results that have obtained this is

1566
00:59:53,989 --> 00:59:55,819
得到的结果是关于高度结构化和这个世界的
the results that have obtained this is for highly structure and this world

1567
00:59:55,819 --> 00:59:55,829
得到的结果是关于高度结构化和这个世界的
for highly structure and this world knows fast structure and we can observe

1568
00:59:55,829 --> 00:59:58,130
知道快速的结构，我们可以观察到它们说明了
for highly structure and this world knows fast structure and we can observe

1569
00:59:58,130 --> 01:00:01,430
知道快速的结构，我们可以观察到它们说明了
knows fast structure and we can observe that the the that they illustrate the de

1570
01:00:01,430 --> 01:00:01,440
知道快速的结构，我们可以观察到它们说明了
that the the that they illustrate the de Graaff with the high degree of sparsity

1571
01:00:01,440 --> 01:00:03,670
格拉夫具有高度的稀疏性，可以回收很少的样品
that the the that they illustrate the de Graaff with the high degree of sparsity

1572
01:00:03,670 --> 01:00:06,349
格拉夫具有高度的稀疏性，可以回收很少的样品
Graaff with the high degree of sparsity to recover few samples it is much

1573
01:00:06,349 --> 01:00:06,359
格拉夫具有高度的稀疏性，可以回收很少的样品
to recover few samples it is much possible so that is this is much better

1574
01:00:06,359 --> 01:00:08,410
可能，这是更好的了，这只是说明，还可以
to recover few samples it is much possible so that is this is much better

1575
01:00:08,410 --> 01:00:16,969
可能，这是更好的了，这只是说明，还可以
possible so that is this is much better that is the illustrate just and ok again

1576
01:00:16,969 --> 01:00:16,979
可能，这是更好的了，这只是说明，还可以
that is the illustrate just and ok again this is the same I'm going to conclude

1577
01:00:16,979 --> 01:00:20,829
这就是我要得出结论的结论，因此在这项工作中
that is the illustrate just and ok again this is the same I'm going to conclude

1578
01:00:20,829 --> 01:00:23,420
这就是我要得出结论的结论，因此在这项工作中
this is the same I'm going to conclude to conclude this so in this work we have

1579
01:00:23,420 --> 01:00:23,430
这就是我要得出结论的结论，因此在这项工作中
to conclude this so in this work we have discussed the method for learning the

1580
01:00:23,430 --> 01:00:25,459
讨论了学习马尔可夫网络的方法
to conclude this so in this work we have discussed the method for learning the

1581
01:00:25,459 --> 01:00:27,009
讨论了学习马尔可夫网络的方法
discussed the method for learning the Markov networks that is from

1582
01:00:27,009 --> 01:00:27,019
讨论了学习马尔可夫网络的方法
Markov networks that is from observational data and then this PMRF is

1583
01:00:27,019 --> 01:00:31,430
观测数据，然后这个PMRF是一个多元天才数据，
Markov networks that is from observational data and then this PMRF is

1584
01:00:31,430 --> 01:00:36,140
观测数据，然后这个PMRF是一个多元天才数据，
observational data and then this PMRF is a multivariate genius data which is much

1585
01:00:36,140 --> 01:00:36,150
观测数据，然后这个PMRF是一个多元天才数据，
a multivariate genius data which is much required for example you take our

1586
01:00:36,150 --> 01:00:37,729
例如您需要我们的医疗数据库或类似的数据库
a multivariate genius data which is much required for example you take our

1587
01:00:37,729 --> 01:00:39,650
例如您需要我们的医疗数据库或类似的数据库
required for example you take our medical database or something like that

1588
01:00:39,650 --> 01:00:39,660
例如您需要我们的医疗数据库或类似的数据库
medical database or something like that and then we have not used the exact use

1589
01:00:39,660 --> 01:00:44,420
然后我们没有为此使用确切的使用近似最大似然
medical database or something like that and then we have not used the exact use

1590
01:00:44,420 --> 01:00:46,519
然后我们没有为此使用确切的使用近似最大似然
and then we have not used the exact use approximate maximum likelihood for this

1591
01:00:46,519 --> 01:00:46,529
然后我们没有为此使用确切的使用近似最大似然
approximate maximum likelihood for this problem and you also developed our a DMM

1592
01:00:46,529 --> 01:00:48,680
问题，您还开发了一种DMM算法，可以减少我
approximate maximum likelihood for this problem and you also developed our a DMM

1593
01:00:48,680 --> 01:00:50,539
问题，您还开发了一种DMM算法，可以减少我
problem and you also developed our a DMM algorithm which can reduce me a

1594
01:00:50,539 --> 01:00:50,549
问题，您还开发了一种DMM算法，可以减少我
algorithm which can reduce me a closed-form updates and these are the

1595
01:00:50,549 --> 01:00:54,499
封闭形式的更新，这些是参考，摘自本文或
algorithm which can reduce me a closed-form updates and these are the

1596
01:00:54,499 --> 01:00:56,870
封闭形式的更新，这些是参考，摘自本文或
closed-form updates and these are the references and from this paper or taken

1597
01:00:56,870 --> 01:00:56,880
封闭形式的更新，这些是参考，摘自本文或
references and from this paper or taken the like the main people that have

1598
01:00:56,880 --> 01:01:00,589
像那些努力并进一步获得theta的主要人物
references and from this paper or taken the like the main people that have

1599
01:01:00,589 --> 01:01:03,829
像那些努力并进一步获得theta的主要人物
the like the main people that have effort and further to obtain a of theta

1600
01:01:03,829 --> 01:01:03,839
像那些努力并进一步获得theta的主要人物
effort and further to obtain a of theta I hope that theta the upper bound refers

1601
01:01:03,839 --> 01:01:07,069
我希望theta上限是本文的参考，并且本文给出了一个
effort and further to obtain a of theta I hope that theta the upper bound refers

1602
01:01:07,069 --> 01:01:09,859
我希望theta上限是本文的参考，并且本文给出了一个
I hope that theta the upper bound refers for this paper and this paper gives a

1603
01:01:09,859 --> 01:01:09,869
我希望theta上限是本文的参考，并且本文给出了一个
for this paper and this paper gives a brief explanation of early how do we go

1604
01:01:09,869 --> 01:01:12,920
早期的简要说明我们如何使用约
for this paper and this paper gives a brief explanation of early how do we go

1605
01:01:12,920 --> 01:01:17,150
早期的简要说明我们如何使用约
brief explanation of early how do we go about of using the approximately

1606
01:01:17,150 --> 01:02:12,880
哦
brief explanation of early how do we go about of using the approximately

1607
01:02:12,880 --> 01:02:12,890
哦


1608
01:02:12,890 --> 01:02:14,920
哦
Oh

1609
01:02:14,920 --> 01:02:16,950
所以您好，我希望物理系能够
Oh

1610
01:02:16,950 --> 01:02:16,960
所以您好，我希望物理系能够


1611
01:02:16,960 --> 01:02:24,480
所以您好，我希望物理系能够
so hi I am a wishing that from the physics department the generation of the

1612
01:02:24,480 --> 01:02:24,490
所以您好，我希望物理系能够
physics department the generation of the handwritten like image using variational

1613
01:02:24,490 --> 01:02:28,470
使用可变自动编码器手写的图像，它已经在
physics department the generation of the handwritten like image using variational

1614
01:02:28,470 --> 01:02:31,470
使用可变自动编码器手写的图像，它已经在
handwritten like image using variational auto encoder it has been trained on the

1615
01:02:31,470 --> 01:02:31,480
使用可变自动编码器手写的图像，它已经在
auto encoder it has been trained on the eminence to dataset the outline is that

1616
01:02:31,480 --> 01:02:37,430
突出数据集的轮廓是关于介绍的一些内容
auto encoder it has been trained on the eminence to dataset the outline is that

1617
01:02:37,430 --> 01:02:39,660
突出数据集的轮廓是关于介绍的一些内容
eminence to dataset the outline is that introduction a little bit about

1618
01:02:39,660 --> 01:02:39,670
突出数据集的轮廓是关于介绍的一些内容
introduction a little bit about missionaries which are like standard we

1619
01:02:39,670 --> 01:02:43,109
像标准的传教士，我们从扫描仪自动编码器开始
introduction a little bit about missionaries which are like standard we

1620
01:02:43,109 --> 01:02:44,940
像标准的传教士，我们从扫描仪自动编码器开始
missionaries which are like standard we start with scanner auto encoder we

1621
01:02:44,940 --> 01:02:44,950
像标准的传教士，我们从扫描仪自动编码器开始
start with scanner auto encoder we introduced variation on experience

1622
01:02:44,950 --> 01:02:47,450
介绍了经验变化的外部颜色变化-
start with scanner auto encoder we introduced variation on experience

1623
01:02:47,450 --> 01:02:49,380
介绍了经验变化的外部颜色变化-
introduced variation on experience variational outside color -

1624
01:02:49,380 --> 01:02:49,390
介绍了经验变化的外部颜色变化-
variational outside color - normalization and the resultant clock so

1625
01:02:49,390 --> 01:02:52,890
归一化和结果时钟，所以我将在
variational outside color - normalization and the resultant clock so

1626
01:02:52,890 --> 01:02:55,109
归一化和结果时钟，所以我将在
normalization and the resultant clock so I'll be talking about a little bit in

1627
01:02:55,109 --> 01:02:55,119
归一化和结果时钟，所以我将在
I'll be talking about a little bit in little about this machineries because I

1628
01:02:55,119 --> 01:02:57,930
关于这台机器的知识很少，因为我在开始之后就了解了它们
I'll be talking about a little bit in little about this machineries because I

1629
01:02:57,930 --> 01:03:01,140
关于这台机器的知识很少，因为我在开始之后就了解了它们
little about this machineries because I learned about them while starting after

1630
01:03:01,140 --> 01:03:01,150
关于这台机器的知识很少，因为我在开始之后就了解了它们
learned about them while starting after starting working on this project itself

1631
01:03:01,150 --> 01:03:05,520
开始从事这个项目本身
learned about them while starting after starting working on this project itself

1632
01:03:05,520 --> 01:03:06,349
因此，自动编码器网络是一对真正相连的网络
learned about them while starting after starting working on this project itself

1633
01:03:06,349 --> 01:03:06,359
因此，自动编码器网络是一对真正相连的网络


1634
01:03:06,359 --> 01:03:13,230
因此，自动编码器网络是一对真正相连的网络
so an autoencoder network is a pair of true connected networks

1635
01:03:13,230 --> 01:03:15,140
编码器组件制作并获取原始数据的表示形式
so an autoencoder network is a pair of true connected networks

1636
01:03:15,140 --> 01:03:15,150
编码器组件制作并获取原始数据的表示形式


1637
01:03:15,150 --> 01:03:25,020
编码器组件制作并获取原始数据的表示形式
the encoder component makes and gains the representation of the original data

1638
01:03:25,020 --> 01:03:25,030
编码器组件制作并获取原始数据的表示形式
the representation of the original data Angele la or grid of pixels and then we

1639
01:03:25,030 --> 01:03:30,030
Angele la或像素网格，然后我们将n个颜色信息和
the representation of the original data Angele la or grid of pixels and then we

1640
01:03:30,030 --> 01:03:32,039
Angele la或像素网格，然后我们将n个颜色信息和
Angele la or grid of pixels and then we call that n color information and the

1641
01:03:32,039 --> 01:03:32,049
Angele la或像素网格，然后我们将n个颜色信息和
call that n color information and the decoder part decodes it back to the

1642
01:03:32,049 --> 01:03:35,160
解码器部分将其解码回原始尺寸，通常高于
call that n color information and the decoder part decodes it back to the

1643
01:03:35,160 --> 01:03:37,950
解码器部分将其解码回原始尺寸，通常高于
decoder part decodes it back to the original dimension usually higher than

1644
01:03:37,950 --> 01:03:37,960
解码器部分将其解码回原始尺寸，通常高于
original dimension usually higher than the dimensional representation like this

1645
01:03:37,960 --> 01:03:42,799
像这样的尺寸表示就是描述
original dimension usually higher than the dimensional representation like this

1646
01:03:42,799 --> 01:03:48,210
像这样的尺寸表示就是描述
the dimensional representation like this this is the description

1647
01:03:48,210 --> 01:03:48,330
所以通常解码器网络的输出与输入不匹配
the dimensional representation like this this is the description

1648
01:03:48,330 --> 01:03:48,340
所以通常解码器网络的输出与输入不匹配


1649
01:03:48,340 --> 01:03:55,100
所以通常解码器网络的输出与输入不匹配
so in general the output of the decoder network would not match with the input

1650
01:03:55,100 --> 01:03:55,110
所以通常解码器网络的输出与输入不匹配
network would not match with the input using the input data point like new data

1651
01:03:55,110 --> 01:04:42,150
使用输入数据点（如新数据点），它会告诉您，因为它不会
network would not match with the input using the input data point like new data

1652
01:04:42,150 --> 01:04:44,130
使用输入数据点（如新数据点），它会告诉您，因为它不会
using the input data point like new data points then it tells because it won't

1653
01:04:44,130 --> 01:04:44,140
使用输入数据点（如新数据点），它会告诉您，因为它不会
points then it tells because it won't it can only give must output replicating

1654
01:04:44,140 --> 01:04:47,880
它只能给必须输出复制我们更密集的表示
points then it tells because it won't it can only give must output replicating

1655
01:04:47,880 --> 01:04:52,140
它只能给必须输出复制我们更密集的表示
it can only give must output replicating the denser representation of our

1656
01:04:52,140 --> 01:04:52,150
它只能给必须输出复制我们更密集的表示
the denser representation of our original input so it cannot create new

1657
01:04:52,150 --> 01:04:54,840
原始输入，因此它无法创建新事物，因此就是这样
the denser representation of our original input so it cannot create new

1658
01:04:54,840 --> 01:04:58,350
原始输入，因此它无法创建新事物，因此就是这样
original input so it cannot create new things so it's that's that's where

1659
01:04:58,350 --> 01:04:58,360
原始输入，因此它无法创建新事物，因此就是这样
things so it's that's that's where standard auto encoder slack so these are

1660
01:04:58,360 --> 01:05:04,500
标准自动编码器松弛，因此这些只是表示形式的示例
things so it's that's that's where standard auto encoder slack so these are

1661
01:05:04,500 --> 01:05:11,010
标准自动编码器松弛，因此这些只是表示形式的示例
standard auto encoder slack so these are kind of an example of the representation

1662
01:05:11,010 --> 01:05:11,020
标准自动编码器松弛，因此这些只是表示形式的示例
kind of an example of the representation of the MST data state where we have like

1663
01:05:11,020 --> 01:05:14,370
MST数据状态的状态，我们有28到28
kind of an example of the representation of the MST data state where we have like

1664
01:05:14,370 --> 01:05:15,720
MST数据状态的状态，我们有28到28
of the MST data state where we have like twenty eighteen to twenty eighth

1665
01:05:15,720 --> 01:05:15,730
MST数据状态的状态，我们有28到28
twenty eighteen to twenty eighth dimension we have converted it to the

1666
01:05:15,730 --> 01:05:17,490
维度，我们已将其转换为二维，因此它们的分布和
twenty eighteen to twenty eighth dimension we have converted it to the

1667
01:05:17,490 --> 01:05:20,690
维度，我们已将其转换为二维，因此它们的分布和
dimension we have converted it to the two dimension so their distribution and

1668
01:05:20,690 --> 01:05:20,700
维度，我们已将其转换为二维，因此它们的分布和
two dimension so their distribution and it's kind of get rich there is no

1669
01:05:20,700 --> 01:05:23,160
这是一种致富，代表不存在连续性
two dimension so their distribution and it's kind of get rich there is no

1670
01:05:23,160 --> 01:05:26,100
这是一种致富，代表不存在连续性
it's kind of get rich there is no continuity from one the representation

1671
01:05:26,100 --> 01:05:26,110
这是一种致富，代表不存在连续性
continuity from one the representation data point of one visit to the other so

1672
01:05:26,110 --> 01:05:29,370
一次访问另一个访问的数据点，因此我们不希望这样，因为它在哪里
continuity from one the representation data point of one visit to the other so

1673
01:05:29,370 --> 01:05:33,840
一次访问另一个访问的数据点，因此我们不希望这样，因为它在哪里
data point of one visit to the other so we won't want that because where it's

1674
01:05:33,840 --> 01:05:33,850
一次访问另一个访问的数据点，因此我们不希望这样，因为它在哪里
we won't want that because where it's difficult to general

1675
01:05:33,850 --> 01:05:35,150
很难像分布那样的一般模型
we won't want that because where it's difficult to general

1676
01:05:35,150 --> 01:05:37,730
很难像分布那样的一般模型
difficult to general models while the distribution is like

1677
01:05:37,730 --> 01:05:37,740
很难像分布那样的一般模型
models while the distribution is like that in generative models we would not

1678
01:05:37,740 --> 01:05:41,990
在生成模型中，我们不想复制使用它的数据
models while the distribution is like that in generative models we would not

1679
01:05:41,990 --> 01:05:44,900
在生成模型中，我们不想复制使用它的数据
that in generative models we would not want to replicate data that we used it

1680
01:05:44,900 --> 01:05:44,910
在生成模型中，我们不想复制使用它的数据
want to replicate data that we used it to train in the first place but also we

1681
01:05:44,910 --> 01:05:47,270
首先训练，但我们也想从
want to replicate data that we used it to train in the first place but also we

1682
01:05:47,270 --> 01:05:49,130
首先训练，但我们也想从
to train in the first place but also we want to sample data points from the

1683
01:05:49,130 --> 01:05:49,140
首先训练，但我们也想从
want to sample data points from the distribution the latent space and decode

1684
01:05:49,140 --> 01:05:51,650
分配潜在空间并对其进行解码，以形成大臣官邸和更高的
want to sample data points from the distribution the latent space and decode

1685
01:05:51,650 --> 01:05:55,180
分配潜在空间并对其进行解码，以形成大臣官邸和更高的
distribution the latent space and decode them to form Chancellor's and the higher

1686
01:05:55,180 --> 01:05:55,190
分配潜在空间并对其进行解码，以形成大臣官邸和更高的
them to form Chancellor's and the higher data points so suppose we we have a lot

1687
01:05:55,190 --> 01:06:09,050
数据点，所以假设我们有很多手写数字的数据点
them to form Chancellor's and the higher data points so suppose we we have a lot

1688
01:06:09,050 --> 01:06:12,230
数据点，所以假设我们有很多手写数字的数据点
data points so suppose we we have a lot of data points of the handwritten digits

1689
01:06:12,230 --> 01:06:12,240
数据点，所以假设我们有很多手写数字的数据点
of data points of the handwritten digits and we want to create a model to get the

1690
01:06:12,240 --> 01:06:16,130
我们想要创建一个模型来获得生命周期的概率分布
of data points of the handwritten digits and we want to create a model to get the

1691
01:06:16,130 --> 01:06:17,900
我们想要创建一个模型来获得生命周期的概率分布
and we want to create a model to get the probability distribution of life of

1692
01:06:17,900 --> 01:06:17,910
我们想要创建一个模型来获得生命周期的概率分布
probability distribution of life of those data points now these images are

1693
01:06:17,910 --> 01:06:20,720
这些数据点现在这些图像按趋势年龄为28，以便获得最大
probability distribution of life of those data points now these images are

1694
01:06:20,720 --> 01:06:23,990
这些数据点现在这些图像按趋势年龄为28，以便获得最大
those data points now these images are 28 by trend age so to get a maximum

1695
01:06:23,990 --> 01:06:24,000
这些数据点现在这些图像按趋势年龄为28，以便获得最大
28 by trend age so to get a maximum likelihood would have to get a min of 28

1696
01:06:24,000 --> 01:06:30,440
可能性必须是将28的最小值变成28的维，并且协方差
28 by trend age so to get a maximum likelihood would have to get a min of 28

1697
01:06:30,440 --> 01:06:34,340
可能性必须是将28的最小值变成28的维，并且协方差
likelihood would have to get a min of 28 into 28 dimension and and the covariance

1698
01:06:34,340 --> 01:06:34,350
可能性必须是将28的最小值变成28的维，并且协方差
into 28 dimension and and the covariance matrix of the similar dimensions those

1699
01:06:34,350 --> 01:06:36,200
尺寸相似的矩阵，它们在计算上非常难处理
into 28 dimension and and the covariance matrix of the similar dimensions those

1700
01:06:36,200 --> 01:06:37,640
尺寸相似的矩阵，它们在计算上非常难处理
matrix of the similar dimensions those are very computationally intractable

1701
01:06:37,640 --> 01:06:37,650
尺寸相似的矩阵，它们在计算上非常难处理
are very computationally intractable that's why the idea of auto-encoders

1702
01:06:37,650 --> 01:06:41,090
这就是为什么自动编码器的想法首先应运而生的原因
are very computationally intractable that's why the idea of auto-encoders

1703
01:06:41,090 --> 01:06:44,540
这就是为什么自动编码器的想法首先应运而生的原因
that's why the idea of auto-encoders comes into play in the first place to

1704
01:06:44,540 --> 01:06:44,550
这就是为什么自动编码器的想法首先应运而生的原因
comes into play in the first place to get a more compressed representation so

1705
01:06:44,550 --> 01:06:50,240
从概率图形模型中获得更压缩的表示
comes into play in the first place to get a more compressed representation so

1706
01:06:50,240 --> 01:06:52,010
从概率图形模型中获得更压缩的表示
get a more compressed representation so from the probabilistic graphical models

1707
01:06:52,010 --> 01:06:52,020
从概率图形模型中获得更压缩的表示
from the probabilistic graphical models from what we can say

1708
01:06:52,020 --> 01:06:56,240
从我们可以说的
from the probabilistic graphical models from what we can say

1709
01:06:56,240 --> 01:07:19,880
[音乐]
from the probabilistic graphical models from what we can say

1710
01:07:19,880 --> 01:07:19,890
[音乐]


1711
01:07:19,890 --> 01:07:22,960
[音乐]
[Music]

1712
01:07:22,960 --> 01:07:33,140
分母本身很难计算非常昂贵
[Music]

1713
01:07:33,140 --> 01:07:33,150
分母本身很难计算非常昂贵


1714
01:07:33,150 --> 01:07:41,810
分母本身很难计算非常昂贵
in the denominator itself is very difficult to compute very expensive

1715
01:07:41,810 --> 01:07:41,820
分母本身很难计算非常昂贵
difficult to compute very expensive that's why we use variation insurance to

1716
01:07:41,820 --> 01:07:48,359
这就是为什么我们使用差异保险来估算与一个家庭的后验
difficult to compute very expensive that's why we use variation insurance to

1717
01:07:48,359 --> 01:07:50,580
这就是为什么我们使用差异保险来估算与一个家庭的后验
that's why we use variation insurance to approximate the posterior with a family

1718
01:07:50,580 --> 01:07:50,590
这就是为什么我们使用差异保险来估算与一个家庭的后验
approximate the posterior with a family of distribution which represents the

1719
01:07:50,590 --> 01:07:59,670
分布代表我们的分布参数
approximate the posterior with a family of distribution which represents the

1720
01:07:59,670 --> 01:08:01,920
分布代表我们的分布参数
of distribution which represents the parameters of the distributions we are

1721
01:08:01,920 --> 01:08:01,930
分布代表我们的分布参数
parameters of the distributions we are trying to fit for example a cube or a

1722
01:08:01,930 --> 01:08:04,890
试图适合例如多维数据集或正态分布，这将意味着新的
parameters of the distributions we are trying to fit for example a cube or a

1723
01:08:04,890 --> 01:08:07,620
试图适合例如多维数据集或正态分布，这将意味着新的
trying to fit for example a cube or a normal distribution it will mean the new

1724
01:08:07,620 --> 01:08:07,630
试图适合例如多维数据集或正态分布，这将意味着新的
normal distribution it will mean the new X I and Sigma X we will use KL

1725
01:08:07,630 --> 01:08:13,440
XI和Sigma X我们将使用KL散度来量化
normal distribution it will mean the new X I and Sigma X we will use KL

1726
01:08:13,440 --> 01:08:15,960
XI和Sigma X我们将使用KL散度来量化
X I and Sigma X we will use KL divergence which should quantify the

1727
01:08:15,960 --> 01:08:15,970
XI和Sigma X我们将使用KL散度来量化
divergence which should quantify the information lost we try to replace the

1728
01:08:15,970 --> 01:08:19,640
信息丢失，我们尝试用lambda替换主分布P
divergence which should quantify the information lost we try to replace the

1729
01:08:19,640 --> 01:08:27,150
信息丢失，我们尝试用lambda替换主分布P
information lost we try to replace the primary distribution P with lambda

1730
01:08:27,150 --> 01:08:31,740
因为是的，杀死差异被定义为预期的期望值
information lost we try to replace the primary distribution P with lambda

1731
01:08:31,740 --> 01:08:31,750
因为是的，杀死差异被定义为预期的期望值


1732
01:08:31,750 --> 01:08:41,910
因为是的，杀死差异被定义为预期的期望值
for that yeah kill divergences define as the expected expectation value of the

1733
01:08:41,910 --> 01:08:41,920
因为是的，杀死差异被定义为预期的期望值
the expected expectation value of the log of Q lambda over P and we can

1734
01:08:41,920 --> 01:08:49,220
P上的Q lambda的对数，我们可以在那里表示减法群
the expected expectation value of the log of Q lambda over P and we can

1735
01:08:49,220 --> 01:08:52,460
P上的Q lambda的对数，我们可以在那里表示减法群
log of Q lambda over P and we can express in there the subtractive swarm

1736
01:08:52,460 --> 01:08:52,470
P上的Q lambda的对数，我们可以在那里表示减法群
express in there the subtractive swarm and using Bayes theorem we can express

1737
01:08:52,470 --> 01:08:57,660
并使用贝叶斯定理，我们可以将其表示为方程二
express in there the subtractive swarm and using Bayes theorem we can express

1738
01:08:57,660 --> 01:09:02,339
并使用贝叶斯定理，我们可以将其表示为方程二
and using Bayes theorem we can express it in the like a form of equation two

1739
01:09:02,339 --> 01:09:05,779
像这里，最佳姿势的近似值很清楚，我发誓要得到
and using Bayes theorem we can express it in the like a form of equation two

1740
01:09:05,779 --> 01:09:05,789
像这里，最佳姿势的近似值很清楚，我发誓要得到


1741
01:09:05,789 --> 01:09:12,879
像这里，最佳姿势的近似值很清楚，我发誓要得到
like here the approximate for optimal posture is clear I swore to get

1742
01:09:12,879 --> 01:09:12,889
像这里，最佳姿势的近似值很清楚，我发誓要得到
posture is clear I swore to get approximate optimal posture we minimize

1743
01:09:12,889 --> 01:09:16,879
近似最佳姿势，我们将lambda的KL散度减至最小
posture is clear I swore to get approximate optimal posture we minimize

1744
01:09:16,879 --> 01:09:19,640
近似最佳姿势，我们将lambda的KL散度减至最小
approximate optimal posture we minimize KL divergence with respect to lambda to

1745
01:09:19,640 --> 01:09:19,650
近似最佳姿势，我们将lambda的KL散度减至最小
KL divergence with respect to lambda to get the optimized Q lambda but the

1746
01:09:19,650 --> 01:09:25,640
得到优化的Q lambda，但是直到丢失为止，px的难解的对数
KL divergence with respect to lambda to get the optimized Q lambda but the

1747
01:09:25,640 --> 01:09:29,979
得到优化的Q lambda，但是直到丢失为止，px的难解的对数
get the optimized Q lambda but the intractable term log of px till lost

1748
01:09:29,979 --> 01:09:29,989
得到优化的Q lambda，但是直到丢失为止，px的难解的对数
intractable term log of px till lost within the expression of the KL

1749
01:09:29,989 --> 01:09:32,479
在这样的KL散度的表达中等于
intractable term log of px till lost within the expression of the KL

1750
01:09:32,479 --> 01:09:35,390
在这样的KL散度的表达中等于
within the expression of the KL divergence like this is equal to that

1751
01:09:35,390 --> 01:09:35,400
在这样的KL散度的表达中等于
divergence like this is equal to that and that term is very computationally

1752
01:09:35,400 --> 01:09:38,200
该术语在计算上非常昂贵，因此我们要删除该术语
divergence like this is equal to that and that term is very computationally

1753
01:09:38,200 --> 01:09:42,519
该术语在计算上非常昂贵，因此我们要删除该术语
and that term is very computationally expensive so we want to remove that

1754
01:09:42,519 --> 01:09:42,529
该术语在计算上非常昂贵，因此我们要删除该术语
expensive so we want to remove that that's why we just flip side and Express

1755
01:09:42,529 --> 01:09:47,499
这就是为什么我们只是反过来表示为这种减法形式
expensive so we want to remove that that's why we just flip side and Express

1756
01:09:47,499 --> 01:09:51,890
这就是为什么我们只是反过来表示为这种减法形式
that's why we just flip side and Express as this subtractive form of to

1757
01:09:51,890 --> 01:09:51,900
这就是为什么我们只是反过来表示为这种减法形式
as this subtractive form of to expectation values plus KL divergence

1758
01:09:51,900 --> 01:09:55,810
期望值加上KL散度现在我们知道KL散度总是
as this subtractive form of to expectation values plus KL divergence

1759
01:09:55,810 --> 01:09:59,450
期望值加上KL散度现在我们知道KL散度总是
expectation values plus KL divergence now we know that KL divergence is always

1760
01:09:59,450 --> 01:09:59,460
期望值加上KL散度现在我们知道KL散度总是
now we know that KL divergence is always non-negative so it's I'm sorry so its

1761
01:09:59,460 --> 01:10:05,709
非负数，所以很抱歉，其最小值为0，以便将其最大化
now we know that KL divergence is always non-negative so it's I'm sorry so its

1762
01:10:05,709 --> 01:10:10,790
非负数，所以很抱歉，其最小值为0，以便将其最大化
non-negative so it's I'm sorry so its minimum value is 0 so to maximize this

1763
01:10:10,790 --> 01:10:10,800
非负数，所以很抱歉，其最小值为0，以便将其最大化
minimum value is 0 so to maximize this we want to minimize this and maximum

1764
01:10:10,800 --> 01:10:14,060
我们要最小化此排放并最大程度地排放，所以现在这有点
minimum value is 0 so to maximize this we want to minimize this and maximum

1765
01:10:14,060 --> 01:10:20,439
我们要最小化此排放并最大程度地排放，所以现在这有点
we want to minimize this and maximum discharge so now this becomes a bit

1766
01:10:20,439 --> 01:10:20,449
我们要最小化此排放并最大程度地排放，所以现在这有点
discharge so now this becomes a bit tractable to compute

1767
01:10:20,449 --> 01:10:24,019
易于计算
discharge so now this becomes a bit tractable to compute

1768
01:10:24,019 --> 01:10:25,260
和信息保险，我们使用工会投票将Forrester放入Thomas
discharge so now this becomes a bit tractable to compute

1769
01:10:25,260 --> 01:10:25,270
和信息保险，我们使用工会投票将Forrester放入Thomas


1770
01:10:25,270 --> 01:10:37,890
和信息保险，我们使用工会投票将Forrester放入Thomas
and informational insurance we use union vo checking Forrester into the Thomas

1771
01:10:37,890 --> 01:10:37,900
和信息保险，我们使用工会投票将Forrester放入Thomas
vo checking Forrester into the Thomas Trump's dependent only upon the single

1772
01:10:37,900 --> 01:10:40,140
特朗普仅依赖于单个数据点，因此可以使用
vo checking Forrester into the Thomas Trump's dependent only upon the single

1773
01:10:40,140 --> 01:10:42,690
特朗普仅依赖于单个数据点，因此可以使用
Trump's dependent only upon the single data points this allows for the use of

1774
01:10:42,690 --> 01:10:42,700
特朗普仅依赖于单个数据点，因此可以使用
data points this allows for the use of stochastic gradient descent with respect

1775
01:10:42,700 --> 01:10:44,940
关于参数λ变化的随机梯度下降
data points this allows for the use of stochastic gradient descent with respect

1776
01:10:44,940 --> 01:10:46,440
关于参数λ变化的随机梯度下降
stochastic gradient descent with respect to the variation of parameters lambda

1777
01:10:46,440 --> 01:10:46,450
关于参数λ变化的随机梯度下降
to the variation of parameters lambda for a given data point X right the LPO

1778
01:10:46,450 --> 01:10:50,130
对于给定的数据点X右，LPO在此定义，因此T超过
to the variation of parameters lambda for a given data point X right the LPO

1779
01:10:50,130 --> 01:11:00,120
对于给定的数据点X右，LPO在此定义，因此T超过
for a given data point X right the LPO are defined on this so long T exceeds

1780
01:11:00,120 --> 01:11:00,950
给定Z减去Q lambda Disney的P的对数期望
for a given data point X right the LPO are defined on this so long T exceeds

1781
01:11:00,950 --> 01:11:00,960
给定Z减去Q lambda Disney的P的对数期望


1782
01:11:00,960 --> 01:11:10,490
给定Z减去Q lambda Disney的P的对数期望
expectation of log of P of a given Z minus Q lambda Disney different extend

1783
01:11:10,490 --> 01:11:10,500
给定Z减去Q lambda Disney的P的对数期望
minus Q lambda Disney different extend teasing minus KL divergence of Q lambda

1784
01:11:10,500 --> 01:11:14,460
在给定X的情况下取QλZ的减负KL散度，在给定X的情况下取笑，因此我们想
minus Q lambda Disney different extend teasing minus KL divergence of Q lambda

1785
01:11:14,460 --> 01:11:20,340
在给定X的情况下取QλZ的减负KL散度，在给定X的情况下取笑，因此我们想
teasing minus KL divergence of Q lambda Z given X and P Z given X so we want to

1786
01:11:20,340 --> 01:11:20,350
在给定X的情况下取QλZ的减负KL散度，在给定X的情况下取笑，因此我们想
Z given X and P Z given X so we want to optimize log tapes by trying to find a

1787
01:11:20,350 --> 01:11:23,190
通过尝试找到内部的数量下限来优化日志磁带
Z given X and P Z given X so we want to optimize log tapes by trying to find a

1788
01:11:23,190 --> 01:11:24,990
通过尝试找到内部的数量下限来优化日志磁带
optimize log tapes by trying to find a lower bound of the quantity inside the

1789
01:11:24,990 --> 01:11:25,000
通过尝试找到内部的数量下限来优化日志磁带
lower bound of the quantity inside the curly bracket computationally

1790
01:11:25,000 --> 01:11:29,550
大括号在计算上难以处理，这是一个最大的示例
lower bound of the quantity inside the curly bracket computationally

1791
01:11:29,550 --> 01:11:44,430
大括号在计算上难以处理，这是一个最大的示例
curly bracket computationally intractable maximizing this is a sample

1792
01:11:44,430 --> 01:11:44,440
大括号在计算上难以处理，这是一个最大的示例
intractable maximizing this is a sample PC is really in the latent space also we

1793
01:11:44,440 --> 01:11:48,060
PC确实处于潜在空间，我们还可以增加获得封闭空间的优势
intractable maximizing this is a sample PC is really in the latent space also we

1794
01:11:48,060 --> 01:11:50,220
PC确实处于潜在空间，我们还可以增加获得封闭空间的优势
PC is really in the latent space also we can add an advantage of obtaining closed

1795
01:11:50,220 --> 01:11:50,230
PC确实处于潜在空间，我们还可以增加获得封闭空间的优势
can add an advantage of obtaining closed formulation of the KL divergence which

1796
01:11:50,230 --> 01:11:52,890
KL散度的公式，在给定X的情况下，将看到Z和Q lambda Z
can add an advantage of obtaining closed formulation of the KL divergence which

1797
01:11:52,890 --> 01:11:56,070
KL散度的公式，在给定X的情况下，将看到Z和Q lambda Z
formulation of the KL divergence which will see Z and Q lambda Z given X we

1798
01:11:56,070 --> 01:11:56,080
KL散度的公式，在给定X的情况下，将看到Z和Q lambda Z
will see Z and Q lambda Z given X we check easy to the standard normal

1799
01:11:56,080 --> 01:11:59,550
容易检查均值0和标准的标准正态分布
will see Z and Q lambda Z given X we check easy to the standard normal

1800
01:11:59,550 --> 01:12:01,380
容易检查均值0和标准的标准正态分布
check easy to the standard normal distribution with mean 0 and standard

1801
01:12:01,380 --> 01:12:01,390
容易检查均值0和标准的标准正态分布
distribution with mean 0 and standard deviation is 1 and 2 lambda Z given X to

1802
01:12:01,390 --> 01:12:07,080
给定X为1时，偏差为1和2λZ
distribution with mean 0 and standard deviation is 1 and 2 lambda Z given X to

1803
01:12:07,080 --> 01:12:08,189
给定X为1时，偏差为1和2λZ
deviation is 1 and 2 lambda Z given X to be

1804
01:12:08,189 --> 01:12:08,199
给定X为1时，偏差为1和2λZ
be like this also another normal

1805
01:12:08,199 --> 01:12:10,439
这样也是另一个正态分布，这就是协方差
be like this also another normal

1806
01:12:10,439 --> 01:12:14,100
这样也是另一个正态分布，这就是协方差
like this also another normal distribution here this is the covariance

1807
01:12:14,100 --> 01:12:14,110
这样也是另一个正态分布，这就是协方差
distribution here this is the covariance matrices constraint to the diagonal

1808
01:12:14,110 --> 01:12:16,229
对角矩阵的矩阵约束以使计算容易，但是
distribution here this is the covariance matrices constraint to the diagonal

1809
01:12:16,229 --> 01:12:25,500
对角矩阵的矩阵约束以使计算容易，但是
matrices constraint to the diagonal matrix to keep computation easy but

1810
01:12:25,500 --> 01:12:25,510
对角矩阵的矩阵约束以使计算容易，但是
matrix to keep computation easy but final the final expression is easy if

1811
01:12:25,510 --> 01:12:29,580
如果我们得到封闭形式的表达式，则最终表达式很容易
matrix to keep computation easy but final the final expression is easy if

1812
01:12:29,580 --> 01:12:31,379
如果我们得到封闭形式的表达式，则最终表达式很容易
final the final expression is easy if the closed form expression that we get

1813
01:12:31,379 --> 01:12:31,389
如果我们得到封闭形式的表达式，则最终表达式很容易
the closed form expression that we get by some algebraic manipulation is the

1814
01:12:31,389 --> 01:12:40,830
通过代数运算得到的归一化非常有用
the closed form expression that we get by some algebraic manipulation is the

1815
01:12:40,830 --> 01:12:44,069
通过代数运算得到的归一化非常有用
by some algebraic manipulation is the normalization which is a very useful

1816
01:12:44,069 --> 01:12:44,079
通过代数运算得到的归一化非常有用
normalization which is a very useful technique introduced to improve the

1817
01:12:44,079 --> 01:12:46,080
引入技术以改善GAE和一般视野的性能
normalization which is a very useful technique introduced to improve the

1818
01:12:46,080 --> 01:12:54,959
引入技术以改善GAE和一般视野的性能
technique introduced to improve the performance of GAE and in general vision

1819
01:12:54,959 --> 01:12:55,339
f3隐藏层的归一化输出在每个mini上标准化
technique introduced to improve the performance of GAE and in general vision

1820
01:12:55,339 --> 01:12:55,349
f3隐藏层的归一化输出在每个mini上标准化


1821
01:12:55,349 --> 01:13:01,169
f3隐藏层的归一化输出在每个mini上标准化
normalization output of f3 hidden layer is standardized over every single mini

1822
01:13:01,169 --> 01:13:01,179
f3隐藏层的归一化输出在每个mini上标准化
is standardized over every single mini batch path in the training session it

1823
01:13:01,179 --> 01:13:03,989
在培训课程中的批处理路径很明显，假设我们有一个
is standardized over every single mini batch path in the training session it

1824
01:13:03,989 --> 01:13:09,810
在培训课程中的批处理路径很明显，假设我们有一个
batch path in the training session it will be clear suppose we have a

1825
01:13:09,810 --> 01:13:09,820
在培训课程中的批处理路径很明显，假设我们有一个
will be clear suppose we have a classifier and we want the classifier to

1826
01:13:09,820 --> 01:13:12,089
分类器，我们希望分类器在一些图像之间进行分类
will be clear suppose we have a classifier and we want the classifier to

1827
01:13:12,089 --> 01:13:14,790
分类器，我们希望分类器在一些图像之间进行分类
classifier and we want the classifier to classify between some images which

1828
01:13:14,790 --> 01:13:14,800
分类器，我们希望分类器在一些图像之间进行分类
classify between some images which contents cat and which doesn't have a

1829
01:13:14,800 --> 01:13:18,239
内容为猫，并且图像中没有猫，因此我们的训练数据
classify between some images which contents cat and which doesn't have a

1830
01:13:18,239 --> 01:13:22,620
内容为猫，并且图像中没有猫，因此我们的训练数据
contents cat and which doesn't have a cat in the image so our training data

1831
01:13:22,620 --> 01:13:22,630
内容为猫，并且图像中没有猫，因此我们的训练数据
cat in the image so our training data contents on the black cat and all other

1832
01:13:22,630 --> 01:13:25,830
黑猫和所有其他非猫图像上的内容，然后将
cat in the image so our training data contents on the black cat and all other

1833
01:13:25,830 --> 01:13:29,699
黑猫和所有其他非猫图像上的内容，然后将
contents on the black cat and all other non cat images and then will be after

1834
01:13:29,699 --> 01:13:29,709
黑猫和所有其他非猫图像上的内容，然后将
non cat images and then will be after training we introduced cat images which

1835
01:13:29,709 --> 01:13:34,259
训练中，我们介绍了一般来说是彩色猫和非猫的猫图像
non cat images and then will be after training we introduced cat images which

1836
01:13:34,259 --> 01:13:36,989
训练中，我们介绍了一般来说是彩色猫和非猫的猫图像
training we introduced cat images which are colorful cat in general and non cat

1837
01:13:36,989 --> 01:13:36,999
训练中，我们介绍了一般来说是彩色猫和非猫的猫图像
are colorful cat in general and non cat or transfer won't be trouble too far

1838
01:13:36,999 --> 01:13:41,219
或转移不会像它所做的那么麻烦那么遥远
are colorful cat in general and non cat or transfer won't be trouble too far

1839
01:13:41,219 --> 01:13:44,089
或转移不会像它所做的那么麻烦那么遥远
or transfer won't be trouble too far from that good as it did for the

1840
01:13:44,089 --> 01:13:44,099
或转移不会像它所做的那么麻烦那么遥远
from that good as it did for the training dataset this is called this is

1841
01:13:44,099 --> 01:13:47,790
训练数据集，这被称为这是一个非常奇特的术语，称为协变量平移
from that good as it did for the training dataset this is called this is

1842
01:13:47,790 --> 01:13:50,339
训练数据集，这被称为这是一个非常奇特的术语，称为协变量平移
training dataset this is called this is a very fancy term called covariate shift

1843
01:13:50,339 --> 01:13:50,349
训练数据集，这被称为这是一个非常奇特的术语，称为协变量平移
a very fancy term called covariate shift which means the a shift in the data

1844
01:13:50,349 --> 01:13:54,359
这意味着数据点在其分布中发生了偏移
a very fancy term called covariate shift which means the a shift in the data

1845
01:13:54,359 --> 01:13:57,959
这意味着数据点在其分布中发生了偏移
which means the a shift in the data point in its distribution

1846
01:13:57,959 --> 01:13:58,220
情境模型
which means the a shift in the data point in its distribution

1847
01:13:58,220 --> 01:13:58,230
情境模型


1848
01:13:58,230 --> 01:14:02,520
情境模型
situation model

1849
01:14:02,520 --> 01:14:04,880
因此，假设黑猫的数据部分-像这样的数据
situation model

1850
01:14:04,880 --> 01:14:04,890
因此，假设黑猫的数据部分-像这样的数据


1851
01:14:04,890 --> 01:14:11,420
因此，假设黑猫的数据部分-像这样的数据
so suppose the the data parts of black cats - like this very thing the data

1852
01:14:11,420 --> 01:14:11,430
因此，假设黑猫的数据部分-像这样的数据
cats - like this very thing the data points and the non cats are like this

1853
01:14:11,430 --> 01:14:14,230
点和非猫就像这个黑色的十字架，所以通常每个可怜的人
cats - like this very thing the data points and the non cats are like this

1854
01:14:14,230 --> 01:14:20,980
点和非猫就像这个黑色的十字架，所以通常每个可怜的人
points and the non cats are like this black crosses so usually this poor each

1855
01:14:20,980 --> 01:14:20,990
点和非猫就像这个黑色的十字架，所以通常每个可怜的人
black crosses so usually this poor each we don't use vaginal normalization our

1856
01:14:20,990 --> 01:14:24,560
我们不使用阴道标准化，我们的模型可能会学习直线
black crosses so usually this poor each we don't use vaginal normalization our

1857
01:14:24,560 --> 01:14:29,390
我们不使用阴道标准化，我们的模型可能会学习直线
we don't use vaginal normalization our model would likely learn straight line

1858
01:14:29,390 --> 01:14:29,400
我们不使用阴道标准化，我们的模型可能会学习直线
model would likely learn straight line difference we should separate these data

1859
01:14:29,400 --> 01:14:31,790
区别，当我们
model would likely learn straight line difference we should separate these data

1860
01:14:31,790 --> 01:14:35,180
区别，当我们
difference we should separate these data points like this straight line when we

1861
01:14:35,180 --> 01:14:35,190
区别，当我们
points like this straight line when we introduced these colorful cats these

1862
01:14:35,190 --> 01:14:39,820
介绍了这些五颜六色的猫这些五颜六色的猫线的这些数据点
points like this straight line when we introduced these colorful cats these

1863
01:14:39,820 --> 01:14:42,650
介绍了这些五颜六色的猫这些五颜六色的猫线的这些数据点
introduced these colorful cats these data points of this colorful cat lines

1864
01:14:42,650 --> 01:14:42,660
介绍了这些五颜六色的猫这些五颜六色的猫线的这些数据点
data points of this colorful cat lines here which our model won't be able to

1865
01:14:42,660 --> 01:14:46,790
在这里我们的模型将无法正确分类，因为现在他们
data points of this colorful cat lines here which our model won't be able to

1866
01:14:46,790 --> 01:14:50,630
在这里我们的模型将无法正确分类，因为现在他们
here which our model won't be able to classify it correctly because now they

1867
01:14:50,630 --> 01:14:50,640
在这里我们的模型将无法正确分类，因为现在他们
classify it correctly because now they have only joined a straight line which

1868
01:14:50,640 --> 01:14:53,360
仅加入了一条直线，显然无法对其进行准确分类
classify it correctly because now they have only joined a straight line which

1869
01:14:53,360 --> 01:14:56,710
仅加入了一条直线，显然无法对其进行准确分类
have only joined a straight line which clearly don't classify them accurately

1870
01:14:56,710 --> 01:14:56,720
仅加入了一条直线，显然无法对其进行准确分类
clearly don't classify them accurately that so that's why we want to we want to

1871
01:14:56,720 --> 01:15:02,120
这就是为什么我们想要使用批处理规范化的原因，即使
clearly don't classify them accurately that so that's why we want to we want to

1872
01:15:02,120 --> 01:15:05,360
这就是为什么我们想要使用批处理规范化的原因，即使
that so that's why we want to we want to use batch normalization so that even if

1873
01:15:05,360 --> 01:15:05,370
这就是为什么我们想要使用批处理规范化的原因，即使
use batch normalization so that even if our data points to vary by some amount

1874
01:15:05,370 --> 01:15:08,350
如果将其归一化，我们的数据点将有所变化，并且我们的模型
use batch normalization so that even if our data points to vary by some amount

1875
01:15:08,350 --> 01:15:14,360
如果将其归一化，我们的数据点将有所变化，并且我们的模型
our data points to vary by some amount if normalizes it back and our our model

1876
01:15:14,360 --> 01:15:14,370
如果将其归一化，我们的数据点将有所变化，并且我们的模型
if normalizes it back and our our model learns faster learns more reliable

1877
01:15:14,370 --> 01:15:18,640
学习更快，学习更可靠，更密集
if normalizes it back and our our model learns faster learns more reliable

1878
01:15:18,640 --> 01:15:22,520
学习更快，学习更可靠，更密集
learns faster learns more reliable denser representation

1879
01:15:22,520 --> 01:15:23,910
这些是使用标准化的优势，这使我们
learns faster learns more reliable denser representation

1880
01:15:23,910 --> 01:15:23,920
这些是使用标准化的优势，这使我们


1881
01:15:23,920 --> 01:15:30,650
这些是使用标准化的优势，这使我们
these are some advantages of using that's normalization which makes our

1882
01:15:30,650 --> 01:15:30,660
这些是使用标准化的优势，这使我们
that's normalization which makes our model to launch faster makes it converge

1883
01:15:30,660 --> 01:15:34,530
更快发布的模型使其能够以更高的价值和更快的速度更好地融合
that's normalization which makes our model to launch faster makes it converge

1884
01:15:34,530 --> 01:15:38,490
更快发布的模型使其能够以更高的价值和更快的速度更好地融合
model to launch faster makes it converge better in a better value and in a faster

1885
01:15:38,490 --> 01:15:38,500
更快发布的模型使其能够以更高的价值和更快的速度更好地融合
better in a better value and in a faster manner while each training iteration

1886
01:15:38,500 --> 01:15:41,220
方式，而每次训练迭代都会变得有些偏斜，因为
better in a better value and in a faster manner while each training iteration

1887
01:15:41,220 --> 01:15:42,959
方式，而每次训练迭代都会变得有些偏斜，因为
manner while each training iteration will become somewhat skewer because the

1888
01:15:42,959 --> 01:15:42,969
方式，而每次训练迭代都会变得有些偏斜，因为
will become somewhat skewer because the externalization calculations in the

1889
01:15:42,969 --> 01:15:45,720
正向路径中的外部化计算，但最终它将
will become somewhat skewer because the externalization calculations in the

1890
01:15:45,720 --> 01:15:47,370
正向路径中的外部化计算，但最终它将
externalization calculations in the forward path but eventually it would

1891
01:15:47,370 --> 01:15:47,380
正向路径中的外部化计算，但最终它将
forward path but eventually it would converge quickly to overall combination

1892
01:15:47,380 --> 01:15:49,800
迅速融合到整体组合中，因为口袋是我用来
forward path but eventually it would converge quickly to overall combination

1893
01:15:49,800 --> 01:15:55,169
迅速融合到整体组合中，因为口袋是我用来
converge quickly to overall combination because pockets these are the I used for

1894
01:15:55,169 --> 01:15:55,179
迅速融合到整体组合中，因为口袋是我用来
because pockets these are the I used for layer deep fully connected Network as

1895
01:15:55,179 --> 01:15:57,030
层深层全连接网络既是编码器又是解码器萨尔萨舞
because pockets these are the I used for layer deep fully connected Network as

1896
01:15:57,030 --> 01:15:59,490
层深层全连接网络既是编码器又是解码器萨尔萨舞
layer deep fully connected Network as both encoder and decoder salsa eminence

1897
01:15:59,490 --> 01:15:59,500
层深层全连接网络既是编码器又是解码器萨尔萨舞
both encoder and decoder salsa eminence together set I take one more minute this

1898
01:15:59,500 --> 01:16:04,260
一起设置我需要一分钟，这是
both encoder and decoder salsa eminence together set I take one more minute this

1899
01:16:04,260 --> 01:16:06,780
一起设置我需要一分钟，这是
together set I take one more minute this is the

1900
01:16:06,780 --> 01:16:10,100
是的，所以这是失去功能的收敛而没有使用合理化
together set I take one more minute this is the

1901
01:16:10,100 --> 01:16:10,110
是的，所以这是失去功能的收敛而没有使用合理化


1902
01:16:10,110 --> 01:16:17,320
是的，所以这是失去功能的收敛而没有使用合理化
yeah so this is the convergence of lost function without using rationalization

1903
01:16:17,320 --> 01:16:17,330
是的，所以这是失去功能的收敛而没有使用合理化
function without using rationalization and this is the generated data set

1904
01:16:17,330 --> 01:16:20,870
这是没有合理化的生成的数据集，接下来我被使用
function without using rationalization and this is the generated data set

1905
01:16:20,870 --> 01:16:26,300
这是没有合理化的生成的数据集，接下来我被使用
and this is the generated data set without rationalization next I am used

1906
01:16:26,300 --> 01:16:26,310
这是没有合理化的生成的数据集，接下来我被使用
without rationalization next I am used batch normalization and the it converges

1907
01:16:26,310 --> 01:16:29,390
批归一化，它收敛到更好的值，这是一个更好的值
without rationalization next I am used batch normalization and the it converges

1908
01:16:29,390 --> 01:16:36,040
批归一化，它收敛到更好的值，这是一个更好的值
batch normalization and the it converges to a better value which is a bit more

1909
01:16:36,040 --> 01:16:36,050
批归一化，它收敛到更好的值，这是一个更好的值
to a better value which is a bit more cleaner

1910
01:16:36,050 --> 01:16:39,050
清洁工
to a better value which is a bit more cleaner

1911
01:16:39,050 --> 01:16:39,130
这些使用的是拉丁扭曲的四个四个维度，而不是两个
to a better value which is a bit more cleaner

1912
01:16:39,130 --> 01:16:39,140
这些使用的是拉丁扭曲的四个四个维度，而不是两个


1913
01:16:39,140 --> 01:16:44,980
这些使用的是拉丁扭曲的四个四个维度，而不是两个
these are using the four four dimensions for the Latin twist instead of two with

1914
01:16:44,980 --> 01:16:44,990
这些使用的是拉丁扭曲的四个四个维度，而不是两个
for the Latin twist instead of two with without BN this is again it using BM so

1915
01:16:44,990 --> 01:16:50,300
如果没有BN，这也是使用BM的原因，因此您可以看到损失函数
for the Latin twist instead of two with without BN this is again it using BM so

1916
01:16:50,300 --> 01:16:54,380
如果没有BN，这也是使用BM的原因，因此您可以看到损失函数
without BN this is again it using BM so you can see that the loss function

1917
01:16:54,380 --> 01:17:07,630
访客参考
without BN this is again it using BM so you can see that the loss function

1918
01:17:07,630 --> 01:17:07,640
访客参考


1919
01:17:07,640 --> 01:17:11,840
访客参考
visitor references

1920
01:17:11,840 --> 01:17:13,040
[掌声]
visitor references

1921
01:17:13,040 --> 01:17:13,050
[掌声]


1922
01:17:13,050 --> 01:17:16,409
[掌声]
[Applause]

